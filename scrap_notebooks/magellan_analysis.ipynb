{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astroquery.ipac.ned import Ned\n",
    "import numpy as np\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from urllib.request import urlretrieve\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "import os\n",
    "from scipy.interpolate import CubicSpline\n",
    "import textwrap\n",
    "import seaborn as sns\n",
    "import scipy.stats as scp\n",
    "\n",
    "\n",
    "def make_desig(data, ra_key='ra', dec_key='dec'):\n",
    "    \"\"\"make designation if df has 'ra' and 'dec' columns\"\"\"\n",
    "    desig=[]\n",
    "    for posstring in SkyCoord(data[ra_key].values*u.deg, data[dec_key].values*u.deg).to_string(\"hmsdms\"):\n",
    "        posstring = posstring.split(' ')\n",
    "        des_ra = posstring[0][0:2]+posstring[0][3:5]\n",
    "        des_dec = posstring[1][0:3]+posstring[1][4:6]\n",
    "        desig.append('J'+des_ra+des_dec)\n",
    "    return desig\n",
    "\n",
    "def pos(row):\n",
    "    \"\"\"make skyCoord object for HST coord cone search\"\"\"\n",
    "    return SkyCoord(ra=row['RA']*u.deg, dec=row['DEC']*u.deg)\n",
    "\n",
    "def cross_bigmac(mul171):\n",
    "    \"\"\"crossmatch sample with big MAC\"\"\"\n",
    "    # read in big  mac\n",
    "    bigmac = pd.read_csv(\"/home/insepien/research-data/GFG.csv\")\n",
    "    # format designation\n",
    "    desigs = []\n",
    "    for i in range(len(bigmac)):\n",
    "        name = bigmac['Name1'].loc[i].replace(\"SDSS\",\"\")\n",
    "        if name[0] == \"J\":\n",
    "            if \"+\" in name:\n",
    "                desig = name.split(\"+\")[0][:5] + \"+\" + name.split(\"+\")[1][:4]\n",
    "                desigs.append(desig)\n",
    "            elif \"-\" in name:\n",
    "                desig = name.split(\"-\")[0][:5] + \"-\" + name.split(\"-\")[1][:4]\n",
    "                desigs.append(desig)\n",
    "            else: print(name) \n",
    "        else:\n",
    "            desigs.append(name)\n",
    "    bigmac['DESIG'] = desigs\n",
    "\n",
    "    # merge big mac and mullaney\n",
    "    mul_bm = pd.merge(mul171,bigmac, on=\"DESIG\")\n",
    "\n",
    "    # optionally can get decals images\n",
    "    # for n in mul_bm.index:\n",
    "    #     urlretrieve('http://legacysurvey.org/viewer/jpeg-cutout?ra='+str(mul_bm.loc[n,'RA'])+'&dec='+str(mul_bm.loc[n,'DEC'])+'&layer=decals-dr7&pixscale=0.27&bands=grz',\n",
    "    #                 \"/home/insepien/research-data/hst/mul_bm/\"+str(mul_bm.loc[n,'DESIG'])+'.jpg')\n",
    "    return mul_bm, bigmac\n",
    "\n",
    "def cal_sep(theta, z):\n",
    "    \"\"\"return dual sep in kpc given scalar angle sep in arcsec\"\"\"\n",
    "    angle = (theta*u.arcsec).to(u.rad).value\n",
    "    return (cosmo.angular_diameter_distance(z)*angle).to(u.kpc)\n",
    "\n",
    "\n",
    "def f(on, theta):\n",
    "    \"\"\"plot decal image and annulus at detected dual separation theta\"\"\"\n",
    "    fn = \"/home/insepien/research-data/hst/mul_bm/\"+on+\".jpg\"\n",
    "    decals_plate_scale = 0.236 #''/pix\n",
    "    pix_sep = theta/decals_plate_scale\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    im = plt.imread(fn)\n",
    "    midF = im.shape[0]/2\n",
    "    ax.imshow(im)\n",
    "    circ = plt.Circle((midF,midF), pix_sep, fill=False, color='white',alpha=0.5,label=f\"{theta:.2f}''\")\n",
    "    ax.add_patch(circ)\n",
    "    ax.legend()\n",
    "    ax.set_title(on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check emission line luminosities\n",
    "J1010 is dimmer than rest of sample based on OIII dereddened, but is brighter than the rest in SDSS R-band. R-band covers OIII and HB, so it should be OIII dominated. Therefore OIII dereddened measurments do not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check emission lines\n",
    "df = Table(fits.getdata(\"/home/insepien/research-data/alpaka/ALPAKA_v1_withDes.fits\")).to_pandas()\n",
    "j10 = df[df['Desig'] == \"J1010+1413\"]\n",
    "with open(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\",\"rb\") as f:\n",
    "    magel = pickle.load(f)\n",
    "keys = ['HB_LUM',\n",
    " 'OIII_4959_LUM',\n",
    " 'OIII_5007_LUM',\n",
    " 'NII_6548_LUM',\n",
    " 'HA_LUM',\n",
    " 'NII_6584_LUM',\n",
    " 'NVS_LUM']\n",
    "i=0\n",
    "clr = sns.color_palette(\"colorblind\", len(keys))\n",
    "for k in keys:\n",
    "    lums = [m for m in magel[k] if np.isfinite(m) and m!=0]\n",
    "    plt.hist(np.log10(lums),color=clr[i],alpha=0.7,label=k)\n",
    "    try:\n",
    "        plt.axvline(np.log10(j10[k].values),c=clr[i])\n",
    "    except:\n",
    "        print(k)\n",
    "    i+=1\n",
    "plt.xlim((37.5,43.5))\n",
    "plt.legend(bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-match catalogs\n",
    "look at the 152 sample when doing HST proposal and cross-match with Big MAC. Also plot dual candidates; this could be used for intro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in original sample\n",
    "mul171 = pd.read_pickle(\"/home/insepien/research-data/alpaka/mull152.pkl\")\n",
    "mul171['DESIG'] = make_desig(mul171, ra_key='RA',dec_key=\"DEC\")\n",
    "mul_bm, bigmac = cross_bigmac(mul171)\n",
    "\n",
    "# get some stats on sub-kpc pairs for science justification\n",
    "subkpc_mask = ((bigmac['Primary System Type']=='Dual AGN Candidate') | (bigmac['Primary System Type']=='Dual AGN')) & (bigmac['Sep(kpc)']<1) & (bigmac['Sep(kpc)']>0)\n",
    "subkpc_dual = bigmac[subkpc_mask]\n",
    "dual_mask = ((bigmac['Primary System Type']=='Dual AGN Candidate') | (bigmac['Primary System Type']=='Dual AGN')) & (bigmac['Sep(kpc)']>1)\n",
    "dual = bigmac[dual_mask]\n",
    "print(\"fraction of sub-kpc\", len(subkpc_dual)/len(dual))\n",
    "print(\"number of duals\", len(dual))\n",
    "\n",
    "# get some methods of measuring sub-kpc sep\n",
    "anyl_meth = Counter(subkpc_dual['Parsed Analysis Method'])\n",
    "print(\"1st most common method: \",anyl_meth.most_common(2)[0])\n",
    "print(\"2nd most common method: \",anyl_meth.most_common(2)[1])\n",
    "\n",
    "\n",
    "# cross-match specifically for magellan\n",
    "with open(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\",\"rb\") as f:\n",
    "    magel = pickle.load(f)\n",
    "\n",
    "magel.reset_index(inplace=True)\n",
    "magel.rename(columns={\"Desig\":\"DESIG\"},inplace=True)\n",
    "magel_bm, _ = cross_bigmac(magel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as patches\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('colorblind')\n",
    "figparams = {'font.family': 'DejaVu Sans',\n",
    "            'font.serif':'Times',\n",
    "            'hatch.linewidth' : 3.0}\n",
    "plt.rcParams.update(figparams)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(15,7),dpi=500)\n",
    "# plot hst resolution limit\n",
    "for reso in [1,5,20]:\n",
    "    seeing = 0.04*2.5*reso\n",
    "    ax.plot(np.linspace(0,3),cal_sep(seeing, np.linspace(0,3)),c='k',linestyle=\"--\",alpha=0.5)\n",
    "    ax.text(2.5, 1*reso, f\"{seeing:.1f} arcsec\", color='k',fontsize=15)\n",
    "\n",
    "# add survey vol\n",
    "# rect = patches.Rectangle((0.1, 0), 0.4-0.1, 1, linewidth=2, edgecolor='w', facecolor='darkseagreen',alpha=0.3)\n",
    "# ax.add_patch(rect)\n",
    "# ax.text(0.2,1,\"Our survey\",c=\"darkolivegreen\",fontsize=15)\n",
    "\n",
    "# kpc points ie sep>1 with confidence>0.5, z0-3, have been imaged\n",
    "conf_kpc = dual['ST1 Confidence Flag']>=0.5\n",
    "imag_kpc = dual['Parsed Analysis Method'].str.contains(\"Imaging\")\n",
    "z_mask = (dual['z1']>0)&(dual['z1']<3)\n",
    "kpcdf = dual[conf_kpc&imag_kpc&z_mask]\n",
    "paper = list(kpcdf['Paper(s)'].str.split(\" ; \").explode().value_counts().keys())[:15]\n",
    "all_markers = list(Line2D.markers.keys())[5:]\n",
    "all_colors = sns.color_palette(\"colorblind\", len(paper))\n",
    "for j in range(len(paper)):    \n",
    "    papermask = np.array([np.isin(paper[j],kpcdf.loc[i,'Paper(s)'].split(\" ; \")).item() for i in kpcdf.index.values])\n",
    "    for k in kpcdf[papermask].index.values:\n",
    "        ulabel = paper[j] if k==kpcdf[papermask].index.values[0] else None\n",
    "        plt.scatter(kpcdf[papermask]['z1'][k],kpcdf[papermask]['Sep(kpc)'][k],marker=all_markers[j],c=all_colors[j],s=30,label=ulabel)\n",
    "\n",
    "# plot points with confidence >0.5 and have been imaged\n",
    "confidence_mask = subkpc_dual['ST1 Confidence Flag']>=0.5\n",
    "imaging_mask  = subkpc_dual['Parsed Analysis Method'].str.contains(\"Imaging\")\n",
    "distance_mask = subkpc_dual['Sep(kpc)']>0.2  # to remove radio sources\n",
    "df = subkpc_dual[confidence_mask&imaging_mask&distance_mask]\n",
    "lagn = np.log10([0.033e44,0.135e44,3e44,10**43.23*600,6e46])\n",
    "subkpc_markers = list(Line2D.markers.keys())[1:6]\n",
    "for i,m,mrk in zip(df.index.to_list(),lagn,subkpc_markers): # mark confirmed and very sure candidates differently\n",
    "    wrapped_label = \"\\n\".join(textwrap.wrap(df['Paper(s)'][i], width=60))\n",
    "    sca = ax.scatter(df['z1'][i], df['Sep(kpc)'][i],label=wrapped_label,s=30,cmap='magma',c=m,marker=mrk,vmin=np.min(lagn)-0.5,vmax=np.max(lagn)+1)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.99, 0.125, 0.01, 0.75]) \n",
    "cbar = fig.colorbar(sca,cax=cbar_ax)\n",
    "cbar.set_label(\"Log($L_{AGN}$) [erg/s]\")\n",
    "\n",
    "ax.set_xlabel(\"Redshift\")\n",
    "ax.set_ylabel(\"Projected separation [kpc]\")\n",
    "ax.set_xlim((-0.01,3))\n",
    "ax.set_ylim((0.2,110))\n",
    "# set top xlabel to look back time\n",
    "ax_top = ax.secondary_xaxis(\"top\")\n",
    "ax_top.set_xlabel(\"Lookback time [Gyr]\")\n",
    "# interpolate to get tick positions for round lookback time\n",
    "spl = CubicSpline(cosmo.lookback_time(np.linspace(0,0.5)),np.linspace(0,0.5))\n",
    "xtick_pos = spl(np.arange(1,12,2))\n",
    "ax_top.set_xticks(xtick_pos)\n",
    "ax_top.set_xticklabels(np.arange(1,12,2))\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(ncol=3,fontsize=8,loc='lower center')\n",
    "ax.grid(linestyle='--',alpha=0.5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"hst.png\",dpi=500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual params\n",
    "get luminosity of Magellan sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.constants as const\n",
    "def get_wise_mags(wise_):\n",
    "    \"\"\"get wise mags and mag errors from data frame of ipac search results\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    w1mag = wise_['w1mpro']\n",
    "    w2mag = wise_['w2mpro']\n",
    "    w3mag = wise_['w3mpro']\n",
    "    w4mag = wise_['w4mpro']\n",
    "    wmags_ = np.array([w1mag, w2mag, w3mag, w4mag])\n",
    "    wmags_err_ = np.array([wise_['w1sigmpro'], wise_['w2sigmpro'], wise_['w3sigmpro'], wise_['w4sigmpro']])\n",
    "    return wmags_, wmags_err_\n",
    "\n",
    "\n",
    "def wise_lum_from_mag(wmags_, wmags_err_, obs_wavelength_, redshift_):\n",
    "    \"\"\"calculate wise luminosity from magnitude at some observed wavelength\"\"\"\n",
    "    ## change mags to fluxes -- http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html#example\n",
    "    zeromagflux = np.array([309.540, 171.787, 31.674, 8.363])*u.Jy\n",
    "    fluxdens = zeromagflux*10**(-wmags_/2.5) # in Jy\n",
    "    # now either interpolate flux dens to some wavelength or use a band from wise\n",
    "    wise_wavelengths = np.array([3.4, 4.6, 12., 22.]) # 1e-6 m\n",
    "    if np.isin(obs_wavelength_, wise_wavelengths): # check if need to interpolate to non-wise wl\n",
    "        obs_flux = fluxdens[wise_wavelengths==obs_wavelength_][0]\n",
    "    else: # interpolate\n",
    "        fluxdens_err = zeromagflux*10**(-wmags_err_/2.5)\n",
    "        ## interpolate - use straight line\n",
    "        wiseflux = np.polyfit(np.array(wise_wavelengths)[[0,1,3]], np.array(fluxdens.value)[[0,1,3]],deg=1, w=1./np.array(fluxdens_err)[[0,1,3]])\n",
    "        ## get flux at obs wavelength, i.e. just a straight line here\n",
    "        obs_flux = (wiseflux[0]*obs_wavelength_+wiseflux[1])*u.Jy    \n",
    "        #plt.scatter(wise_wavelengths, fluxdens.value)  \n",
    "        #plt.plot(wise_wavelengths, wise_wavelengths*wiseflux[0]+wiseflux[1])\n",
    "    ## change to luminosity\n",
    "    obs_hz = (const.c/(obs_wavelength_*u.micron)).to(u.Hz)\n",
    "    lum = (obs_flux*obs_hz*4*np.pi*\n",
    "           cosmo.luminosity_distance(redshift_)**2).to(u.erg/u.s)\n",
    "    return lum\n",
    "\n",
    "\n",
    "def correct_ir():\n",
    "    \"\"\"correct IR luminosity at 15 microns rest frame based on Hopkins+20\"\"\"\n",
    "    # load hopkins bolometric correction\n",
    "    with open(\"/home/insepien/research-data/pop-result/bc.txt\",\"r\") as f:\n",
    "        d = f.read().splitlines()\n",
    "    hopkins = pd.DataFrame([d[1:][i].split(' ') for i in range(len(d[1:]))],columns=d[0].split(' '))\n",
    "    Lbol = np.array(list(hopkins['Lbols'].values), dtype=float)\n",
    "    LIR = np.array(list(hopkins['LIRs'].values), dtype=float)\n",
    "    spl = CubicSpline(LIR, Lbol)\n",
    "    return spl\n",
    "\n",
    "def get_wise_ir_lums(wise_, alpaka_,wise_key = 'designation', mul_key='Desig',wl_=22):\n",
    "    \"\"\"calculate wise IR luminosity and bolometric lum, \n",
    "        default keys are for magellan sample\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    wmags, wmags_err_nan = get_wise_mags(wise_)\n",
    "    # replace nan values in mag error with median\n",
    "    wmags_err = np.nan_to_num(wmags_err_nan,np.median(wmags_err_nan))\n",
    "    # calculate luminosity\n",
    "    wise_lums = np.zeros((len(wise_)))\n",
    "    for i in range(0, len(wise_)):\n",
    "        on = wise_.loc[i,wise_key]\n",
    "        z = np.mean(alpaka_[alpaka_[mul_key]==on]['Z'])\n",
    "        wise_lums[i] = wise_lum_from_mag(wmags[:,i], wmags_err[:,i], wl_, z).value\n",
    "    # check wavelength to see how to do bolo correction\n",
    "    if wl_==15: # use Hopkins+2020 if at 15 microns\n",
    "        spl = correct_ir()\n",
    "        irbol = 10**(spl(np.log10(wise_lums)))\n",
    "    else: # else correct by 12%\n",
    "        irbol = wise_lums*10**1.12\n",
    "    return wmags, wise_lums,irbol\n",
    "\n",
    "def crop_cat(namelist,wsearch,mul):\n",
    "    wmask = wsearch['desig'].isin(namelist)\n",
    "    wcat = wsearch[wmask].reset_index()\n",
    "    mmask = mul['desig'].isin(namelist)\n",
    "    mcat = mul[mmask].reset_index()\n",
    "    return wcat, mcat\n",
    "\n",
    "def lbol_to_m(lbol,edd_rate=0.3):\n",
    "    ledd = lbol/edd_rate\n",
    "    return np.log10(ledd/(1.28e46/1e8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wise match of all type 2 agn in mullaney\n",
    "wsearch =  pd.read_pickle(\"/home/insepien/research-data/alpaka/wise-cat/all_type2_wise.pkl\")\n",
    "wsearch['desig'] = make_desig(wsearch)\n",
    "# load alpaka and match with wise, for sample plotting later\n",
    "alpaka = Table(fits.open(\"/home/insepien/research-data/alpaka/ALPAKA_v1_withDes.fits\")[1].data).to_pandas()\n",
    "wise_names = wsearch['desig']\n",
    "alpaka_in_wise = alpaka[alpaka['Desig'].isin(wise_names)]\n",
    "alpaka_in_wise.rename(columns={'Desig':'desig'},inplace=True)\n",
    "maindf = pd.merge(alpaka_in_wise, wsearch,on='desig',how='left')\n",
    "# load magellan 39 sample\n",
    "mul = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\")\n",
    "mul['desig'] = make_desig(mul, ra_key='RA',dec_key=\"DEC\")\n",
    "# crop single and dual magellan subsets\n",
    "dualnames = [\"J1215+1344\",\"J1222-0007\"]\n",
    "wdual, mdual = crop_cat(dualnames,wsearch,mul)\n",
    "singleAGNnames =  mul[~ mul['desig'].isin(dualnames)]['desig']\n",
    "wsingle, msingle = crop_cat(singleAGNnames,wsearch,mul)\n",
    "# calculate Lbol from WISE and BH mass\n",
    "wmags_dual, wise_lums_dual,irbol_dual = get_wise_ir_lums(wdual,mdual,wise_key=\"desig\",mul_key='desig',wl_=15)\n",
    "wmags, wise_lums,irbol = get_wise_ir_lums(wsingle, msingle,wise_key=\"desig\",mul_key='desig',wl_=15)\n",
    "print(wise_lums_dual)\n",
    "print(irbol_dual)\n",
    "print(\"BH mass \", lbol_to_m(irbol_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some sample plots\n",
    "first IR only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{mathptmx}\",  # Times Roman\n",
    "    \"hatch.linewidth\": 3.0,\n",
    "})\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(2,2,gridspec_kw={'width_ratios': [2,0.5],'height_ratios': [0.7,2]},figsize=(8,6),\n",
    "                      sharey='row',sharex='col',dpi=300)\n",
    "plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "\n",
    "mdual_labs = ['J1215+1344','J1222-0007 E', 'J1222-0007 W']\n",
    "ax[1,0].scatter(maindf['Z'],np.log10(maindf['irbol']),s=2,alpha=0.1,color=\"plum\")\n",
    "ax[1,0].scatter(msingle['Z'],np.log10(irbol),s=50,marker='2',color='indigo',alpha=0.7)\n",
    "[ax[1,0].scatter(mdual['Z'][:2][i],np.log10(irbol_dual)[i],s=40,marker=['s','o'][i],color='indigo',alpha=0.7,label=mdual_labs[:2][i]) for i in range(2)];\n",
    "\n",
    "ax[1,0].set_ylim(43.5,47.5)\n",
    "ax[1,0].set_xlabel(\"Redshift\")\n",
    "ax[1,0].set_ylabel('Log($L_{bol,IR}$) $[erg s^-1]$')\n",
    "ax[1,0].legend(fontsize=10) \n",
    "\n",
    "def norm_hist(ax,quant,ecolor,fcolor,bin_arr=[],alpha=1,horz=False):\n",
    "    \"\"\"normalize histogram sum count to 1 given some quantity (quant)\n",
    "        args: edgecoloe, facecolor, bin array, opacity, flag for plotting horizontal hist\"\"\"\n",
    "    count, bin = np.histogram(quant,bins=bin_arr)\n",
    "    if horz:\n",
    "        ax.barh(bin[:-1],count/np.sum(count), height= np.diff(bin),align='edge',edgecolor=ecolor,facecolor=fcolor,alpha=alpha)\n",
    "    else:\n",
    "        ax.bar(bin[:-1],count/np.sum(count),width = np.diff(bin),align='edge',edgecolor=ecolor,facecolor=fcolor,alpha=alpha)\n",
    "\n",
    "binz = np.linspace(np.min(maindf['Z']),np.max(maindf['Z']),20)\n",
    "norm_hist(ax[0,0],maindf['Z'],\"plum\",'none',bin_arr=binz)\n",
    "norm_hist(ax[0,0],np.concatenate([msingle['Z'],mdual['Z']]),'none','indigo',bin_arr=binz,alpha=0.5)\n",
    "ax[0,0].set_ylabel(\"f$_{AGN}$\")\n",
    "\n",
    "binL = np.linspace(np.log10(np.min(maindf['irbol'])), np.log10(np.max(maindf['irbol'])),10)\n",
    "norm_hist(ax[1,1],np.log10(maindf['irbol'].dropna()),'plum',\"none\",binL,horz=True)\n",
    "norm_hist(ax[1,1],np.log10(np.concatenate([irbol,irbol_dual])),'none','indigo',binL,alpha=0.5,horz=True)\n",
    "ax_top = ax[1,1].secondary_xaxis(\"top\")\n",
    "ax_top.set_xlabel(\"f$_{AGN}$\")\n",
    "ax_top.set_xticks([0,0.2])\n",
    "ax_top.set_xticklabels([0,0.2])\n",
    "ax[1,1].set_xticks([])\n",
    "\n",
    "ax[0,1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{mathptmx}\",  # Times Roman\n",
    "    \"hatch.linewidth\": 3.0,\n",
    "})\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4),sharey=True,dpi=500)\n",
    "ax[0].scatter(maindf['Z'],np.log10(maindf['OIII_5007_LUM_DERRED']*800),s=2,alpha=0.1,color='plum')\n",
    "ax[0].scatter(mul['Z'],np.log10(mul['OIII_5007_LUM_DERRED']*800),s=50,alpha=0.5,marker=\"2\",color='indigo')\n",
    "mdual_labs = ['J1215+1344','J1222-0007 W', 'J1222-0007 E']\n",
    "[ax[0].scatter(mdual['Z'][i],np.log10(mdual['OIII_5007_LUM_DERRED']*800)[i],s=40,marker=['s','o',\"^\"][i],color='indigo',alpha=0.5,label=mdual_labs[i]) for i in range(3)];\n",
    "\n",
    "ax[1].scatter(maindf['Z'],np.log10(maindf['irbol']),s=2,alpha=0.1,color='plum')\n",
    "ax[1].scatter(msingle['Z'],np.log10(irbol),s=50,marker='2',color='indigo',alpha=0.5)\n",
    "[ax[1].scatter(mdual['Z'][:2][i],np.log10(irbol_dual)[i],s=40,marker=['s','^'][i],color='indigo',alpha=0.5,label=[mdual_labs[0],mdual_labs[2]][i]) for i in range(2)];\n",
    "\n",
    "ax[0].set_ylim(43,48)\n",
    "[a.set_xlabel(\"Redshift\") for a in ax]\n",
    "[ax[i].set_ylabel(['Log($L_{bol,[OIII] dered}$) $[erg s^-1]$','Log($L_{bol,IR}$) $[erg s^-1]$'][i]) for i in range(2)]\n",
    "[ax[i].legend(fontsize=10) for i in range(2)]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try resampling to correct incomplete lum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all type 2 agn in z cut from mul with match in wise\n",
    "type2 = maindf[(maindf['Z'] > 0.14) & (maindf['Z'] < 0.22) & (maindf['AGN_TYPE']==2)]\n",
    "magel_withwise = type2[type2['desig'].isin(magel['desig'])]\n",
    "# get histograms, using sqrt smaller sample as numbers of bin\n",
    "lbol_all = np.log10(type2['irbol'])\n",
    "bin = np.linspace(lbol_all.min(),lbol_all.max(),int(np.ceil(np.sqrt(39))))\n",
    "hist_ful = plt.hist(lbol_all,label=\"mullaney type-2 agn \\nmatched with WISE\",bins=bin)\n",
    "hist_magel = plt.hist(np.log10(np.concatenate([irbol,irbol_dual])),label='Magellan sample',bins=bin)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Log(L_bol)')\n",
    "plt.ylabel(\"number of AGN\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate pdf for pretty plotting\n",
    "binmid = (bin[:-1]+bin[1:])*0.5\n",
    "pdf_full = CubicSpline(binmid,hist_ful[0])\n",
    "pdf_magel = CubicSpline(binmid,hist_magel[0])\n",
    "# use full sample pdf as weight\n",
    "w = hist_ful[0]/np.sum(hist_ful[0])\n",
    "# assign weight to each magel target\n",
    "binnum = np.digitize(np.log10(magel_withwise['irbol']),bin)-1\n",
    "weights = [w[b] for b in binnum]\n",
    "magel_withwise['weights'] = weights\n",
    "# sample magel with weights\n",
    "new_sample_size = 20\n",
    "magel_sub = [magel_withwise.sample(n=new_sample_size,weights='weights') for i in range(1000)]\n",
    "pdfs_magel = [np.histogram(np.log10(magel_sub[i]['irbol']),bins=bin)[0] for i in range(1000)]\n",
    "# random sample from full sample\n",
    "pdfs = [np.histogram(np.log10(type2.sample(n=new_sample_size)['irbol']),bins=bin)[0] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxind = np.argmax(hist_magel[0])\n",
    "magel_corrected = w/w[maxind]*hist_magel[0]\n",
    "magel_corrected_spl = CubicSpline(binmid,magel_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty plot\n",
    "x = np.linspace(binmid.min(),binmid.max(),20)\n",
    "# plot full sample\n",
    "plt.plot(x,pdf_full(x),c='b')\n",
    "plt.scatter(binmid,hist_ful[0],c='b',label='full sample')\n",
    "# plot magellan sample\n",
    "plt.scatter(binmid,hist_magel[0],label='magel',c='r')\n",
    "plt.plot(x,pdf_magel(x),c='r')\n",
    "# correct by largest bin\n",
    "plt.scatter(binmid,magel_corrected,c=\"g\",label='corrected')\n",
    "plt.plot(x,magel_corrected_spl(x),c='g')\n",
    "# plot subsamples\n",
    "[plt.plot(binmid, pdfs_magel[i],c='r',alpha=0.01) for i in range(500)];\n",
    "[plt.plot(binmid, pdfs[i],c='b',alpha=0.01) for i in range(500)];\n",
    "\n",
    "plt.plot(binmid[maxind], magel_corrected[maxind],c=\"r\",marker=\"*\",markersize=20)\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Log(L_bol)')\n",
    "plt.ylabel(\"number of AGN\")\n",
    "plt.legend(bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### malmquist correction\n",
    "tried volume limited sample but our sample is already very bright, so doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "mlim = 22.2 # r-band\n",
    "sdss = pd.read_pickle(\"/home/insepien/research-data/alpaka/sdss-cat/sdss_rband_171.pkl\")\n",
    "sdss40 = sdss[sdss['DESIG'].isin(mul['desig'])]\n",
    "sdss40['r-mag'] = 22.5 - 2.5 * np.log10(sdss40['spectroFlux_r'])\n",
    "sdss40 = pd.merge(sdss40,mul.rename(columns={'desig':'DESIG'})[['Z','DESIG']],on='DESIG')\n",
    "sdss40['M'] = sdss40['r-mag']-5*np.log10((cosmo.angular_diameter_distance(sdss40['Z'])*u.Mpc/(10*u.pc).to(u.Mpc)))\n",
    "\n",
    "Mlim = -16.5\n",
    "mask = sdss40['M'] < Mlim\n",
    "dmax = (10**((mlim-Mlim)/5)*10*u.pc).to(u.Mpc)\n",
    "from scipy.interpolate import CubicSpline\n",
    "spl = CubicSpline(cosmo.angular_diameter_distance(np.linspace(0,1,20)), np.linspace(0,1,20))\n",
    "zmax = spl(dmax.value)\n",
    "zmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dual fraction from lit rev table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv(\"/home/insepien/research-data/pop-result/lit_rev_frac/dualfrac_rev2.csv\")\n",
    "dfr_agn = dfr[~ dfr['lower dual frac'].isna()]\n",
    "errs = []\n",
    "not_nan_ind = dfr_agn['lower dual frac error'].dropna().index.values\n",
    "nan_ind = dfr_agn.index[~ np.isin(dfr_agn.index,dfr_agn['lower dual frac error'].dropna().index.values)]\n",
    "for i in range(len(dfr_agn)):\n",
    "    if i in not_nan_ind:\n",
    "        try:\n",
    "            errs.append(np.abs(dfr_agn['lower dual frac'][i]-sorted(np.array(dfr_agn['lower dual frac error'][i].split(','),dtype=float))))\n",
    "        except:\n",
    "                print(i)\n",
    "    else:\n",
    "         errs.append(np.array([np.nan,np.nan]))\n",
    "errs = pd.DataFrame(errs)\n",
    "\n",
    "fmt = lambda minv, maxv: f\"${minv:.0f}-{maxv:.0f}$\"\n",
    "fmt2 = lambda minv, maxv: f\"${minv:.2f}-{maxv:.2f}$\"\n",
    "fmt_err = lambda val, low_err, up_err: f\"${val:.3f}^{{-{low_err:.4f}}}_{{+{up_err:.4f}}}$\"\n",
    "fmt_lbol = lambda min,max : f\"$10^{{{min:.0f}}}-10^{{{max:.0f}}}$\"\n",
    "\n",
    "\n",
    "redshift = [fmt2(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['min z'],dfr_agn['max z'])]\n",
    "sep = [fmt(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['Min sep'],dfr_agn['Max sep'])]\n",
    "lbols = [fmt_lbol(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['min Lbol'],dfr_agn['max Lbol'])]\n",
    "fracs = [fmt_err(val,errl,erru) for val,errl,erru in zip(dfr_agn['lower dual frac'],errs[0],errs[1])]\n",
    "\n",
    "keys = ['Paper Name', 'Red shift', 'Separation $[kpc]$', \"$L_{bol}~[erg~s^{-1}$]\", \"Selection method\", \"Dual fraction\", \"Fraction definition\"]\n",
    "tabb=pd.DataFrame([list(dfr_agn['Paper']),redshift,sep,lbols,list(dfr_agn['selection']),fracs,list(dfr_agn['note'])],index=keys).T.to_latex(column_format='c|c|c|c|c|c',index=False)\n",
    "print(tabb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
