{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astroquery.ipac.ned import Ned\n",
    "import numpy as np\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from urllib.request import urlretrieve\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "import os\n",
    "from scipy.interpolate import CubicSpline\n",
    "import textwrap\n",
    "import seaborn as sns\n",
    "import scipy.stats as scp\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{mathptmx}\",  # Times Roman\n",
    "    \"hatch.linewidth\": 3.0,\n",
    "})\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "\n",
    "\n",
    "def make_desig(data, ra_key='ra', dec_key='dec'):\n",
    "    \"\"\"make designation if df has 'ra' and 'dec' columns\"\"\"\n",
    "    desig=[]\n",
    "    for posstring in SkyCoord(data[ra_key].values*u.deg, data[dec_key].values*u.deg).to_string(\"hmsdms\"):\n",
    "        posstring = posstring.split(' ')\n",
    "        des_ra = posstring[0][0:2]+posstring[0][3:5]\n",
    "        des_dec = posstring[1][0:3]+posstring[1][4:6]\n",
    "        desig.append('J'+des_ra+des_dec)\n",
    "    return desig\n",
    "\n",
    "def pos(row):\n",
    "    \"\"\"make skyCoord object for HST coord cone search\"\"\"\n",
    "    return SkyCoord(ra=row['RA']*u.deg, dec=row['DEC']*u.deg)\n",
    "\n",
    "def load_bigmac():\n",
    "    \"\"\"crossmatch sample with big MAC\"\"\"\n",
    "    # read in big  mac\n",
    "    bigmac = pd.read_csv(\"/home/insepien/research-data/GFG.csv\")\n",
    "    # format designation\n",
    "    desigs = []\n",
    "    for i in range(len(bigmac)):\n",
    "        name = bigmac['Name1'].loc[i].replace(\"SDSS\",\"\")\n",
    "        if name[0] == \"J\":\n",
    "            if \"+\" in name:\n",
    "                desig = name.split(\"+\")[0][:5] + \"+\" + name.split(\"+\")[1][:4]\n",
    "                desigs.append(desig)\n",
    "            elif \"-\" in name:\n",
    "                desig = name.split(\"-\")[0][:5] + \"-\" + name.split(\"-\")[1][:4]\n",
    "                desigs.append(desig)\n",
    "            else: print(name) \n",
    "        else:\n",
    "            desigs.append(name)\n",
    "    bigmac['Desig'] = desigs\n",
    "    # optionally can get decals images\n",
    "    # for n in mul_bm.index:\n",
    "    #     urlretrieve('http://legacysurvey.org/viewer/jpeg-cutout?ra='+str(mul_bm.loc[n,'RA'])+'&dec='+str(mul_bm.loc[n,'DEC'])+'&layer=decals-dr7&pixscale=0.27&bands=grz',\n",
    "    #                 \"/home/insepien/research-data/hst/mul_bm/\"+str(mul_bm.loc[n,'DESIG'])+'.jpg')\n",
    "    return bigmac\n",
    "\n",
    "def cal_sep(theta, z):\n",
    "    \"\"\"return dual sep in kpc given scalar angle sep in arcsec\"\"\"\n",
    "    angle = (theta*u.arcsec).to(u.rad).value\n",
    "    return (cosmo.angular_diameter_distance(z)*angle).to(u.kpc)\n",
    "\n",
    "\n",
    "def f(on, theta):\n",
    "    \"\"\"plot decal image and annulus at detected dual separation theta\"\"\"\n",
    "    fn = \"/home/insepien/research-data/hst/mul_bm/\"+on+\".jpg\"\n",
    "    decals_plate_scale = 0.236 #''/pix\n",
    "    pix_sep = theta/decals_plate_scale\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    im = plt.imread(fn)\n",
    "    midF = im.shape[0]/2\n",
    "    ax.imshow(im)\n",
    "    circ = plt.Circle((midF,midF), pix_sep, fill=False, color='white',alpha=0.5,label=f\"{theta:.2f}''\")\n",
    "    ax.add_patch(circ)\n",
    "    ax.legend()\n",
    "    ax.set_title(on)\n",
    "\n",
    "def lbol_to_m(lbol,edd_rate=0.3):\n",
    "    ledd = lbol/edd_rate\n",
    "    return np.log10(ledd/(1.28e46/1e8))\n",
    "\n",
    "def m_to_lbol(m,edd_rate=0.3):\n",
    "    ledd = 1.28e46*m/1e8\n",
    "    return np.log10(ledd*edd_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaka = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_z05_merged_wise.pkl\")\n",
    "# alpaka_fullZ = Table(fits.getdata(\"/home/insepien/research-data/alpaka/ALPAKA_v1_withDes.fits\")).to_pandas()\n",
    "magel_o = pd.read_pickle(\"/home/insepien/research-data/alpaka/magellan/alpaka_39fits.pkl\")\n",
    "magel = alpaka[(alpaka['RA'].isin(magel_o['RA'])) & (alpaka['DEC'].isin(magel_o['DEC']))]\n",
    "bigmac = load_bigmac()\n",
    "# separate dual and singles\n",
    "dualnames = [\"J1215+1344\",\"J1222-0007\"]\n",
    "singlenames =  magel[~ magel['Desig'].isin(dualnames)]['Desig']\n",
    "duals = alpaka[alpaka['Desig'].isin(dualnames)]\n",
    "singles = alpaka[alpaka['Desig'].isin(singlenames)]\n",
    "print(duals.shape,singles.shape)\n",
    "# some masks\n",
    "j1010mask = alpaka['Desig'] == \"J1010+1413\"\n",
    "j1000mask  = alpaka['Desig'] == \"J1000+1242\"\n",
    "mask171 = ((alpaka['OIII_5007_LUM_DERRED']*600 > 1e46) & (alpaka['Z']> 0.14) & (alpaka['Z']<0.22))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions to do linear fit to 4 fluxes and get Lir, fixed to 10% bolometric correction already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const\n",
    "def get_wise_mags(wise_):\n",
    "    \"\"\"get wise mags and mag errors from data frame of ipac search results\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    w1mag = wise_['w1mpro']\n",
    "    w2mag = wise_['w2mpro']\n",
    "    w3mag = wise_['w3mpro']\n",
    "    w4mag = wise_['w4mpro']\n",
    "    wmags_ = np.array([w1mag, w2mag, w3mag, w4mag])\n",
    "    wmags_err_ = np.array([wise_['w1sigmpro'], wise_['w2sigmpro'], wise_['w3sigmpro'], wise_['w4sigmpro']])\n",
    "    return wmags_, wmags_err_\n",
    "\n",
    "def wise_lum_from_mag_rest_frame(wmags_, wmags_err_, rest_wavelength_, redshift_):\n",
    "    \"\"\"calculate wise luminosity from magnitude at rest-frame wavelength\"\"\"\n",
    "    ## change mags to fluxes -- http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html#example\n",
    "    obs_wavelength_ = (1 + redshift_) * rest_wavelength_\n",
    "    zeromagflux = np.array([309.540, 171.787, 31.674, 8.363])*u.Jy\n",
    "    fluxdens = zeromagflux*10**(-wmags_/2.5) # in Jy\n",
    "    # now either interpolate flux dens to some wavelength or use a band from wise\n",
    "    wise_wavelengths = np.array([3.4, 4.6, 12., 22.]) # 1e-6 m\n",
    "    fluxdens_err = zeromagflux*10**(-wmags_err_/2.5)\n",
    "    ## interpolate - use straight line\n",
    "    wiseflux = np.polyfit(wise_wavelengths, fluxdens.value,1, w=1./fluxdens_err)\n",
    "    ## get flux at obs wavelength, i.e. just a straight line here\n",
    "    obs_flux = (wiseflux[0]*obs_wavelength_+wiseflux[1])*u.Jy \n",
    "    obs_hz = (const.c/(obs_wavelength_*u.micron)).to(u.Hz)\n",
    "    lum = (obs_flux*obs_hz*4*np.pi*\n",
    "           cosmo.luminosity_distance(redshift_)**2).to(u.erg/u.s)\n",
    "    return lum\n",
    "\n",
    "def correct_ir():\n",
    "    \"\"\"correct IR luminosity at 15 microns rest frame based on Hopkins+20\"\"\"\n",
    "    # load hopkins bolometric correction\n",
    "    with open(\"/home/insepien/research-data/pop-result/bc.txt\",\"r\") as f:\n",
    "        d = f.read().splitlines()\n",
    "    hopkins = pd.DataFrame([d[1:][i].split(' ') for i in range(len(d[1:]))],columns=d[0].split(' '))\n",
    "    Lbol = np.array(list(hopkins['Lbols'].values), dtype=float)\n",
    "    LIR = np.array(list(hopkins['LIRs'].values), dtype=float)\n",
    "    spl = CubicSpline(LIR, Lbol)\n",
    "    return spl\n",
    "\n",
    "def get_wise_ir_lums(cat,wl_=22):\n",
    "    \"\"\"calculate wise IR luminosity and bolometric lum, \n",
    "        default keys (variants of 'desig') are for magellan sample\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    wmags, wmags_err_nan = get_wise_mags(cat)\n",
    "    # replace nan values in mag error with median\n",
    "    wmags_err = np.nan_to_num(wmags_err_nan,np.median(wmags_err_nan))\n",
    "    # calculate luminosity\n",
    "    wise_lums = np.zeros((len(cat)))\n",
    "    for i in cat.index.values:\n",
    "        z = cat.loc[i,'Z']\n",
    "        wise_lums[i] = wise_lum_from_mag_rest_frame(wmags[:,i], wmags_err[:,i], wl_, z).value\n",
    "    # check wavelength to see how to do bolo correction\n",
    "    if wl_==15: # use Hopkins+2020 if at 15 microns\n",
    "        spl = correct_ir()\n",
    "        irbol = 10**(spl(np.log10(wise_lums)))\n",
    "    else: # else correct by 12%\n",
    "        irbol = wise_lums/0.1\n",
    "    return wmags, wise_lums,irbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions to interpolate 3 wise bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const\n",
    "def get_wise_mags_3band(wise_):\n",
    "    \"\"\"get wise mags and mag errors from data frame of ipac search results\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    w2mag = wise_['w2mpro']\n",
    "    w3mag = wise_['w3mpro']\n",
    "    w4mag = wise_['w4mpro']\n",
    "    wmags_ = np.array([w2mag, w3mag, w4mag])\n",
    "    wmags_err_ = np.array([wise_['w2sigmpro'], wise_['w3sigmpro'], wise_['w4sigmpro']])\n",
    "    return wmags_, wmags_err_\n",
    "\n",
    "import scipy.interpolate as intp\n",
    "def wise_lum_from_mag_rest_frame_3band_interp(wmags_, wmags_err_, rest_wavelength_, redshift_):\n",
    "    \"\"\"calculate wise luminosity from magnitude at rest-frame wavelength\"\"\"\n",
    "    ## change mags to fluxes -- http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html#example\n",
    "    obs_wavelength_ = (1 + redshift_) * rest_wavelength_\n",
    "    zeromagflux = np.array([171.787, 31.674, 8.363])*u.Jy\n",
    "    fluxdens = zeromagflux*10**(-wmags_/2.5) # in Jy\n",
    "    # now either interpolate flux dens to some wavelength or use a band from wise\n",
    "    wise_wavelengths = np.array([4.6, 12., 22.]) # 1e-6 m\n",
    "    fluxdens_err = zeromagflux*10**(-wmags_err_/2.5)\n",
    "    ## interpolate spline\n",
    "    bspl = intp.make_interp_spline(np.log10(wise_wavelengths), np.log10(fluxdens.value),k=2)\n",
    "    ## get flux at obs wavelength, i.e. just a straight line here\n",
    "    obs_flux = 10**(bspl(np.log10(obs_wavelength_)))*u.Jy \n",
    "    obs_hz = (const.c/(obs_wavelength_*u.micron)).to(u.Hz)\n",
    "    lum = (obs_flux*obs_hz*4*np.pi*\n",
    "           cosmo.luminosity_distance(redshift_)**2).to(u.erg/u.s)\n",
    "    return lum\n",
    "\n",
    "def correct_ir():\n",
    "    \"\"\"correct IR luminosity at 15 microns rest frame based on Hopkins+20\"\"\"\n",
    "    # load hopkins bolometric correction\n",
    "    with open(\"/home/insepien/research-data/pop-result/bc.txt\",\"r\") as f:\n",
    "        d = f.read().splitlines()\n",
    "    hopkins = pd.DataFrame([d[1:][i].split(' ') for i in range(len(d[1:]))],columns=d[0].split(' '))\n",
    "    Lbol = np.array(list(hopkins['Lbols'].values), dtype=float)\n",
    "    LIR = np.array(list(hopkins['LIRs'].values), dtype=float)\n",
    "    spl = CubicSpline(LIR, Lbol)\n",
    "    return spl\n",
    "\n",
    "def get_wise_ir_lums_3band_intp(cat,wl_=22):\n",
    "    \"\"\"calculate wise IR luminosity and bolometric lum, \n",
    "        default keys (variants of 'desig') are for magellan sample\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    wmags, wmags_err_nan = get_wise_mags_3band(cat)\n",
    "    # replace nan values in mag error with median\n",
    "    wmags_err = np.nan_to_num(wmags_err_nan,np.median(wmags_err_nan))\n",
    "    # calculate luminosity\n",
    "    wise_lums = np.zeros((len(cat)))\n",
    "    for i in cat.index.values:\n",
    "        z = cat.loc[i,'Z']\n",
    "        try:\n",
    "            wise_lums[i] = wise_lum_from_mag_rest_frame_3band_interp(wmags[:,i], wmags_err[:,i], wl_, z).value\n",
    "        except:\n",
    "            wise_lums[i] = 0\n",
    "            print(i)\n",
    "    # check wavelength to see how to do bolo correction\n",
    "    if wl_==15: # use Hopkins+2020 if at 15 microns\n",
    "        spl = correct_ir()\n",
    "        irbol = 10**(spl(np.log10(wise_lums)))\n",
    "    else: # else correct by 12%\n",
    "        irbol = wise_lums/0.1\n",
    "    return wmags, wise_lums,irbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmag, werr = get_wise_mags_3band(alpaka)\n",
    "def wise_lum_from_mag_rest_frame_3band_interp(wmags_, wmags_err_, rest_wavelength_, redshift_):\n",
    "    \"\"\"calculate wise luminosity from magnitude at rest-frame wavelength\"\"\"\n",
    "    ## change mags to fluxes -- http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html#example\n",
    "    obs_wavelength_ = (1 + redshift_) * rest_wavelength_\n",
    "    zeromagflux = np.array([171.787, 31.674, 8.363])*u.Jy\n",
    "    fluxdens = zeromagflux*10**(-wmags_/2.5) # in Jy\n",
    "    # now either interpolate flux dens to some wavelength or use a band from wise\n",
    "    wise_wavelengths = np.array([4.6, 12., 22.]) # 1e-6 m\n",
    "    ## interpolate spline\n",
    "    bspl = intp.make_interp_spline(np.log10(wise_wavelengths), np.log10(fluxdens.value),k=2)\n",
    "    ## get flux at obs wavelength, i.e. just a straight line here\n",
    "    obs_flux = 10**(bspl(np.log10(obs_wavelength_)))*u.Jy \n",
    "    return fluxdens.value, bspl, obs_flux.value\n",
    "\n",
    "errind = []\n",
    "res = []\n",
    "for i in alpaka.index.values:\n",
    "    z = alpaka.loc[i,'Z']\n",
    "    try:\n",
    "        res.append(wise_lum_from_mag_rest_frame_3band_interp(wmag[:,i], werr[:,i], 15, z))\n",
    "    except:\n",
    "        res.append([0,0,0])\n",
    "        errind.append(i)\n",
    "\n",
    "spl = [r[1] for r in res]\n",
    "flxd = [r[0] for r in res]\n",
    "obsflx = [r[2] for r in res]\n",
    "obswl = [(1+z)*15 for z in alpaka['Z'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwl = np.array([4.6, 12., 22.])\n",
    "wwl_fine = np.linspace(wwl.min(),wwl.max(),20)\n",
    "fig,ax = plt.subplots(1,5,figsize=(12,2))\n",
    "for i in range(5):\n",
    "    ax[i].scatter(np.log10(wwl),np.log10(flxd[i]))\n",
    "    ax[i].plot(np.log10(wwl_fine), spl[i](np.log10(wwl_fine)))\n",
    "    ax[i].scatter(np.log10(obswl[i]),np.log10(obsflx[i]))\n",
    "    ax[i].set_ylabel(\"log flx dens\")\n",
    "    ax[i].set_xlabel(\"log wlen\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate luminosity of whole alpaka here and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear fit flxds\n",
    "wmags15, wise_lums15,irbol15 = get_wise_ir_lums(alpaka,15)\n",
    "wmags22, wise_lums22,irbol22 = get_wise_ir_lums(alpaka,22)\n",
    "# 2nd order interpolate\n",
    "wmags15_3b, wise_lums15_3b,irbol15_3b = get_wise_ir_lums_3band_intp(alpaka,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nu L_{\\nu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(wise_lums15_3b)[j1010mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obshz = (const.c/obswl/u.micron).to(u.Hz)\n",
    "emhz = (const.c/15/u.micron).to(u.Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmask = alpaka['Z']<0.2\n",
    "plt.scatter(alpaka['OIII_5007_LUM'][zmask],wise_lums15_3b[zmask],label='rest15,spline',s=1)\n",
    "# plt.scatter(alpaka['OIII_5007_LUM'][zmask],wise_lums15[zmask],label='linear',s=1,alpha=0.5)\n",
    "# plt.scatter(alpaka['OIII_5007_LUM'][zmask],alpaka['wiseLum'][zmask],label='observed',s=1,alpha=0.5)\n",
    "plt.plot([1e40,2e43],[3.5e42,1e46])\n",
    "plt.axvline(1.5e41)\n",
    "plt.axhline(5e43)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlim(1e40,2e43)\n",
    "plt.ylim(1e42,1e46)\n",
    "plt.xlabel(\"L[OIII]\")\n",
    "plt.ylabel(\"Wise $\\\\nu L_{\\\\nu}$ (rest frame)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snap stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notObserved = ~ alpaka['Desig'].isin(['J1000+1242', 'J1010+1413','J1352+6541', 'J1356+1026','J1222-0007'])\n",
    "snap = (np.log10(alpaka['irbol'])>45.9) & notObserved\n",
    "snapminrest = irbol15_3b >= irbol15_3b[snap].min()\n",
    "newL = 45.769\n",
    "newcut = (np.log10(irbol15_3b) >= newL) & notObserved\n",
    "\n",
    "(newcut & snap).sum(), newcut.sum(), lbol_to_m(10**newL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(44,48),np.arange(44,48),c='k',alpha=0.5)\n",
    "plt.scatter(np.log10(irbol15_3b), np.log10(alpaka['irbol']),label='all type-2')\n",
    "plt.scatter(np.log10(irbol15_3b)[snap], np.log10(alpaka['irbol'])[snap],label='SNAP 146')\n",
    "plt.ylim(45.5,47)\n",
    "plt.xlim(45.5,47)\n",
    "plt.axvline(45.8,label=f'new cut $L>${newL},\\nMbh $>${lbol_to_m(10**newL):.3f},\\n{(newcut & snap).sum()}/146 in snap')\n",
    "plt.axvline(np.log10(irbol15_3b[snap].min()),c='r',label='SNAP old min',alpha=0.5)\n",
    "plt.xlabel(\"Log rest frame 15, spline\")\n",
    "plt.ylabel('Log observed 22')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross-match with Big MAC for paper intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some stats on sub-kpc pairs for science justification\n",
    "not_recoil = bigmac['Primary System Type']!='Recoil Candidate'\n",
    "subkpc_mask = not_recoil & (bigmac['Sep(kpc)']<1) & (bigmac['Sep(kpc)']>0.3)\n",
    "kpc_mask = not_recoil & (bigmac['Sep(kpc)']>1)\n",
    "dual_mask = subkpc_mask | kpc_mask\n",
    "confirmed_mask = dual_mask & ~bigmac[\"Primary System Type\"].str.contains(\"Candidate\")\n",
    "\n",
    "# fractions\n",
    "print(f\"fraction of sub-kpc/total dual = {subkpc_mask.sum()}/{dual_mask.sum()} = {subkpc_mask.sum()/dual_mask.sum():.3f}\")\n",
    "print(f\"fraction of confirmed/total dual = {confirmed_mask.sum()/dual_mask.sum():.3f}\")\n",
    "\n",
    "# get some methods of measuring sub-kpc sep\n",
    "anyl_meth = Counter(bigmac[subkpc_mask]['Parsed Analysis Method'])\n",
    "print(\"1st most common method: \",anyl_meth.most_common(2)[0])\n",
    "print(\"2nd most common method: \",anyl_meth.most_common(2)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check airmass and coords stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroplan import Observer, FixedTarget\n",
    "from astropy.time import Time\n",
    "\n",
    "twi_end = Time('2020-02-08 0:48:00') ## local time 21:48\n",
    "twi_beg = Time('2020-02-08 9:06:00') ## local time 6:06\n",
    "start = twi_end\n",
    "end = twi_beg\n",
    "magellan = Observer.at_site(\"Las Campanas Observatory\")\n",
    "d = alpaka[mask171]\n",
    "targets = FixedTarget(coord=SkyCoord(d['RA'].values*u.deg,d['DEC'].values*u.deg))\n",
    "time_window = start + (end-start)*np.linspace(0,1,len(d))\n",
    "is_up = magellan.target_is_up(time_window,targets)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "ax[0].scatter(d[is_up]['RA'],d[is_up]['DEC'],label=f'{np.sum(is_up)}/{len(d)}\\n up at magellan')\n",
    "ax[0].scatter(magel['RA'],magel['DEC'], label='39 observed')\n",
    "ax[0].axhline(30)\n",
    "ax[0].set_xlabel(\"RA\")\n",
    "ax[0].set_ylabel(\"DEC\")\n",
    "ax[0].legend()\n",
    "\n",
    "airmass_time_window = start + (end-start)*np.linspace(0,1,10)\n",
    "dec = np.array([30,50,60])\n",
    "coords = SkyCoord(200*u.deg,dec*u.deg)\n",
    "pos = [magellan.altaz(airmass_time_window, SkyCoord(200*u.deg,d*u.deg)) for d in dec]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.plot(pos[i].alt, label=f\"DEC = {dec[i]} deg\")\n",
    "ax[1].axhline(0,alpha=0.5)\n",
    "ax[1].set_xlabel(\"$\\\\approx$ time\")\n",
    "ax[1].set_ylabel(\"Altitude\")\n",
    "ax[1].legend()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample plot of IR only for methods section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_hist(ax,quant,ecolor,fcolor,bin_arr=[],alpha=1,horz=False,hatchsym=''):\n",
    "    \"\"\"normalize histogram sum count to 1 given some quantity (quant)\n",
    "        args: edgecoloe, facecolor, bin array, opacity, flag for plotting horizontal hist\"\"\"\n",
    "    count, bin = np.histogram(quant,bins=bin_arr)\n",
    "    if horz:\n",
    "        ax.barh(bin[:-1],count/np.sum(count), height= np.diff(bin),\n",
    "                align='edge',edgecolor=ecolor,facecolor=fcolor,alpha=alpha,hatch=hatchsym,hatch_linewidth=0.5)\n",
    "    else:\n",
    "        ax.bar(bin[:-1],count/np.sum(count),width = np.diff(bin),\n",
    "               align='edge',edgecolor=ecolor,facecolor=fcolor,alpha=alpha,hatch=hatchsym,hatch_linewidth=0.5)\n",
    "        \n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(2,2,gridspec_kw={'width_ratios': [2,0.5],'height_ratios': [0.7,2]},figsize=(8,6),\n",
    "                      sharey='row',sharex='col',dpi=200)\n",
    "plt.subplots_adjust(wspace=0.05,hspace=0.05)\n",
    "\n",
    "mdual_labs = ['J1215+1344','J1222-0007 W', 'J1222-0007 E']\n",
    "\n",
    "# scatter type-2 in z=0.1-0.5 with match in wise\n",
    "ax[1,0].scatter(alpaka['Z'],np.log10(alpaka['irbol']),s=2,alpha=0.1,color=\"plum\")\n",
    "# same as above but Lbol OIII > 1e46\n",
    "ax[1,0].scatter(alpaka['Z'][mask171],np.log10(alpaka['irbol'][mask171]),s=7,color=\"darkseagreen\",marker=\"x\")\n",
    "# magellan sample\n",
    "ax[1,0].scatter(singles['Z'],np.log10(singles['irbol']),s=50,marker='2',color='indigo',alpha=0.7)\n",
    "[ax[1,0].scatter(duals['Z'].values[i],np.log10(duals['irbol'].values[i]),\n",
    "                 s=40,marker=['s',\"\",'o'][i],color='indigo',alpha=0.7,label=mdual_labs[i]) for i in [0,2]];\n",
    "\n",
    "ax[1,0].set_ylim(43.5,47.5)\n",
    "ax[1,0].set_xlim(0.09,0.3)\n",
    "ax[1,0].set_xlabel(\"Redshift\")\n",
    "ax[1,0].set_ylabel('Log($L_{\\\\rm{bol,~IR}}$) $[\\\\rm{erg~s}^-1]$')\n",
    "ax[1,0].legend(fontsize=10) \n",
    "\n",
    "# hist z\n",
    "binz = np.linspace(np.min(alpaka['Z']),np.max(alpaka['Z']),20)\n",
    "norm_hist(ax[0,0],alpaka['Z'],\"plum\",'none',bin_arr=binz)\n",
    "norm_hist(ax[0,0],alpaka['Z'][mask171],\"darkseagreen\",'none',bin_arr=binz,hatchsym=\"/\")\n",
    "norm_hist(ax[0,0],np.concatenate([singles['Z'],duals['Z']]),'none','indigo',bin_arr=binz,alpha=0.5)\n",
    "ax[0,0].set_ylabel(\"Fraction\")\n",
    "\n",
    "# hist Lbol\n",
    "binL = np.linspace(np.log10(np.min(alpaka['irbol'])), np.log10(np.max(alpaka['irbol'])),10)\n",
    "norm_hist(ax[1,1],np.log10(alpaka['irbol'].dropna()),'plum',\"none\",binL,horz=True)\n",
    "norm_hist(ax[1,1],np.log10(alpaka['irbol'].dropna()[mask171]),'darkseagreen',\"none\",binL,horz=True,hatchsym=\"/\")\n",
    "norm_hist(ax[1,1],np.log10(np.concatenate([singles['irbol'],duals['irbol']])),'none','indigo',binL,alpha=0.5,horz=True)\n",
    "ax_top = ax[1,1].secondary_xaxis(\"top\")\n",
    "ax_top.set_xlabel(\"Fraction\")\n",
    "ax_top.set_xticks([0,0.2])\n",
    "ax_top.set_xticklabels([0,0.2])\n",
    "ax[1,1].set_xticks([])\n",
    "\n",
    "ax[0,1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12,4),sharey=True,sharex=True,dpi=500)\n",
    "ax[0].scatter(alpaka['Z'],np.log10(alpaka['OIII_5007_LUM_DERRED']*800),s=2,alpha=0.1,color='plum')\n",
    "ax[0].scatter(magel['Z'],np.log10(magel['OIII_5007_LUM_DERRED']*800),s=50,alpha=0.5,marker=\"2\",color='indigo')\n",
    "mdual_labs = ['J1215+1344','J1222-0007 W', 'J1222-0007 E']\n",
    "[ax[0].scatter(duals['Z'].values[i],np.log10(duals['OIII_5007_LUM_DERRED'].values*800)[i],s=40,marker=['s','o',\"^\"][i],color='indigo',alpha=0.5,label=mdual_labs[i]) for i in range(3)];\n",
    "\n",
    "ax[1].scatter(alpaka['Z'],np.log10(alpaka['irbol']),s=2,alpha=0.1,color='plum')\n",
    "ax[1].scatter(singles['Z'],np.log10(singles['irbol']),s=50,marker='2',color='indigo',alpha=0.5)\n",
    "[ax[1].scatter(duals['Z'].values[i],np.log10(duals['irbol'].values)[i],s=40,marker=['s','o','^'][i],color='indigo',alpha=0.5,label=[mdual_labs[0],\"\",mdual_labs[2]][i]) for i in [0,2]];\n",
    "\n",
    "ax[0].scatter(alpaka[j1010mask]['Z'],np.log10(alpaka[j1010mask]['OIII_5007_LUM_DERRED']*800),marker=\"x\",color=\"k\",label='J1010+1413')\n",
    "ax[1].scatter(alpaka[j1010mask]['Z'],np.log10(alpaka[j1010mask]['irbol']),marker=\"x\",color=\"k\",label='J1010+1413')\n",
    "\n",
    "ax[0].set_ylim(43,48)\n",
    "ax[0].set_xlim(0.09,0.3)\n",
    "[a.set_xlabel(\"Redshift\") for a in ax]\n",
    "[ax[i].set_ylabel(['Log($L_{\\\\rm{bol,~[OIII]~dered}}$) $[\\\\rm{erg~s}^-1]$','Log($L_{\\\\rm{bol,~IR}}$) $[\\\\rm{erg~s}^-1]$'][i]) for i in range(2)]\n",
    "[ax[i].legend(fontsize=10) for i in range(2)]\n",
    "[ax[i].text(0.025, 0.975, [\"[OIII]\",\"IR\"][i], transform=ax[i].transAxes, ha='left', va='top',fontsize=20) for i in range(2)]\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check emission line luminosities: J1010 is dimmer than rest of sample based on OIII dereddened, but is brighter than the rest in SDSS R-band. R-band covers OIII and HB, so it should be OIII dominated. Therefore OIII dereddened measurments do not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check emission lines\n",
    "j10 = alpaka[alpaka['Desig'] == \"J1010+1413\"]\n",
    "keys = ['HB_LUM',\n",
    " 'OIII_4959_LUM',\n",
    " 'OIII_5007_LUM',\n",
    " 'NII_6548_LUM',\n",
    " 'HA_LUM',\n",
    " 'NII_6584_LUM',\n",
    " 'NVS_LUM']\n",
    "i=0\n",
    "clr = sns.color_palette(\"colorblind\", len(keys))\n",
    "for k in keys:\n",
    "    lums = [m for m in magel[k] if np.isfinite(m) and m!=0]\n",
    "    plt.hist(np.log10(lums),color=clr[i],alpha=0.7,label=k)\n",
    "    try:\n",
    "        plt.axvline(np.log10(j10[k].values),c=clr[i])\n",
    "    except:\n",
    "        print(k)\n",
    "    i+=1\n",
    "plt.xlim((37.5,43.5))\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.title(\"J1010 is generally brighter than magellan sample\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code below to make dual sep vs redshift plot (used for hst phase 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as patches\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('colorblind')\n",
    "figparams = {'font.family': 'DejaVu Sans',\n",
    "            'font.serif':'Times',\n",
    "            'hatch.linewidth' : 3.0}\n",
    "plt.rcParams.update(figparams)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(15,7),dpi=500)\n",
    "# plot hst resolution limit\n",
    "for reso in [1,5,20]:\n",
    "    seeing = 0.04*2.5*reso\n",
    "    ax.plot(np.linspace(0,3),cal_sep(seeing, np.linspace(0,3)),c='k',linestyle=\"--\",alpha=0.5)\n",
    "    ax.text(2.5, 1*reso, f\"{seeing:.1f} arcsec\", color='k',fontsize=15)\n",
    "\n",
    "# add survey vol\n",
    "# rect = patches.Rectangle((0.1, 0), 0.4-0.1, 1, linewidth=2, edgecolor='w', facecolor='darkseagreen',alpha=0.3)\n",
    "# ax.add_patch(rect)\n",
    "# ax.text(0.2,1,\"Our survey\",c=\"darkolivegreen\",fontsize=15)\n",
    "\n",
    "# kpc points ie sep>1 with confidence>0.5, z0-3, have been imaged\n",
    "conf_kpc = dual['ST1 Confidence Flag']>=0.5\n",
    "imag_kpc = dual['Parsed Analysis Method'].str.contains(\"Imaging\")\n",
    "z_mask = (dual['z1']>0)&(dual['z1']<3)\n",
    "kpcdf = dual[conf_kpc&imag_kpc&z_mask]\n",
    "paper = list(kpcdf['Paper(s)'].str.split(\" ; \").explode().value_counts().keys())[:15]\n",
    "all_markers = list(Line2D.markers.keys())[5:]\n",
    "all_colors = sns.color_palette(\"colorblind\", len(paper))\n",
    "for j in range(len(paper)):    \n",
    "    papermask = np.array([np.isin(paper[j],kpcdf.loc[i,'Paper(s)'].split(\" ; \")).item() for i in kpcdf.index.values])\n",
    "    for k in kpcdf[papermask].index.values:\n",
    "        ulabel = paper[j] if k==kpcdf[papermask].index.values[0] else None\n",
    "        plt.scatter(kpcdf[papermask]['z1'][k],kpcdf[papermask]['Sep(kpc)'][k],marker=all_markers[j],c=all_colors[j],s=30,label=ulabel)\n",
    "\n",
    "# plot points with confidence >0.5 and have been imaged\n",
    "confidence_mask = subkpc_dual['ST1 Confidence Flag']>=0.5\n",
    "imaging_mask  = subkpc_dual['Parsed Analysis Method'].str.contains(\"Imaging\")\n",
    "distance_mask = subkpc_dual['Sep(kpc)']>0.2  # to remove radio sources\n",
    "df = subkpc_dual[confidence_mask&imaging_mask&distance_mask]\n",
    "lagn = np.log10([0.033e44,0.135e44,3e44,10**43.23*600,6e46])\n",
    "subkpc_markers = list(Line2D.markers.keys())[1:6]\n",
    "for i,m,mrk in zip(df.index.to_list(),lagn,subkpc_markers): # mark confirmed and very sure candidates differently\n",
    "    wrapped_label = \"\\n\".join(textwrap.wrap(df['Paper(s)'][i], width=60))\n",
    "    sca = ax.scatter(df['z1'][i], df['Sep(kpc)'][i],label=wrapped_label,s=30,cmap='magma',c=m,marker=mrk,vmin=np.min(lagn)-0.5,vmax=np.max(lagn)+1)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.99, 0.125, 0.01, 0.75]) \n",
    "cbar = fig.colorbar(sca,cax=cbar_ax)\n",
    "cbar.set_label(\"Log($L_{AGN}$) [erg/s]\")\n",
    "\n",
    "ax.set_xlabel(\"Redshift\")\n",
    "ax.set_ylabel(\"Projected separation [kpc]\")\n",
    "ax.set_xlim((-0.01,3))\n",
    "ax.set_ylim((0.2,110))\n",
    "# set top xlabel to look back time\n",
    "ax_top = ax.secondary_xaxis(\"top\")\n",
    "ax_top.set_xlabel(\"Lookback time [Gyr]\")\n",
    "# interpolate to get tick positions for round lookback time\n",
    "spl = CubicSpline(cosmo.lookback_time(np.linspace(0,0.5)),np.linspace(0,0.5))\n",
    "xtick_pos = spl(np.arange(1,12,2))\n",
    "ax_top.set_xticks(xtick_pos)\n",
    "ax_top.set_xticklabels(np.arange(1,12,2))\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(ncol=3,fontsize=8,loc='lower center')\n",
    "ax.grid(linestyle='--',alpha=0.5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"hst.png\",dpi=500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare OIII and IR for JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_sdss152 = pd.read_pickle(\"/home/insepien/research-data/alpaka/snap/hstP2_snap151_alpakaWithSDSS.pkl\")\n",
    "# remove 4 observed targets\n",
    "observed_mask = hst_sdss152['Desig'].isin(['J1000+1242', 'J1010+1413','J1352+6541', 'J1356+1026','J1222-0007'])\n",
    "hst_sdss148 = hst_sdss152[~observed_mask]\n",
    "hst_sdss148.reset_index(inplace=True,drop=True)\n",
    "print(f\"final sample shape: {hst_sdss148.shape}\")\n",
    "snap_mask = (alpaka['RA'].isin(hst_sdss148['RA'])) & (alpaka['DEC'].isin(hst_sdss148['DEC']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4),sharex=True,dpi=300)\n",
    "zm = alpaka['Z'] < 0.2\n",
    "ax[0].scatter(alpaka['OIII_5007_LUM'], alpaka['wiseLum'],s=2,alpha=0.1,color='grey')\n",
    "ax[1].scatter(alpaka['OIII_5007_LUM_DERRED'] ,alpaka['wiseLum'],s=2,alpha=0.1,color='grey')\n",
    "\n",
    "#magellan\n",
    "ax[0].scatter(magel['OIII_5007_LUM'], magel['wiseLum'],s=5,color='b',marker='x',label='Magellan')\n",
    "ax[1].scatter(magel['OIII_5007_LUM_DERRED'] ,magel['wiseLum'],s=5,color='b',marker='x')\n",
    "\n",
    "# snap\n",
    "ax[0].scatter(alpaka['OIII_5007_LUM'][snap_mask], alpaka['wiseLum'][snap_mask],s=2,alpha=0.5,color='green',label='SNAP')\n",
    "ax[1].scatter(alpaka['OIII_5007_LUM_DERRED'][snap_mask],alpaka['wiseLum'][snap_mask],s=2,alpha=0.5,color='green')\n",
    "\n",
    "# j1010\n",
    "# j1010mask = alpaka['Desig'] == \"J1010+1413\"\n",
    "# j1000mask  = alpaka['Desig'] == \"J1000+1242\"\n",
    "# [ax[0].scatter(alpaka['OIII_5007_LUM'][jmask], alpaka['wiseLum'][jmask],s=10,alpha=0.5,color='red',marker='x') for jmask in [j1000mask,j1010mask]]\n",
    "\n",
    "[a.set_xscale('log') for a in ax]\n",
    "[a.set_yscale('log') for a in ax]\n",
    "[a.set_ylabel(\"$L_{\\\\rm{IR}}$\") for a in ax]\n",
    "[a.set_xlabel(lab) for a,lab in zip(ax,['$L_{\\\\rm{[OIII]}}$','$L_{\\\\rm{[OIII],dered}}$'])]\n",
    "[a.set_xlim(1e40,1e44) for a in ax]\n",
    "[a.set_ylim(3e42,1e46) for a in ax]\n",
    "ax[0].legend(fontsize=10,loc='lower right')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try resampling to correct incomplete lum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all type 2 agn in z cut from mul with match in wise\n",
    "type2 = alpaka[(alpaka['Z'] > 0.14) & (alpaka['Z'] < 0.22) & (alpaka['AGN_TYPE']==2)]\n",
    "magel_withwise = type2[type2['desig'].isin(magel['desig'])]\n",
    "# get histograms, using sqrt smaller sample as numbers of bin\n",
    "lbol_all = np.log10(type2['irbol'])\n",
    "bin = np.linspace(lbol_all.min(),lbol_all.max(),int(np.ceil(np.sqrt(39))))\n",
    "hist_ful = plt.hist(lbol_all,label=\"mullaney type-2 agn \\nmatched with WISE\",bins=bin)\n",
    "hist_magel = plt.hist(np.log10(np.concatenate([irbol,irbol_dual])),label='Magellan sample',bins=bin)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Log(L_bol)')\n",
    "plt.ylabel(\"number of AGN\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate pdf for pretty plotting\n",
    "binmid = (bin[:-1]+bin[1:])*0.5\n",
    "pdf_full = CubicSpline(binmid,hist_ful[0])\n",
    "pdf_magel = CubicSpline(binmid,hist_magel[0])\n",
    "# use full sample pdf as weight\n",
    "w = hist_ful[0]/np.sum(hist_ful[0])\n",
    "# assign weight to each magel target\n",
    "binnum = np.digitize(np.log10(magel_withwise['irbol']),bin)-1\n",
    "weights = [w[b] for b in binnum]\n",
    "magel_withwise['weights'] = weights\n",
    "# sample magel with weights\n",
    "new_sample_size = 20\n",
    "magel_sub = [magel_withwise.sample(n=new_sample_size,weights='weights') for i in range(1000)]\n",
    "pdfs_magel = [np.histogram(np.log10(magel_sub[i]['irbol']),bins=bin)[0] for i in range(1000)]\n",
    "# random sample from full sample\n",
    "pdfs = [np.histogram(np.log10(type2.sample(n=new_sample_size)['irbol']),bins=bin)[0] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxind = np.argmax(hist_magel[0])\n",
    "magel_corrected = w/w[maxind]*hist_magel[0]\n",
    "magel_corrected_spl = CubicSpline(binmid,magel_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty plot\n",
    "x = np.linspace(binmid.min(),binmid.max(),20)\n",
    "# plot full sample\n",
    "plt.plot(x,pdf_full(x),c='b')\n",
    "plt.scatter(binmid,hist_ful[0],c='b',label='full sample')\n",
    "# plot magellan sample\n",
    "plt.scatter(binmid,hist_magel[0],label='magel',c='r')\n",
    "plt.plot(x,pdf_magel(x),c='r')\n",
    "# correct by largest bin\n",
    "plt.scatter(binmid,magel_corrected,c=\"g\",label='corrected')\n",
    "plt.plot(x,magel_corrected_spl(x),c='g')\n",
    "# plot subsamples\n",
    "[plt.plot(binmid, pdfs_magel[i],c='r',alpha=0.01) for i in range(500)];\n",
    "[plt.plot(binmid, pdfs[i],c='b',alpha=0.01) for i in range(500)];\n",
    "\n",
    "plt.plot(binmid[maxind], magel_corrected[maxind],c=\"r\",marker=\"*\",markersize=20)\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Log(L_bol)')\n",
    "plt.ylabel(\"number of AGN\")\n",
    "plt.legend(bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### malmquist correction\n",
    "tried volume limited sample but our sample is already very bright, so doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "mlim = 22.2 # r-band\n",
    "sdss = pd.read_pickle(\"/home/insepien/research-data/alpaka/sdss-cat/sdss_rband_171.pkl\")\n",
    "sdss40 = sdss[sdss['DESIG'].isin(mul['desig'])]\n",
    "sdss40['r-mag'] = 22.5 - 2.5 * np.log10(sdss40['spectroFlux_r'])\n",
    "sdss40 = pd.merge(sdss40,mul.rename(columns={'desig':'DESIG'})[['Z','DESIG']],on='DESIG')\n",
    "sdss40['M'] = sdss40['r-mag']-5*np.log10((cosmo.angular_diameter_distance(sdss40['Z'])*u.Mpc/(10*u.pc).to(u.Mpc)))\n",
    "\n",
    "Mlim = -16.5\n",
    "mask = sdss40['M'] < Mlim\n",
    "dmax = (10**((mlim-Mlim)/5)*10*u.pc).to(u.Mpc)\n",
    "from scipy.interpolate import CubicSpline\n",
    "spl = CubicSpline(cosmo.angular_diameter_distance(np.linspace(0,1,20)), np.linspace(0,1,20))\n",
    "zmax = spl(dmax.value)\n",
    "zmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make table of dual fraction from literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv(\"/home/insepien/research-data/pop-result/lit_rev_frac/dualfrac_rev2.csv\")\n",
    "dfr_agn = dfr[~ dfr['lower dual frac'].isna()]\n",
    "errs = []\n",
    "not_nan_ind = dfr_agn['lower dual frac error'].dropna().index.values\n",
    "nan_ind = dfr_agn.index[~ np.isin(dfr_agn.index,dfr_agn['lower dual frac error'].dropna().index.values)]\n",
    "for i in range(len(dfr_agn)):\n",
    "    if i in not_nan_ind:\n",
    "        try:\n",
    "            errs.append(np.abs(dfr_agn['lower dual frac'][i]-sorted(np.array(dfr_agn['lower dual frac error'][i].split(','),dtype=float))))\n",
    "        except:\n",
    "                print(i)\n",
    "    else:\n",
    "         errs.append(np.array([np.nan,np.nan]))\n",
    "errs = pd.DataFrame(errs)\n",
    "\n",
    "fmt = lambda minv, maxv: f\"${minv:.0f}-{maxv:.0f}$\"\n",
    "fmt2 = lambda minv, maxv: f\"${minv:.2f}-{maxv:.2f}$\"\n",
    "fmt_err = lambda val, low_err, up_err: f\"${val:.3f}^{{-{low_err:.4f}}}_{{+{up_err:.4f}}}$\"\n",
    "fmt_lbol = lambda min,max : f\"$10^{{{min:.0f}}}-10^{{{max:.0f}}}$\"\n",
    "\n",
    "\n",
    "redshift = [fmt2(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['min z'],dfr_agn['max z'])]\n",
    "sep = [fmt(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['Min sep'],dfr_agn['Max sep'])]\n",
    "lbols = [fmt_lbol(minvl,maxvl) for minvl,maxvl in zip(dfr_agn['min Lbol'],dfr_agn['max Lbol'])]\n",
    "fracs = [fmt_err(val,errl,erru) for val,errl,erru in zip(dfr_agn['lower dual frac'],errs[0],errs[1])]\n",
    "\n",
    "keys = ['Paper Name', 'Red shift', 'Separation $[kpc]$', \"$L_{bol}~[erg~s^{-1}$]\", \"Selection method\", \"Dual fraction\", \"Fraction definition\"]\n",
    "tabb=pd.DataFrame([list(dfr_agn['Paper']),redshift,sep,lbols,list(dfr_agn['selection']),fracs,list(dfr_agn['note'])],index=keys).T.to_latex(column_format='c|c|c|c|c|c',index=False)\n",
    "print(tabb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volonteri22(plot=False):\n",
    "    # load CDF frac at z~0 (tried to get z~0.15 but hard to get accurate values from plot digitizer)\n",
    "    v = pd.read_csv('/home/insepien/research-data/pop-result/fvL/volonteri22.csv',names=['z','logN'])\n",
    "    frac_cdf = 10**(np.array([v.loc[i,'logN']-v.loc[i-1,'logN'] for i in [1,3,5]]))\n",
    "    x = np.array([42,43,44])\n",
    "    # interpolate the cdf frac for better precision when taking gradient\n",
    "    cdf_spl = CubicSpline(x,frac_cdf)\n",
    "    xfine = np.linspace(42,44,100)\n",
    "    fracfine_cdf = cdf_spl(xfine)\n",
    "    # take gradient of cdf to get pdf\n",
    "    fracfine_pdf = np.gradient(fracfine_cdf,xfine)\n",
    "\n",
    "    # plot\n",
    "    if plot:\n",
    "        fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "        ax[0].plot(xfine,fracfine_cdf,label='Volonteri+22')\n",
    "        ax[0].plot(x,frac_cdf)\n",
    "        ax[0].set_xlabel(\"Log(Lbol) [erg/s]\")\n",
    "        ax[0].set_ylabel(\"dual frac ($>$Lbol)\")\n",
    "        ax[1].plot(xfine,fracfine_pdf)\n",
    "        ax[1].set_xlabel(\"Log(Lbol) [erg/s]\")\n",
    "        ax[1].set_ylabel(\"dual frac\")\n",
    "        fig.suptitle(\"Convert dual frac CDF to PDF in Volonteri+22\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "    return xfine,fracfine_pdf\n",
    "\n",
    "\n",
    "def fu12(plot=False):\n",
    "    # load and clean df\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/fu2012.txt\",\"r\") as f:\n",
    "        fu = f.readlines()\n",
    "    fu = [dd.split(\"\\t\")[:-1] for dd in fu]\n",
    "    dfu = pd.DataFrame(fu[3:],columns=fu[0])\n",
    "    dfu.drop(index=[0,3,25],inplace=True)\n",
    "    # get z<0.2 subsample and calculate Lbol= L+oiii total * 3500\n",
    "    zlim = 0.4\n",
    "    dfz2 = dfu.copy()[dfu['z'].astype(float)<zlim]\n",
    "    dfz2.reset_index(inplace=True, drop=True)\n",
    "    dfz2['Lbol'] = np.log10(3500*(10**dfz2['L_oiiib'].astype(float) + 10**dfz2['L_oiiir'].astype(float)))+33\n",
    "    # load merger data for frac cal\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/fu12merger.txt\",\"r\") as f:\n",
    "        merger = f.readlines()\n",
    "    merger = [dd.split(\"\\t\")[:-1] for dd in merger]\n",
    "    mergerdf = pd.DataFrame(merger[1:],columns=merger[0])\n",
    "    mergernames = mergerdf['SDSS Name'].values\n",
    "    mergermask = dfz2['SDSS Name'].isin(mergernames)\n",
    "    # get counts in Lbol bins and plot fraction\n",
    "    binz = np.linspace(dfz2['Lbol'].min(),dfz2['Lbol'].max(),int(np.sqrt(len(dfz2['Lbol']))))\n",
    "    count_merger, _ = np.histogram(dfz2['Lbol'][mergermask],bins=binz)\n",
    "    sebin_mask  = dfz2['SDSS Name'].isin(['124037.8+353437','115106.7+471158*'])\n",
    "    dpbin_mask = dfz2['SDSS Name'].isin(['095207.6+255257*', '150243.1+111557*'])\n",
    "    count_dpbin,_ = np.histogram(dfz2['Lbol'][dpbin_mask].values,bins=binz)\n",
    "    count_sebin,_ = np.histogram(dfz2['Lbol'][sebin_mask].values,bins=binz)\n",
    "    binfrac = count_dpbin/count_merger * 29/100 *1/100 + count_sebin/count_merger * 29/100\n",
    "    midbin = binz[:-1]+np.diff(binz)/2\n",
    "    if plot:\n",
    "        plt.scatter(midbin, binfrac)\n",
    "        plt.xlabel(\"Lbol\")\n",
    "        plt.ylabel(f\"binary/ SDSS AGN ($z<{zlim}$)\")\n",
    "        plt.title(\"Infer fraction from data table in Fu+2012 (dpeak)\")\n",
    "    return midbin, binfrac\n",
    "\n",
    "def imanishi():\n",
    "    \"\"\"note that this combines samples from Imanishi+13 and +20 but excludes LIRG, which has Lir<12\n",
    "        also, the number of bins is set to 4, since the Lbol range is small compared to number of data points\"\"\"\n",
    "    # open and clean data\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/imanishi2013.txt\",\"r\") as f:\n",
    "        iman = f.readlines()\n",
    "    iman13 = [i.strip().split('\\t') for i in iman]\n",
    "    imandf13 = pd.DataFrame(iman13[3:],columns=iman13[0])\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/imanishi20.txt\",\"r\") as f:\n",
    "            iman = f.readlines()\n",
    "    iman20 = [i.strip().split('\\t') for i in iman]\n",
    "    imandf20 = pd.DataFrame(iman20[3:],columns=iman20[0])\n",
    "    mergeddf = pd.concat([imandf13[['Object','log L_IR']],imandf20[['Object','log L_IR']]])\n",
    "    ulirg_mask = (mergeddf['log L_IR'].astype(float) >= 12)\n",
    "    uldf = mergeddf[ulirg_mask]\n",
    "    # assume Lir/Lbol = 0.12\n",
    "    imanLbol = np.log10(10**(uldf['log L_IR'].astype(float).values+33)/0.12)\n",
    "    # separate 4(2013)+2(2020) duals\n",
    "    duals_iman = ['Mrk 273', 'Arp 220', '16474', 'NGC 6240', \"12072\", \"12112\"]\n",
    "    dual_lbol = []\n",
    "    for d in duals_iman:\n",
    "        dual_mask = uldf['Object'].str.contains(d)\n",
    "        try:\n",
    "            dual_lbol.append(imanLbol[dual_mask][0])\n",
    "        except:\n",
    "            pass\n",
    "    # make histogram stats\n",
    "    imanbins = np.linspace(imanLbol.min(),imanLbol.max(), 4)\n",
    "    imanBinMid  = imanbins[1:]-np.diff(imanbins)/2\n",
    "    c_all, _ = np.histogram(imanLbol,bins = imanbins)\n",
    "    c_dual, _ = np.histogram(dual_lbol,bins=imanbins)\n",
    "    return imanBinMid, c_dual/c_all\n",
    "\n",
    "def load_gross(fn):\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/\"+fn,\"r\") as f:\n",
    "        dd = f.readlines()\n",
    "    data = [d.strip().split('\\t') for d in dd]\n",
    "    df = pd.DataFrame(data[3:], columns=data[0])\n",
    "    return df\n",
    "\n",
    "def gross23():\n",
    "    # 17 kinematic pairs radio obs, this is technically the final sample, since they use high-res 6Ghz imaging to determin duals\n",
    "    # paper says there are 6 duals, listed as 12 rows, plus 11 singles, so the final table should have 23 rows. but 1 pair 22522 is not dAGN but listed as 2 rows --> 24 rows\n",
    "    gradio = load_gross(\"gross23radio.txt\")\n",
    "    # 21 kinematic radio gal pairs oiii, not observing 4 sources in radio due to low snr\n",
    "    goiii = load_gross(\"gross23oiii.txt\")\n",
    "    # 21 kinematic pairs redshift to infer jet lum\n",
    "    gz = load_gross(\"gross23z.txt\")\n",
    "    # merge kinematic pairs df (manually changed 1 name in txt file)\n",
    "    kpairs = gz.merge(goiii, on='Optical ID')\n",
    "    # make unique name since desig varies among tables....\n",
    "    kpairs['name'] = [kpairs.loc[i,'Optical ID'][:5] for i in range(len(kpairs))]\n",
    "    # remove 3 pairs without full OIII meas\n",
    "    pair_no_oiii = kpairs[(kpairs['L _[O III]'] == 'cdots')]['name']\n",
    "    kpairs_36_withoiii = kpairs.copy()[~ kpairs['name'].isin(pair_no_oiii)]\n",
    "    kpairs_36_withoiii.reset_index(inplace=True, drop=True)\n",
    "    # get total L_oiii and average redshift of 18 kinematic pairs with oiii meas.\n",
    "    loiii_tot = []\n",
    "    z = []\n",
    "    uniname = []\n",
    "    for i in range(0,len(kpairs_36_withoiii),2):\n",
    "        loiii_tot.append(np.log10(10**float(kpairs_36_withoiii.loc[i,\"L _[O III]\"])+ 10**float(kpairs_36_withoiii.loc[i+1,\"L _[O III]\"])))\n",
    "        z.append(kpairs_36_withoiii.loc[i:i+1,\"z _spec\"].astype(float).sum()/2)\n",
    "        uniname.append(kpairs_36_withoiii.loc[i,'name'])\n",
    "    kpairs18 = pd.DataFrame([uniname,z,loiii_tot],index=['name','z','loiii']).T\n",
    "    # group radio data by unique name and get sum of flux\n",
    "    gradio['name']=[gradio.loc[i,'Radio Designation'][:5] for i in range(len(gradio))]\n",
    "    gradio17 = gradio.groupby('name',as_index=False).sum()\n",
    "    # merge 6ghz radio, oiii, and z data. 14 objs have all 3\n",
    "    g23samp = gradio17.merge(kpairs18,on='name')\n",
    "    # add 1.4ghz data for Lbol cal\n",
    "    gross14ghz = load_gross('gross23radio14.txt')\n",
    "    gross14ghz['flx1.4GHz'] = gross14ghz['flx1.4GHz'].astype(float)\n",
    "    gross14ghz['name'] = [g[:5] for g in gross14ghz['Radio Designation'].values]\n",
    "    gross14ghz.drop(columns='z',inplace=True)\n",
    "    gross14ghz_uni  = gross14ghz.groupby(\"name\",as_index=False).sum()\n",
    "    fsamp = g23samp.merge(gross14ghz_uni,on='name')\n",
    "    # calculate lbol\n",
    "    Lradio = (fsamp['flx1.4GHz'].values*1e-3*u.Jy*cosmo.angular_diameter_distance(fsamp['z'].values)**2*4*np.pi)\n",
    "    Lmech = 43+ 0.7*np.log10((Lradio/ (1e24*u.watt/u.Hz)).to(\"\").value.astype(float))\n",
    "    Lrad = 3500*10**fsamp['loiii'].values\n",
    "    fsamp['lbol'] = np.log10((10**Lmech+Lrad).astype(float))\n",
    "    # separate duals\n",
    "    gdualnames = ['00511', '22063', '22322', '22442', '23001', '23195']\n",
    "    gduals = fsamp[fsamp['name'].isin(gdualnames)]\n",
    "    # make hist\n",
    "    gbin = makebin(fsamp['lbol'][fsamp['z']<0.4])\n",
    "    gcount_all, _ = np.histogram(fsamp['lbol'][fsamp['z']<0.4],bins=gbin)\n",
    "    gcount_dual, _ = np.histogram(gduals['lbol'][gduals['z']<0.4],bins=gbin)\n",
    "    print(gcount_all,gcount_dual)\n",
    "    return gbin[1:]-np.diff(gbin)/2, gcount_dual/gcount_all\n",
    "\n",
    "def he23():\n",
    "    # read data, really ugly text file with messy spaces\n",
    "    with open(\"/home/insepien/research-data/pop-result/fvL/he23.txt\",\"r\") as f:\n",
    "        d  = f.readlines()\n",
    "    # extract name and L 2-10 keV\n",
    "    data = [i.strip(\"\\n\") for i in d[1:]]\n",
    "    names = [d[:19] for d in data]\n",
    "    uninames = [d[:6] for d in data]\n",
    "    log_L2_10 = np.array([d[-32:-27] for d in data],dtype=float)\n",
    "    # put into df, add Lbol = Lxray * 10\n",
    "    hedf = pd.DataFrame([names,log_L2_10,uninames],index=['name','Lxray','uniname']).T\n",
    "    hedf['lbol'] = log_L2_10 + 1\n",
    "    # get only x-ray detected source in an optical pair that has AGN lum Lxray > 41\n",
    "    hedfagn = hedf[hedf['Lxray']>41]\n",
    "    heduals = ['J14144','J09071']\n",
    "    # drop from a gal pair that has 2 detected xray sources, 1 source that only has upper lim of Lxray. this target is thus not categorized as dual\n",
    "    hedfagn.drop(index=12, inplace=True)\n",
    "    # get lbol for duals and singles\n",
    "    lbol_dual = []\n",
    "    for i in range(len(heduals)):\n",
    "        lbol_indiv = hedfagn[hedfagn['uniname'] == heduals[0]]['lbol'].values\n",
    "        lbol_dual.append(np.log10(10**lbol_indiv[0]+10**lbol_indiv[1]))\n",
    "    lbol_single = hedfagn[~ hedfagn['uniname'].isin(heduals)]['lbol'].values\n",
    "    lbol_all_agn = np.concatenate([lbol_single,lbol_dual])\n",
    "    # get hist stats\n",
    "    hebin = makebin(lbol_all_agn)\n",
    "    hecount_all, _ = np.histogram(lbol_all_agn,bins=hebin)\n",
    "    hecount_dual, _ = np.histogram(lbol_dual,bins=hebin)\n",
    "    return hebin[1:]-np.diff(hebin)/2, hecount_dual/hecount_all\n",
    "\n",
    "\n",
    "makebin = lambda x: np.linspace(x.min(),x.max(),int(np.sqrt(len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotpaper(ax,fn,markertype,clr,lbl):\n",
    "    df = pd.read_csv('/home/insepien/research-data/pop-result/fvL/'+fn, names=['lbol','f'])\n",
    "    # sort by lbol, then frac, to find fraction and up/lower limits\n",
    "    df.sort_values(by=['lbol','f'],inplace=True)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    # data point is the mid value in y at index 1, 3, ...\n",
    "    x = [df.loc[i]['lbol'] for i in range(1,len(df),3)]\n",
    "    f = np.array([df.loc[i]['f'] for i in range(1,len(df),3)])\n",
    "    err = np.array([np.abs(df.loc[i]['f'] - df.loc[i-1]['f']) for i in range(1,len(df),3)])\n",
    "    ax.errorbar(x,f,yerr=[err,err],linestyle='',fmt=markertype,c=clr,label=lbl)\n",
    "\n",
    "# literature\n",
    "all_markers = [\"o\",\"s\",\"x\",\"d\",'p',\"H\"]\n",
    "all_colors = sns.color_palette(\"colorblind\", len(all_markers))\n",
    "fns = ['ford2015.csv','koss12bat.csv','koss12sdss.csv','barrows2017.csv','barrows2023.csv']\n",
    "labels = ['Ford\\&Greene+15\\n(spectrally offset, $z<0.21$)',\n",
    "          'Koss+12\\n(X-ray, $z<0.05$)', 'Koss+12\\n(Optical, $z<0.07$)',\n",
    "            'Barrows+17\\n(optical, spatially offset, $0.025<z<0.2$)', 'Barrows+23\\n(use photo-z PDF to find WISE duals, $z<0.08$)']\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "# ready-plots\n",
    "for i in range(len(fns)):\n",
    "    plotpaper(ax, fns[i], lbl=labels[i],\n",
    "              clr=all_colors[i], markertype=all_markers[i])\n",
    "    \n",
    "\n",
    "# inferred fracs\n",
    "# volonteri+22\n",
    "xfine,fracfine_pdf = volonteri22()\n",
    "ax.plot(xfine,fracfine_pdf, label='Volonteri+22\\n(simulation, z=0)',c='green',linestyle='--')\n",
    "# fu+2012\n",
    "xfu, fracfu = fu12()\n",
    "ax.plot(xfu,fracfu, label='Fu+12\\n(douple-peak IFS, $z<0.4$)',c='steelblue',linestyle='-.')\n",
    "# imanishi+20 - ULIRG\n",
    "xIman, fracIman = imanishi()\n",
    "ax.plot(xIman,fracIman, label='Imanishi+13,+20\\n(ULIRG, $z<0.2$)',c=all_colors[4],linestyle='--')\n",
    "# gross+23\n",
    "xgross, fracgross = gross23()\n",
    "ax.scatter(xgross,fracgross, label='Gross+23\\n(radio, dual/pair, very small sample (4/8), $z<0.4$)',c='r',marker='x')\n",
    "# he+23\n",
    "xhe, frache = he23()\n",
    "ax.scatter(xhe,frache, label='He+23\\n(optical+xray, dual/gal. pair hosting $\\geq 1$ Chandra Xray AGN,\\n$z<0.2$)',c=all_colors[5],marker='x')\n",
    "\n",
    "# Magellan\n",
    "unresolved_duals = alpaka[alpaka['Desig'].isin(['J0932+1611',\"J0918+1207\"])]\n",
    "all_dual_cand = pd.concat([unresolved_duals, duals])\n",
    "count_all,binz = np.histogram(np.log10(magel['irbol']).dropna())\n",
    "count_duals,_ = np.histogram(np.log10(all_dual_cand['irbol'].dropna()),bins=binz)\n",
    "binmid = (binz[1:]+binz[:-1])/2\n",
    "ax.scatter(binmid,count_duals/count_all,c='k',marker=\"*\",label='Our fraction\\n(counting unresolved candidates)',s=50)\n",
    "\n",
    "# cosmetics\n",
    "ax.set_yscale('log')\n",
    "ax.legend(bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
