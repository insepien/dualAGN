{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import corner\n",
    "\n",
    "\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample n-D Gaussian\n",
    "def log_prob(x, mu, cov):\n",
    "    diff = x - mu\n",
    "    return -0.5 * np.dot(diff, np.linalg.solve(cov, diff))\n",
    "\n",
    "ndim = 5\n",
    "np.random.seed(42)\n",
    "means = np.random.rand(ndim)\n",
    "\n",
    "# calculate covariance matrix\n",
    "cov = 0.5 - np.random.rand(ndim**2).reshape((ndim, ndim))\n",
    "cov = np.triu(cov)\n",
    "cov += cov.T - np.diag(cov.diagonal())\n",
    "cov = np.dot(cov, cov)\n",
    "\n",
    "nwalkers = 32\n",
    "p0 = np.random.rand(nwalkers, ndim)\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[means, cov])\n",
    "state = sampler.run_mcmc(p0, 100)\n",
    "sampler.reset()\n",
    "# after discard burn-in, sample again\n",
    "numsteps = 5000\n",
    "sampler.run_mcmc(state, numsteps)\n",
    "\n",
    "# plot posterior\n",
    "samples = sampler.get_chain(flat=True)\n",
    "plt.hist(samples[:, 0], 100, color=\"k\", histtype=\"step\")\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(r\"$p(\\theta_1)$\")\n",
    "plt.gca().set_yticks([])\n",
    "\n",
    "print(f\"numsteps: {numsteps}\")\n",
    "print(f\"mean autocorrelation time*50: {np.mean(sampler.get_autocorr_time())*50:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Fitting model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data of straight line with noise\n",
    "np.random.seed(123)\n",
    "\n",
    "# Choose the \"true\" parameters.\n",
    "m_true = -0.9594\n",
    "b_true = 4.294\n",
    "f_true = 0.534\n",
    "\n",
    "# Generate some synthetic data from the model.\n",
    "N = 50\n",
    "x = np.sort(10 * np.random.rand(N))\n",
    "yerr = 0.1 + 0.5 * np.random.rand(N)\n",
    "y = m_true * x + b_true\n",
    "y += np.abs(f_true * y) * np.random.randn(N)\n",
    "y += yerr * np.random.randn(N)\n",
    "\n",
    "def log_likelihood(theta, x, y, yerr):\n",
    "    m, b, log_f = theta\n",
    "    model = m * x + b\n",
    "    sigma2 = yerr**2 + model**2 * np.exp(2 * log_f)\n",
    "    return -0.5 * np.sum((y - model) ** 2 / sigma2 + np.log(sigma2))\n",
    "\n",
    "#getting best fit value with Ml estimation\n",
    "np.random.seed(42)\n",
    "nll = lambda *args: -log_likelihood(*args)\n",
    "initial = np.array([m_true, b_true, np.log(f_true)]) + 0.1 * np.random.randn(3)\n",
    "soln = minimize(nll, initial, args=(x, y, yerr))\n",
    "m_ml, b_ml, log_f_ml = soln.x\n",
    "\n",
    "# sample posterior\n",
    "def log_prior(theta):\n",
    "    m, b, log_f = theta\n",
    "    if -5.0 < m < 0.5 and 0.0 < b < 10.0 and -10.0 < log_f < 1.0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_probability(theta, x, y, yerr):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr)\n",
    "\n",
    "pos = soln.x + 1e-4 * np.random.randn(32, 3)\n",
    "nwalkers, ndim = pos.shape\n",
    "\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, ndim, log_probability, args=(x, y, yerr)\n",
    ")\n",
    "numsteps = 5000\n",
    "sampler.run_mcmc(pos, numsteps, progress=True)\n",
    "\n",
    "print(f\"numsteps: {numsteps}\")\n",
    "print(f\"mean autocorrelation time*50: {np.mean(sampler.get_autocorr_time())*50:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# The definition of the log probability function\n",
    "# We'll also use the \"blobs\" feature to track the \"log prior\" for each step\n",
    "def log_prob(theta):\n",
    "    log_prior = -0.5 * np.sum((theta - 1.0) ** 2 / 100.0)\n",
    "    log_prob = -0.5 * np.sum(theta**2) + log_prior\n",
    "    return log_prob, log_prior\n",
    "\n",
    "\n",
    "# Initialize the walkers\n",
    "coords = np.random.randn(32, 5)\n",
    "nwalkers, ndim = coords.shape\n",
    "\n",
    "# Set up the backend\n",
    "# Don't forget to clear it in case the file already exists\n",
    "filename = \"tutorial.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(nwalkers, ndim)\n",
    "\n",
    "# Initialize the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, backend=backend)\n",
    "\n",
    "max_n = 100000\n",
    "\n",
    "# We'll track how the average autocorrelation time estimate changes\n",
    "index = 0\n",
    "autocorr = np.empty(max_n)\n",
    "\n",
    "# This will be useful to testing convergence\n",
    "old_tau = np.inf\n",
    "\n",
    "# Now we'll sample for up to max_n steps\n",
    "for sample in sampler.sample(coords, iterations=max_n, progress=True):\n",
    "    # Only check convergence every 100 steps\n",
    "    if sampler.iteration % 100:\n",
    "        continue\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    autocorr[index] = np.mean(tau)\n",
    "    index += 1\n",
    "\n",
    "    # Check convergence\n",
    "    converged = np.all(tau * 100 < sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    if converged:\n",
    "        break\n",
    "    old_tau = tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# hf5 IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = emcee.backends.HDFBackend(filename)\n",
    "tau = reader.get_autocorr_time()\n",
    "burnin = int(2 * np.max(tau))\n",
    "thin = int(0.5 * np.min(tau))\n",
    "samples = reader.get_chain(discard=burnin, flat=True, thin=thin)\n",
    "log_prob_samples = reader.get_log_prob(discard=burnin, flat=True, thin=thin)\n",
    "log_prior_samples = reader.get_blobs(discard=burnin, flat=True, thin=thin)\n",
    "\n",
    "print(\"burn-in: {0}\".format(burnin))\n",
    "print(\"thin: {0}\".format(thin))\n",
    "print(\"flat chain shape: {0}\".format(samples.shape))\n",
    "print(\"flat log prob shape: {0}\".format(log_prob_samples.shape))\n",
    "print(\"flat log prior shape: {0}\".format(log_prior_samples.shape))\n",
    "\n",
    "all_samples = np.concatenate(\n",
    "    (samples, log_prob_samples[:, None], log_prior_samples[:, None]), axis=1\n",
    ")\n",
    "\n",
    "labels = list(map(r\"$\\theta_{{{0}}}$\".format, range(1, ndim + 1)))\n",
    "labels += [\"log prob\", \"log prior\"]\n",
    "\n",
    "corner.corner(all_samples, labels=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
