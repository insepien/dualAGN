{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pyimfit\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import angular_separation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from photutils.isophote import EllipseSample, Isophote\n",
    "from photutils.isophote.sample import CentralEllipseSample\n",
    "from photutils.isophote.fitter import CentralEllipseFitter\n",
    "from photutils.isophote import Ellipse, EllipseGeometry, IsophoteList\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import glob\n",
    "import matplotlib.gridspec as gridspec\n",
    "from photutils.aperture import EllipticalAperture\n",
    "from photutils.detection import find_peaks\n",
    "import astropy.units as u\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\",font_scale=1.75)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{mathptmx}\",  # Times Roman\n",
    "    \"hatch.linewidth\": 3.0,  \n",
    "    \"xtick.labelsize\": 13,      \n",
    "    \"ytick.labelsize\": 13,      \n",
    "    \"legend.fontsize\": 13,\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_indices(arr):\n",
    "    \"\"\"returns a tuple of ys, xs - indices of pixels with highest counts\"\"\"\n",
    "    flattened_arr = np.array(arr).flatten()\n",
    "    max_indices = np.unravel_index(np.argsort(flattened_arr)[-2:], arr.shape)\n",
    "    return max_indices\n",
    "\n",
    "def makeModelDict(PA_ss, ell_ss, n_ss, I_ss, r_ss, Itot,\n",
    "                 PA_lim, ell_lim, I_lim,  Iss_lim, rss_lim, Itot_lim,\n",
    "                 sigma, sigma_lim, Isky, Isky_lim,\n",
    "                 h1,h2,h_lim,alpha,alpha_lim):\n",
    "    \"\"\"Return Sersic, PSF, and Gaussian model parameter dictionary\"\"\"\n",
    "    # Sersic\n",
    "    \"\"\"sersic = {'PA': [PA_ss, PA_lim[0],PA_lim[1]], 'ell_bulge': [ell_ss, ell_lim[0],ell_lim[1]], 'n': [n_ss, 'fixed'],\n",
    "    'I_e': [I_ss, Iss_lim[0],Iss_lim[1]], 'r_e': [r_ss, rss_lim[0],rss_lim[1]]}\"\"\"\n",
    "    sersic = {'PA': [PA_ss, PA_lim[0],PA_lim[1]], 'ell_bulge': [ell_ss, ell_lim[0],ell_lim[1]], 'n': [n_ss, 0.3, 6],\n",
    "    'I_e': [I_ss, Iss_lim[0],Iss_lim[1]], 'r_e': [r_ss, rss_lim[0],rss_lim[1]]}\n",
    "    sersic_dict = {'name': \"Sersic\", 'label': \"bulge\", 'parameters': sersic}\n",
    "    # PSF\n",
    "    psf = {'I_tot' : [Itot, Itot_lim[0], Itot_lim[1]]}\n",
    "    psf_dict = {'name': \"PointSource\", 'label': \"psf\", 'parameters': psf}\n",
    "    # Rot psf\n",
    "    psfRot = {'I_tot' : [Itot, Itot_lim[0], Itot_lim[1]], 'PA':[PA_ss, PA_lim[0],PA_lim[1]] }\n",
    "    psfRot_dict = {'name': \"PointSourceRot\", 'label': \"psf\", 'parameters': psfRot}\n",
    "    # Gaussians\n",
    "    gaussian = {'PA':[PA_ss, PA_lim[0],PA_lim[1]], 'ell':[ell_ss, ell_lim[0],ell_lim[1]], \n",
    "                'I_0':[I_ss, Iss_lim[0],Iss_lim[1]], 'sigma':[sigma, sigma_lim[0], sigma_lim[1]]}\n",
    "    gaussian_dict = {'name': \"Gaussian\", 'label': \"gaussian\", 'parameters': gaussian}\n",
    "    # Flat sky\n",
    "    flatsky = {'I_sky': [Isky, Isky_lim[0], Isky_lim[1]]}\n",
    "    flatsky_dict = {'name': \"FlatSky\", 'label': \"flat_sky\", 'parameters':flatsky}\n",
    "    # flat bar\n",
    "    flatbar = {'PA':[PA_ss, PA_lim[0],PA_lim[1]], 'ell':[ell_ss, ell_lim[0],ell_lim[1]],\n",
    "               'deltaPA_max':[PA_ss, PA_lim[0],PA_lim[1]], 'I_0':[I_ss, Iss_lim[0],Iss_lim[1]],\n",
    "               'h1':[h1, h_lim[0],h_lim[1]], 'h2':[h2, h_lim[0],h_lim[1]], \n",
    "               'r_break':[r_ss, rss_lim[0],rss_lim[1]], 'alpha':[alpha,alpha_lim[0],alpha_lim[1]]}\n",
    "    flatbar_dict = {'name': \"FlatBar\", 'label': \"flat_bar\", 'parameters':flatbar}\n",
    "    # Exponential\n",
    "    exponential = {'PA': [PA_ss, PA_lim[0],PA_lim[1]], 'ell': [ell_ss, ell_lim[0],ell_lim[1]], \n",
    "                   'I_0': [I_ss, Iss_lim[0],Iss_lim[1]], 'h': [h1, h_lim[0],h_lim[1]]}\n",
    "    exp_dict = {'name': \"Exponential\", 'label': \"disk\", 'parameters':exponential}\n",
    "    return sersic_dict, psf_dict, gaussian_dict, flatsky_dict, flatbar_dict,exp_dict\n",
    "\n",
    "def find_sky(imageAGNcrop, plothist=False):\n",
    "    bgr = plt.hist(imageAGNcrop.flatten(),bins=np.arange(np.min(imageAGNcrop),20))\n",
    "    plt.close()\n",
    "    max_ind = np.where(bgr[0]==np.max(bgr[0]))[0][0]\n",
    "    sky = (bgr[1][max_ind]+bgr[1][max_ind+1])/2\n",
    "    if plothist:\n",
    "        fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "        ax[0].hist(imageAGNcrop.flatten(),bins=np.arange(np.min(imageAGNcrop),np.max(imageAGNcrop)))\n",
    "        ax[1].hist(imageAGNcrop.flatten(),bins=np.arange(np.min(imageAGNcrop),20))\n",
    "        [ax[i].set_title(['Whole intensity range',f'sky level: {float(sky):.4f}'][i]) for i in range(2)]\n",
    "        [ax[i].set_xlabel('intensity') for i in range(2)]\n",
    "        ax[0].set_ylabel('number of agns') \n",
    "    return sky\n",
    "\n",
    "def profile_1D(semiA,image,PA=180,ell=0.5):\n",
    "    \"\"\"make 1D elliptical profiles\"\"\"\n",
    "    # create guess ellipse\n",
    "    pos0 = image.shape[0]//2\n",
    "    geometry = EllipseGeometry(x0=pos0, y0=pos0, sma=semiA, eps=ell,\n",
    "                               pa=PA * np.pi / 180.0)\n",
    "    # load image and geometry\n",
    "    ellipse = Ellipse(image, geometry)\n",
    "    # do isophote fit\n",
    "    isolist = ellipse.fit_image()\n",
    "    return isolist\n",
    "\n",
    "def plot_isophotes(ax,isolist,num_aper=10):\n",
    "    \"\"\"plot aperatures on image\"\"\"\n",
    "    for sma in np.linspace(isolist.sma[0],isolist.sma[-1],num_aper):\n",
    "        iso = isolist.get_closest(sma)\n",
    "        x, y, = iso.sampled_coordinates()\n",
    "        ax.plot(x, y, color='white',linewidth=\"0.5\")\n",
    "        \n",
    "# def make_model_components(config,imshape):\n",
    "#     \"\"\"make model component images from best fit config\"\"\"\n",
    "#     comp_names = config.functionLabelList()\n",
    "#     comp_ims=[]\n",
    "#     comp_pos = []\n",
    "#     for i in range(len(config.getModelAsDict()['function_sets'])):\n",
    "#         posX = config.getModelAsDict()['function_sets'][i]['X0']\n",
    "#         posY = config.getModelAsDict()['function_sets'][i]['Y0']\n",
    "#         functions = config.getModelAsDict()['function_sets'][i]['function_list']\n",
    "#         for j in range(len(functions)):\n",
    "#             if functions[j]['label'] ==\"bulge n=1\" or functions[j]['label'] ==\"bulge n=4\":\n",
    "#                 functions[j]['parameters']['n'].append(\"fixed\")\n",
    "#             funcset_dict = {'X0': posX, 'Y0': posY, 'function_list': [functions[j]]}\n",
    "#             model_dict = {'function_sets': [funcset_dict]}\n",
    "#             model = pyimfit.ModelDescription.dict_to_ModelDescription(model_dict)\n",
    "#             imfit_fitter = pyimfit.Imfit(model,epsf)\n",
    "#             comp_ims.append(imfit_fitter.getModelImage(shape=(imshape,imshape)))\n",
    "#             comp_pos.append([posX[0],posY[0]])\n",
    "#     return comp_ims, comp_pos, comp_names\n",
    "\n",
    "def make_model_components(config,imshape):\n",
    "    \"\"\"make model component images from best fit config\"\"\"\n",
    "    comp_names = config.functionLabelList()\n",
    "    comp_ims=[]\n",
    "    comp_pos = []\n",
    "    # at each position in model\n",
    "    for i in range(len(config.getModelAsDict()['function_sets'])):\n",
    "        # get position and function sets \n",
    "        posX = config.getModelAsDict()['function_sets'][i]['X0']\n",
    "        posY = config.getModelAsDict()['function_sets'][i]['Y0']\n",
    "        functions = config.getModelAsDict()['function_sets'][i]['function_list']\n",
    "        # for each function set\n",
    "        for j in range(len(functions)):\n",
    "            # fix pyimfit fault for fixed params\n",
    "            if functions[j]['label'] ==\"bulge n=1\":\n",
    "                functions[j]['parameters']['n'] = [1, \"fixed\"]\n",
    "            if functions[j]['label'] ==\"flat_sky\":\n",
    "                functions[j]['parameters']['I_sky'] = [functions[j]['parameters']['I_sky'][0],\"fixed\"]\n",
    "            # create dictionary for each component \n",
    "            funcset_dict = {'X0': posX, 'Y0': posY, 'function_list': [functions[j]]}\n",
    "            model_dict = {'function_sets': [funcset_dict]}\n",
    "            # make fitter and component image\n",
    "            model = pyimfit.ModelDescription.dict_to_ModelDescription(model_dict)\n",
    "            imfit_fitter = pyimfit.Imfit(model,epsf)\n",
    "            # save to list\n",
    "            comp_ims.append(imfit_fitter.getModelImage(shape=(imshape,imshape)))\n",
    "            comp_pos.append([posX[0],posY[0]])\n",
    "    return comp_ims, comp_pos, comp_names\n",
    "\n",
    "def plot_model_components(comp_ims,comp_names,comp_pos,isolist_comps, colormap=\"ch:s=-.3,r=.6\", plotIso=False,shrink_ratio=0.5):\n",
    "    \"\"\"plot 2D model components and check residual with model image\"\"\"\n",
    "    clmap = sns.color_palette(colormap, as_cmap=True)\n",
    "    ncom = len(comp_names)\n",
    "    fig,ax = plt.subplots(nrows=1,ncols=ncom+1, figsize=(ncom*4,3))\n",
    "    im = [ax[i].imshow(comp_ims[i],norm='symlog',cmap=clmap) for i in range(ncom)]\n",
    "    [ax[i].text(0.05, 0.05, f\"(x,y)=({comp_pos[i][0]:.1f},{comp_pos[i][1]:.1f})\", transform=ax[i].transAxes, fontsize=8, color='k') for i in range(ncom-1)]\n",
    "    [ax[i].set_title(comp_names[i]) for i in range(ncom)]\n",
    "    im.append(ax[-1].imshow(np.sum(comp_ims[:-1],axis=0)-comp_ims[-1],norm='symlog',cmap=clmap))\n",
    "    ax[-1].set_title(\"model-comps\")\n",
    "    [fig.colorbar(im[i], ax=ax[i], shrink=shrink_ratio).ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f')) for i in range(len(ax))]\n",
    "    if plotIso:\n",
    "        for i in range(len(isolist_comps)):\n",
    "             plot_isophotes(ax[i],isolist_comps[i],num_aper=5)\n",
    "    fig.tight_layout();\n",
    "\n",
    "def plot_1isophote(ax,sma,isolist):\n",
    "    \"\"\"plot aperatures on image\"\"\"\n",
    "    iso = isolist.get_closest(sma)\n",
    "    x, y, = iso.sampled_coordinates()\n",
    "    ax.plot(x, y, color='white',linewidth=\"0.3\")\n",
    "\n",
    "def pix_to_arcsec(imageFile,framelim):\n",
    "    w = WCS(imageFile)\n",
    "    # convert pixel to degree\n",
    "    ra1,dec1 = w.pixel_to_world_values(0,0)\n",
    "    ra2,dec2 = w.pixel_to_world_values(framelim,framelim)\n",
    "    arcsec_per_pix = 0.16*u.arcsec\n",
    "    return arcsec_per_pix, [ra1,dec1,ra2,dec2]\n",
    "\n",
    "def surface_brightness(intensity, area, magZPT):\n",
    "    return -2.5*np.log10(intensity/area)+ magZPT\n",
    "\n",
    "def radial_plot_params(imageFile, framelim, isolist_data,isolist_comps,hdu_exp,z=0.2):\n",
    "    # convert pixel to arcsec and kpc\n",
    "    arcsec_per_pix, skycoords = pix_to_arcsec(imageFile,framelim)\n",
    "    sma_arcsec = isolist_data.sma*arcsec_per_pix\n",
    "    sma_kpc = (cosmo.angular_diameter_distance(z)*sma_arcsec.to('rad').value).to('kpc')\n",
    "    # calculate isophote areas and find surface brightness\n",
    "    areas = (np.sqrt((1-isolist_data.eps**2)*sma_arcsec**2)*np.pi*sma_arcsec).value\n",
    "    magZPT = hdu_exp.header['MAGZP']\n",
    "    mu_data = [surface_brightness(i,areas,magZPT) for i in [isolist_data.intens,isolist_data.intens-isolist_data.int_err,isolist_data.intens+isolist_data.int_err]]\n",
    "    mu_models = [[surface_brightness(i,areas,magZPT) for i in [isolist_comps[j].intens,isolist_comps[j].intens-isolist_comps[j].int_err,isolist_comps[j].intens+isolist_comps[j].int_err]] for j in range(len(isolist_comps))]\n",
    "    return sma_arcsec, sma_kpc, mu_data, mu_models, skycoords\n",
    "\n",
    "def plot_everything(on,image,m,modelname,comp_names,fsr,sma_arcsec,sma_kpc,mu_data,mu_models,skycoords,colormap):\n",
    "    colors = sns.color_palette(colormap, len(comp_names)+2)[1:]\n",
    "    linestyles = ['-', '--', '-.', ':']\n",
    "    #colors = sns.color_palette(\"colorblind\", len(comp_names)+2)\n",
    "    cmapp = sns.color_palette(colormap, as_cmap=True).reversed()\n",
    "    # Create grid and add subplots\n",
    "    fig = plt.figure(figsize=(14, 4),layout='tight')\n",
    "    gs = gridspec.GridSpec(2, 4, height_ratios=[3, 1], width_ratios=[1.25,1.25,1,1.5],hspace=0.05,wspace=0.05)\n",
    "    ax1 = fig.add_subplot(gs[:, 0],xlabel='RA (deg)',ylabel='DEC (deg)') \n",
    "    ax2 = fig.add_subplot(gs[:, 1],xticks=[],yticks=[])\n",
    "    ax3 = fig.add_subplot(gs[:, 2],xticks=[],yticks=[])\n",
    "    ax4a = fig.add_subplot(gs[0, 3]) \n",
    "    ax4b = fig.add_subplot(gs[1, 3])   \n",
    "    # formatting ticks\n",
    "    xticks = np.linspace(skycoords[0],skycoords[2],4)\n",
    "    yticks = np.linspace(skycoords[1],skycoords[3],4)\n",
    "    ax1.set_xticks(np.linspace(0,image.shape[0],4))\n",
    "    ax1.set_yticks(np.linspace(0,image.shape[0],4))\n",
    "    ax1.set_xticklabels([f'{x:.3f}' for x in xticks])\n",
    "    ax1.set_yticklabels([f'{y:.3f}' for y in yticks],rotation=90)\n",
    "    ax1.tick_params(direction='in')\n",
    "    # plot 2d and colorbars\n",
    "    ax = [ax1,ax2,ax3,ax4a,ax4b]\n",
    "    im = [ax[i].imshow([image, m][i], norm='symlog',cmap=cmapp) for i in range(2)]\n",
    "    im2 = ax[2].imshow(image-m,cmap=cmapp)\n",
    "    fig.colorbar(im2,ax=ax[2],orientation='horizontal',location='bottom',pad=0.05)\n",
    "    fig.colorbar(im[1],ax=[ax[0],ax[1]],orientation='vertical',location='right',shrink=0.5)\n",
    "    [ax[i].set_title([on,f\"Model:\\n{modelname}\",f'Residual,$\\chi^2$={fsr:.0f}'][i]) for i in range(3)]\n",
    "    # radial plot data\n",
    "    ax[3].plot(sma_arcsec[1:],mu_data[0][1:],label=\"data\",c=colors[-1])\n",
    "    ax[3].fill_between(sma_arcsec[1:].value,mu_data[1][1:],mu_data[2][1:],color=colors[-1],alpha=0.5)\n",
    "    # radial plot components\n",
    "    [ax[3].plot(sma_arcsec[1:],mu_models[i][0][1:],label=comp_names[i],linestyle=linestyles[i],c=colors[i]) for i in range(len(comp_names)-1)]\n",
    "    [ax[3].fill_between(sma_arcsec[1:].value,mu_models[i][1][1:],mu_models[i][2][1:],color=colors[i],alpha=0.5) for i in range(len(comp_names)-1)]\n",
    "    ax[4].plot(sma_kpc[1:],mu_data[0][1:]-mu_models[-1][0][1:],c=colors[-2],linestyle=\"dashdot\")\n",
    "    ax[4].fill_between(sma_kpc[1:].value,mu_data[1][1:]-mu_models[-1][1][1:],mu_data[2][1:]-mu_models[-1][2][1:],color=colors[-2],alpha=0.5)\n",
    "    ax[4].axhline(y=0,linestyle='--',c=colors[1],lw=1)\n",
    "    # format ticks\n",
    "    ax[3].invert_yaxis()\n",
    "    ax[3].set_xlabel(\"R[arcsec]\")\n",
    "    ax[3].set_ylabel(\"$\\mu$ [mag arcsec$^{-2}$]\")\n",
    "    ax[3].xaxis.set_label_position('top') \n",
    "    ax[3].xaxis.set_ticks_position('top') \n",
    "    ax[3].legend(fontsize=10,loc='upper right',bbox_to_anchor=(1.6, 1))\n",
    "    [ax[i].set_xscale(\"log\") for i in [3,4]]\n",
    "    ax[4].set_xlabel(\"R[kpc]\")\n",
    "    ax[4].set_ylabel(\"$\\Delta \\mu$\") \n",
    "    ax[4].set_ylim((-0.5,0.5))\n",
    "    [ax.yaxis.set_label_position('right') for ax in [ax4a,ax4b]]\n",
    "    [ax.yaxis.set_ticks_position('right') for ax in [ax4a,ax4b]];\n",
    "\n",
    "\n",
    "def make_model_isophotes(isolist_data, comp_ims, comp_names, midf):\n",
    "    isolist_comps=[]\n",
    "    circ = [comp_names[i]=='psf' for i in range(len(comp_names))]\n",
    "    for i in range(len(comp_ims)):\n",
    "        isolist_ = []\n",
    "        for iso in isolist_data[1:]:\n",
    "            g = iso.sample.geometry\n",
    "            ell = 0 if circ[i] else g.eps\n",
    "            gn = EllipseGeometry(g.x0,g.y0, g.sma, ell, g.pa)\n",
    "            sample = EllipseSample(comp_ims[i],g.sma,geometry=gn)\n",
    "            sample.update()\n",
    "            iso_ = Isophote(sample,0,True,0)\n",
    "            isolist_.append(iso_)\n",
    "        isolist = IsophoteList(isolist_)\n",
    "        g = EllipseGeometry(midf,midf, 0.0, 0., 0.)\n",
    "        sample = CentralEllipseSample(comp_ims[i], 0., geometry=g)\n",
    "        fitter = CentralEllipseFitter(sample)\n",
    "        center = fitter.fit()\n",
    "        isolist.append(center)\n",
    "        isolist.sort()\n",
    "        isolist_comps.append(isolist)\n",
    "    return isolist_comps\n",
    "\n",
    "def make_data_isophotes(data,sma,midf):\n",
    "    isolist_data = profile_1D(semiA=sma,image=data)\n",
    "    # discard first isophote and make new\n",
    "    isolist_data = isolist_data[1:]\n",
    "    g = EllipseGeometry(midf,midf, 0.0, 0., 0.)\n",
    "    sample = CentralEllipseSample(data, 0., geometry=g)\n",
    "    fitter = CentralEllipseFitter(sample)\n",
    "    center = fitter.fit()\n",
    "    isolist_data.append(center)\n",
    "    isolist_data.sort()\n",
    "    return isolist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### fit \n",
    "read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J0912+0148\"\n",
    "imageFile = glob.glob(os.path.expanduser(\"/home/insepien/research-data/agn-result/box/kpcbox/*\"+on+\"*.fits\"))[0]\n",
    "imageAGN = fits.getdata(imageFile)\n",
    "# with open(os.path.expanduser(\"~/research-data/psf-results/psf_pkls/psf_\"+on+\".pkl\"),\"rb\") as f:\n",
    "#     d = pickle.load(f)\n",
    "# epsf = d['psf'].data\n",
    "\n",
    "epsf = fits.getdata(\"/home/insepien/dualAGN/scrap_notebooks/psf_j0912.fits\")\n",
    "\n",
    "ys,xs = find_highest_indices(imageAGN)\n",
    "Imax = imageAGN.max()\n",
    "itot=1500\n",
    "framelim = imageAGN.shape[0]\n",
    "midF=framelim//2\n",
    "\n",
    "skylev = pd.read_pickle(\"../fit/sky41.pkl\")#(\"/home/insepien/research-data/agn-result/box/skylev/sky_clean.pkl\")\n",
    "sky = skylev[on]#[0]\n",
    "plt.imshow(imageAGN, norm='symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dofit_no_oversp(model, dataImage, psf, readnoise=0.22, expT=1, skylevel = 654.63, ncom=4, solver=\"NM\",effgain=1):\n",
    "    \"\"\"do fit with not oversampled psf\n",
    "       \"\"\"\n",
    "    fitter = pyimfit.Imfit(model,psf=psf)\n",
    "    if float(ncom)==1.:\n",
    "        fitter.loadData(dataImage,exp_time=expT, \n",
    "                    read_noise=readnoise, original_sky=skylevel,gain=effgain)\n",
    "    else:\n",
    "        fitter.loadData(dataImage,exp_time=expT, \n",
    "                    read_noise=readnoise, original_sky=skylevel,n_combined=ncom,gain=effgain)\n",
    "    fitter.doFit(solver)\n",
    "    fitConfig = fitter.getModelDescription()\n",
    "    fitModelImage = fitter.getModelImage()\n",
    "    fitResult = fitter.getFitResult()\n",
    "    param_names = fitter.numberedParameterNames\n",
    "    return fitConfig, fitModelImage, fitResult, param_names,fitter\n",
    "\n",
    "\n",
    "Imax = imageAGN.max()\n",
    "itot=1700\n",
    "sersic_dict, psf_dict, gaussian_dict, flatsky_dict, flatbar_dict, exp_dict = makeModelDict(PA_ss=30, ell_ss=0.1, n_ss=1, I_ss=1, r_ss=20, Itot=itot,\n",
    "                                                                     PA_lim=[0,360], ell_lim=[0.0,1.0], I_lim=[0.1,Imax],\n",
    "                                                                     Iss_lim=[0.1,Imax], rss_lim=[0.1,framelim], Itot_lim=[0.1,1e4],\n",
    "                                                                     sigma = 5, sigma_lim = [1,20], Isky = 2.5, Isky_lim =[0,10],\n",
    "                                                                     h1=10,h2=10,h_lim=[0.1,framelim],alpha=0.1,alpha_lim=[0.1,framelim])\n",
    "broken_exponentialParamsDict = {'PA': [0, 0,360], 'ell': [0.5, 0,1], 'I_0': [10.0, 0.0,Imax], \n",
    "                                'h1': [10, 0.1,framelim],'h2': [10, 0.1,framelim],'r_break': [10, 0.1,framelim],'alpha':[0.5,0,100]}\n",
    "bexp_dict = {'name': \"BrokenExponential\", 'label': \"bexp\", 'parameters':broken_exponentialParamsDict}\n",
    "\n",
    "GaussianRingAzParamsDict = {'PA': [40, 0,360], 'ell': [0.5, 0,1], 'A_maj':[100,0,framelim], 'A_min_rel':[0.5,0,1],\n",
    "                          'R_ring':[10,0,100],'sigma_r':[5,0,100]}\n",
    "gausR_dict = {'name': \"GaussianRingAz\", 'label': \"GaussianRingAz\", 'parameters': GaussianRingAzParamsDict}\n",
    "\n",
    "exponentialParamDict = {'PA': [30, 0,360], 'ell': [0.5, 0,1], 'I_0': [1, 0.1,Imax], 'h': [1, 0.1,1e4]}\n",
    "exp2_dict = {'name': \"Exponential\", 'label': \"disk\", 'parameters':exponentialParamDict}\n",
    "\n",
    "flatbar = {'PA':[30,0,360], 'ell':[0.5,0,1],\n",
    "            'deltaPA_max':[30,0,360], 'I_0':[1,0,Imax],\n",
    "            'h1':[10,0.1,framelim], 'h2':[10,0.1,framelim,], \n",
    "            'r_break':[3,0,framelim], 'alpha':[0.1,0,framelim]}\n",
    "flatbar0_dict = {'name': \"FlatBar\", 'label': \"flat_bar\", 'parameters':flatbar}\n",
    "\n",
    "flatsky = {'I_sky': [sky,'fixed']}\n",
    "flatsky_dict = {'name': \"FlatSky\", 'label': \"flat_sky\", 'parameters':flatsky}\n",
    "\n",
    "sersicParamsDict = {'PA': [45, 0, 360], 'ell_bulge': [0.2, 0, 1],\n",
    "                    'n': [1, 0.3,6],'I_e': [1, 0.0,Imax], 'r_e': [3, 0.0, framelim]}\n",
    "sersic2_dict = {'name': \"Sersic\", 'label': \"bulge 2\", 'parameters': sersicParamsDict}\n",
    "\n",
    "sersic1_dict = {'name': \"Sersic\", 'label': \"bulge 1\", 'parameters': sersicParamsDict}\n",
    "\n",
    "sersic3ParamsDict = {'PA': [30, 0, 360], 'ell_bulge': [0.7, 0, 1],\n",
    "                    'n': [1,  0.3,6],'I_e': [10, 0.0,Imax], 'r_e': [3, 0.0, framelim]}\n",
    "sersic3_dict = {'name': \"Sersic\", 'label': \"bulge 3\", 'parameters': sersic3ParamsDict}\n",
    "\n",
    "ext_sersicParamsDict = {'PA': [30, 0, 360], 'ell_bulge': [0.5, 0, 1],\n",
    "                    'n': [1,  0.3,6],'I_e': [10, 0.0,Imax], 'r_e': [5, 0.0, framelim]}\n",
    "sersic_ext_dict = {'name': \"Sersic\", 'label': \"ext bulge\", 'parameters': ext_sersicParamsDict}\n",
    "\n",
    "\n",
    "funcset_dict_sersic1= {'X0': [xs[0],0,framelim], 'Y0': [ys[0],0,framelim], \n",
    "                    'function_list': [sersic1_dict,flatsky_dict]}\n",
    "funcset_dict_sersic2= {'X0': [xs[1],0,framelim], 'Y0': [ys[1],0,framelim], \n",
    "                    'function_list': [psf_dict,sersic2_dict]}\n",
    "funcset_dict_sersic3= {'X0': [75,0,framelim], 'Y0': [115,0,framelim], \n",
    "                    'function_list': [sersic2_dict]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_dict = {'function_sets': [funcset_dict_sersic1]}\n",
    "model = pyimfit.ModelDescription.dict_to_ModelDescription(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_fit/\"+on+\".pkl\"\n",
    "# fit_path = \"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6(wrongBG)/masked_fit/\"+on+\".pkl\"\n",
    "with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "    d_fit = pickle.load(f)\n",
    "modelname = \"sersic+sersic(n1)+psf\"\n",
    "# d_fit['modelNames'][modelname].getModelAsDict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "printparam = lambda name,val: [print(f\"{n}: {v:.2f}\") for n,v in zip(name,val)];\n",
    "ind = np.where(np.array(list(d_fit['modelNames'].keys()))==\"sersic+sersic(n1)+psf\")[0][0]\n",
    "printparam(d_fit['paramNames'][ind],d_fit['fitResults'][ind].params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_explim = np.array([4.0, 0.1, 374.0625915527344])*np.exp(1.678)\n",
    "r_explim = np.array([0.75, 0.1, 147.0])/1.678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'function_sets': [{'X0': [73.0, 0.0, 147.0],\n",
    "   'Y0': [73.0, 0.0, 147.0],\n",
    "   'function_list': [{'name': 'Sersic',\n",
    "     'label': 'bulge',\n",
    "     'parameters': {'PA': [40.0, 0.0, 360.0],\n",
    "      'ell_bulge': [0.4, 0.0, 1.0],\n",
    "      'n': [1.0, 0.3, 6.0],\n",
    "      'I_e': [1.0, 0.1, 374.0625915527344],\n",
    "      'r_e': [3.0, 0.1, 147.0]}},\n",
    "    {'name': 'Exponential',\n",
    "     'label': 'disk',\n",
    "     'parameters': {'PA': [40.0, 0.0, 360.0],\n",
    "      'ell': [0.4, 0.0, 1.0],\n",
    "      'I_0': list(i_explim),\n",
    "      'h': list(r_explim)}},\n",
    "    {'name': 'PointSource',\n",
    "     'label': 'psf',\n",
    "     'parameters': {'I_tot': [1500.0, 0.1, 10000.0]}},\n",
    "    {'name': 'FlatSky',\n",
    "     'label': 'flat_sky',\n",
    "     'parameters': {'I_sky': [-0.040774786844849586, 'fixed']}}]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosfile = glob.glob(os.path.expanduser(\"~/raw-data-agn/mos-fits-agn/*\"+on+\"*.mos.fits\"))[0]\n",
    "expfile = glob.glob(os.path.expanduser(\"~/raw-data-agn/exp-fits-agn/*\"+on+\"*.exp.fits\"))[0]\n",
    "with fits.open(os.path.expanduser(mosfile)) as hdul:\n",
    "    hdu0 = hdul[0]\n",
    "\n",
    "sky_level = hdu0.header['BACKGND'] #fits:[e-/s] native pixels, pf: value should be in the same units as the data pixels\n",
    "\n",
    "with fits.open(os.path.expanduser(expfile)) as hdul:\n",
    "    hdu = hdul[0]\n",
    "exptime= hdu0.header['EXPORG'] # fits: actual exp time, pf: total integration time\n",
    "gain = hdu0.header['EGAIN'] #fits: e/du, pf: in electrons/ADU\n",
    "noise=hdu.header['EFFRN'] #fits:[e-], pf: in electrons\n",
    "numcom=hdu0.header['NCOADD'] #Number of Averaged Frames   \n",
    "# Try for only 1 model\n",
    "image = imageAGN\n",
    "config0, modelIm0, fitRes0, pname0,fitter0  = _dofit_no_oversp(model,dataImage=image, psf=epsf,solver=\"LM\",\n",
    "                                                 readnoise=noise, expT=exptime, skylevel = sky_level, ncom=numcom,effgain=gain)\n",
    "m = modelIm0\n",
    "res = fitRes0.params\n",
    "pname = pname0\n",
    "fs = fitRes0.fitStat\n",
    "fsr = fitRes0.fitStatReduced\n",
    "comp_ims, comp_pos, comp_names = make_model_components(config0,imshape=image.shape[0])\n",
    "comp_ims.append(m)\n",
    "comp_names.append(\"model\")\n",
    "comp_pos.append([midF,midF])\n",
    "[print(f\"{pname0[i]}: {fitRes0.params[i]:.2f} \") for i in range(len(fitRes0.params))];\n",
    "fig,ax = plt.subplots(1,3,figsize=(10,3),dpi=300)\n",
    "im0 = ax[0].imshow(image,norm='symlog')\n",
    "im1=ax[1].imshow(m,norm='symlog')\n",
    "im2=ax[2].imshow(image-m,norm='symlog')\n",
    "[fig.colorbar([im0,im1,im2][i],ax=ax[i],shrink=0.5) for i in range(3)]\n",
    "ax[0].set_title(on)\n",
    "ax[1].set_title(\"\")\n",
    "ax[2].set_title(f'residual, $\\chi$:{fs:.2f},$\\chi_r$:{fitRes0.fitStatReduced:.2f}')\n",
    "fig.tight_layout();\n",
    "print(len(fitRes0.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolist_comps=[]\n",
    "plot_model_components(comp_ims,comp_names,comp_pos,isolist_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "im0=ax[0].imshow(comp_ims[0],norm='symlog')\n",
    "im1=ax[1].imshow(m,norm='symlog')\n",
    "[fig.colorbar([im0,im1][i],ax=ax[i],shrink=0.4) for i in range(2)]\n",
    "fig.tight_layout();\n",
    "ax[1].plot(comp_pos[0][0]-1,comp_pos[0][1]-1,\"ro\",markersize=2)\n",
    "#ax[1].plot(comp_pos[2][0]-1,comp_pos[2][1]-1,\"ro\",markersize=2)\n",
    "# ax[1].plot(80,135,\"ro\",markersize=1)\n",
    "#ax[1].plot(40,40,\"ro\",markersize=1)\n",
    "#[print(f\"{pname0[i]}: {fitRes0.params[i]:.2f} \") for i in range(len(fitRes0.params))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'sersic+psf,sersic+psf'\n",
    "isolist_data = make_data_isophotes(image,20,midF)\n",
    "isolist_comps = make_model_isophotes(isolist_data,comp_ims,comp_names,midF)  \n",
    "plot_model_components(comp_ims,comp_names,comp_pos,isolist_comps)\n",
    "sma_arcsec, sma_kpc, mu_data,mu_models,skycoords = radial_plot_params(imageFile, framelim,isolist_data,isolist_comps,hdu_exp=hdu0,z=0.2)\n",
    "plot_everything(on,image,m,modelname,comp_names,fs,sma_arcsec,sma_kpc,mu_data,mu_models,skycoords,colormap=\"ch:s=-.3,r=.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(modelname,image,model,configs,modelIms,fitResults,\n",
    "              pnames,objectName, savepath):\n",
    "    d = {}\n",
    "    d[modelname] = model\n",
    "    savedata = {}\n",
    "    savedata['imageSS'] = image\n",
    "    savedata['modelNames'] = d\n",
    "    savedata['configs'] = configs\n",
    "    savedata['modelImage'] = modelIms\n",
    "    savedata['fitResults'] = fitResults\n",
    "    savedata['paramNames'] = pnames\n",
    "    pickle.dump(savedata,open(os.path.expanduser(savepath),\"wb\"))\n",
    "    \n",
    "# outDir =os.path.expanduser(\"~/research-data/agn-result/fit/fit_masked_n.3to6/nb_fit/\"+on+\"_nb.pkl\")\n",
    "# save_data(modelname,image=image, model=[model],configs=[config0],\n",
    "#           modelIms=[modelIm0],fitResults=[fitRes0],pnames=[pname0],\n",
    "#           objectName=on, savepath=outDir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### tables for paper\n",
    "note that this is for specific models: 1215 - sersic+psf,sersic+psf, 1222 - sersic,sersic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### j1215\n",
    "from uncertainties import ufloat\n",
    "import uncertainties.umath as um \n",
    "def make_paper_table(d_fit,d_comp,hdu0,ind,z):\n",
    "    # get param vals and errs\n",
    "    params = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['params']))\n",
    "    errs = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['paramErrs']))\n",
    "    # get comp total count \n",
    "    counts = [np.sum(i) for i in d_comp[modelname].comp_im]\n",
    "    # convert to mag with errors\n",
    "    magzp= hdu0.header['MAGZP']\n",
    "    magzpe = hdu0.header['MAGZPE']\n",
    "    comp_mag=[um.log10(ufloat(c,0)) * -2.5 + ufloat(magzp,magzpe) for c in counts[:-1]]\n",
    "    # convert radius to phys distance\n",
    "    platescale = hdu0.header['SCALE']\n",
    "    physd = lambda r,z: ((r*platescale*u.arcsec).to(u.rad).value*cosmo.angular_diameter_distance(z)).to(u.kpc).value\n",
    "    re1 = physd(params['r_e_1'],z)\n",
    "    re1_err = physd(errs['r_e_1'],z)\n",
    "    re2 = physd(params['r_e_3'],z)\n",
    "    re2_err = physd(errs['r_e_3'],z)\n",
    "    # create df and convert to latex \n",
    "    fmt = lambda val, err: f\"{val:.2f} $\\pm$ {err:.2f}\"\n",
    "    keys = ['m(ser)','m(psf)','r(kpc)','n']\n",
    "    comp1 = [fmt(comp_mag[0].n,comp_mag[0].s),fmt(comp_mag[1].n,comp_mag[1].s),fmt(re1,re1_err),fmt(params['n_1'],errs['n_1'])]\n",
    "    comp2 = [fmt(comp_mag[2].n,comp_mag[2].s),fmt(comp_mag[3].n,comp_mag[3].s),fmt(re2,re2_err),fmt(params['n_3'],errs['n_3'])]\n",
    "    print(pd.DataFrame([comp1,comp2],columns=keys).to_latex(column_format='|c|c|c|',float_format=\"%.3f\"))\n",
    "\n",
    "##################### j1222\n",
    "def j1222_table(d_fit,d_comp):\n",
    "    j1222params = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['params']))\n",
    "    j1222errs = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['paramErrs']))\n",
    "    # get comp total count \n",
    "    counts = [np.sum(i) for i in d_comp[modelname].comp_im]\n",
    "    # convert to mag with errors\n",
    "    magzp= hdu0.header['MAGZP']\n",
    "    magzpe = hdu0.header['MAGZPE']\n",
    "    comp_mag=[um.log10(ufloat(c,0)) * -2.5 + ufloat(magzp,magzpe) for c in counts[:-1]]\n",
    "    # convert radius to phys distance\n",
    "    platescale = hdu0.header['SCALE']\n",
    "    z1222 = 0.172\n",
    "    physd = lambda r,z: ((r*platescale*u.arcsec).to(u.rad).value*cosmo.angular_diameter_distance(z)).to(u.kpc).value\n",
    "    re1 = physd(j1222params['r_e_1'],z1222)\n",
    "    re1_err = physd(j1222errs['r_e_1'],z1222)\n",
    "    re2 = physd(j1222params['r_e_3'],z1222)\n",
    "    re2_err = physd(j1222errs['r_e_3'],z1222)\n",
    "    # create df and convert to latex \n",
    "    fmt = lambda val, err: f\"{val:.2f} $\\pm$ {err:.2f}\"\n",
    "    keys = ['m(ser)','r(kpc)','n']\n",
    "    comp1 = [fmt(comp_mag[0].n,comp_mag[0].s),fmt(re1,re1_err),fmt(j1222params['n_1'],j1222errs['n_1'])]\n",
    "    comp2 = [fmt(comp_mag[1].n,comp_mag[1].s),fmt(re2,re2_err),fmt(j1222params['n_3'],j1222errs['n_3'])]\n",
    "    print(pd.DataFrame([comp1,comp2],columns=keys).to_latex(column_format='|c|c|c|',float_format=\"%.3f\"))\n",
    "\n",
    "############### models in appendix\n",
    "modelnames = list(d_fit['modelNames'].keys())\n",
    "paramnames = d_fit['paramNames']\n",
    "nparams = [len(p) for p in paramnames]\n",
    "intps=[]\n",
    "mnames = []\n",
    "for m,p in zip(modelnames,paramnames):\n",
    "    mnames.append(m.replace(\"sersic\", \"S\\'{e}rsic\").replace(\"psf\",\"PSF\").replace(\"exp\",\"Exponential\").replace(\"n1\",\"n=1\"))\n",
    "    intp = \"Dual AGN\" if m.count(\"psf\")==1 else \"Single AGN\"\n",
    "    intps.append(intp)\n",
    "\n",
    "print(pd.DataFrame([mnames,nparams,intps],index=[\"mname\", \"N_dof\", \"Intepretation\"], columns=np.arange(1,len(modelnames)+1)).T.to_latex(column_format=\"c|c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J1140+0918\"\n",
    "modelname = \"sersic+psf,sersic\"\n",
    "\n",
    "fit_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_fit/\"+on+\".pkl\"\n",
    "with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "    d_fit = pickle.load(f)\n",
    "comp_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_comp/\"+on+\"_comp.pkl\"\n",
    "with open(os.path.expanduser(comp_path),\"rb\") as f:\n",
    "    d_comp = pickle.load(f)\n",
    "mosfile = glob.glob(os.path.expanduser(\"~/raw-data-agn/mos-fits-agn/*\"+on+\"*.mos.fits\"))[0]\n",
    "with fits.open(os.path.expanduser(mosfile)) as hdul:\n",
    "    hdu0 = hdul[0]\n",
    "\n",
    "getind = lambda name: np.where(np.array(list(d_fit['modelNames'].keys()))==name)[0][0]\n",
    "ind = getind(modelname)\n",
    "\n",
    "def make_paper_table(d_fit,d_comp,hdu0,ind,z,addflux=False):\n",
    "    # get param vals and errs\n",
    "    params = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['params']))\n",
    "    print(params)\n",
    "    errs = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind]['paramErrs']))\n",
    "    # get comp total count \n",
    "    counts = [np.sum(i) for i in d_comp[modelname].comp_im]\n",
    "    # remove background count\n",
    "    counts = [c for c in counts[:-1] if c>0]\n",
    "    # option to combine flux for ser+ser,ser models\n",
    "    if addflux:\n",
    "        counts = [counts[0]+counts[1], counts[2]]\n",
    "    print(counts)\n",
    "    # convert to mag with errors\n",
    "    magzp= hdu0.header['MAGZP']\n",
    "    magzpe = hdu0.header['MAGZPE']\n",
    "    comp_mag=[um.log10(ufloat(c,0)) * -2.5 + ufloat(magzp,magzpe) for c in counts]\n",
    "    # convert radius to phys distance\n",
    "    platescale = hdu0.header['SCALE']\n",
    "    physd = lambda r,z: ((r*platescale*u.arcsec).to(u.rad).value*cosmo.angular_diameter_distance(z)).to(u.kpc).value\n",
    "    re1 = physd(params['r_e_1'],z)\n",
    "    re1_err = physd(errs['r_e_1'],z)\n",
    "    re2 = physd(params['r_e_4'],z)\n",
    "    re2_err = physd(errs['r_e_4'],z)\n",
    "    # create df and convert to latex \n",
    "    fmt = lambda val, err: rf\"${val:.2f} \\pm {err:.2f}$\"\n",
    "    keys = ['m(ser)','r(kpc)','n',\"e\"]\n",
    "    # comp1 = [fmt(comp_mag[0].n,comp_mag[0].s),fmt(re1,re1_err),fmt(params['n_1'],errs['n_1'])]\n",
    "    print(fmt(comp_mag[0].n,comp_mag[0].s))\n",
    "    comp2 = [fmt(comp_mag[1].n,comp_mag[1].s),fmt(re2,re2_err),fmt(params['n_4'],errs['n_4']),fmt(params['ell_bulge_4'],errs['ell_bulge_4'])]\n",
    "    print(pd.DataFrame([comp2],columns=keys).to_latex(column_format='|c|c|c|',float_format=\"%.3f\"))\n",
    "\n",
    "make_paper_table(d_fit,d_comp, hdu0,ind,z=0.172,addflux=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### some 1-time-use functions to \n",
    "- cut fit.pkl from 17 to 15 models\n",
    "- make fits with header\n",
    "- make cutout of original size for extended boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_15_models(on):\n",
    "    \"\"\"cut from 17 or more models to 15 models, i.e. remove bar models, for fit.pkl and comp.pkl\"\"\"\n",
    "    fit_path = \"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_fit/\"+on+\".pkl\"\n",
    "    with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "        d_fit = pickle.load(f)\n",
    "    key = list(d_fit.keys())\n",
    "    # remove model dict\n",
    "    for k in list(d_fit['modelNames'].keys())[15:]:\n",
    "        del d_fit['modelNames'][k]\n",
    "    # now remove from lists\n",
    "    for k in key[2:]:\n",
    "        try:\n",
    "            d_fit[k] = d_fit[k][:15]\n",
    "        except:\n",
    "            print(k)\n",
    "    if np.sum([len(d_fit[k])==15 for k in key[1:]]) == 5:\n",
    "        print(f\"{on} new fit.pkl len=15, saving fit pkl\")\n",
    "        pickle.dump(d_fit,open(os.path.expanduser(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_fit15/\"+on+\".pkl\"),\"wb\"))\n",
    "\n",
    "    comp_path = \"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_fit_comp/\"+on+\"_comp.pkl\"\n",
    "    with open(os.path.expanduser(comp_path),\"rb\") as f:\n",
    "        d_comp = pickle.load(f)\n",
    "    for k in list(d_comp.keys())[15:-2]:\n",
    "        del d_comp[k]\n",
    "    if len(d_comp)==17:\n",
    "        print(f\"{on} new comp.pkl len=15+2(data), saving comp pkl\")\n",
    "        pickle.dump(d_comp,open(os.path.expanduser(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_fit_comp15/\"+on+\"_comp.pkl\"),\"wb\"))\n",
    "\n",
    "def rewrite_image_fits_with_header(on):\n",
    "    \"\"\"make a new fits file for data image with header\"\"\"\n",
    "    data= fits.getdata(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_image_SS/\"+on+\".fits\")\n",
    "    data0, header = fits.getdata(glob.glob(os.path.expanduser(\"~/research-data/agn-result/box/final_cut/\"+on+\"*\"))[0],header=True)\n",
    "    if data.shape==data0.shape:\n",
    "        print(f\"{on}: same size of {data.shape}, writing new file\")\n",
    "        fits.writeto(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_image_with_header/\"+on+\".fits\",\n",
    "                    data=data, header = header.copy(),overwrite=True)\n",
    "    else:\n",
    "        print(f\"{on}: images not same size. need to resize\")\n",
    "\n",
    "\n",
    "def rebox_extended_boxes():\n",
    "    \"\"\"for 6 objects that extended box size from photutils, make cutouts again with original photutil sizes.\"\"\"\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    import astropy.units as u\n",
    "    from astropy.nddata import Cutout2D\n",
    "    # load coord catalog\n",
    "    catalog = pd.read_csv('../cutouts/catalog.txt', names=['name', 'ra', 'dec'], delimiter='\\s+')\n",
    "    coords = [SkyCoord(ra=catalog['ra'].loc[i]*u.deg, dec=catalog['dec'].loc[i]*u.deg) for i in range(len(catalog))]\n",
    "    catalog['coords'] = coords\n",
    "    catalog.set_index(\"name\",inplace=True)\n",
    "    # get sizes from google doc\n",
    "    onames = [\"J0328-0710\", \"J0752+2019\",\"J0918+1406\",\"J0926+0724\",\"J1204+0335\",\"J1341-0049\"]\n",
    "    old_sizes = [100,100,80,100,200,150]\n",
    "    sizes = [77,64,70,58,70,70]\n",
    "    # create new cutouts\n",
    "    for old,on,sz in zip(old_sizes, onames, sizes):\n",
    "        try:\n",
    "            d,h = fits.getdata(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/masked_image_with_header/\"+on+\".fits\",header=True)\n",
    "            if d.shape[0] == old:\n",
    "                wcs = WCS(h)\n",
    "                new_cutout = Cutout2D(d, position=catalog.loc[on,'coords'], size=(sz,sz), wcs=wcs)\n",
    "                fits.writeto(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6/refit_boxsize/\"+on+\".fits\", new_cutout.data, header=new_cutout.wcs.to_header())\n",
    "                print(on, \" done\")\n",
    "            else:\n",
    "                print(f\"{on}: old sizes don't match. {old} in doc vs {d.shape[0]} in fits\")\n",
    "        except:\n",
    "            print(f\"{on}: error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 1-time-use search for neighboring AGN\n",
    "- in alpaka\n",
    "- in SDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "################## in alpaka\n",
    "def find_neibor(name, nrow=3):\n",
    "    \"\"\"given object name, return boolean array of whether projected separation of nrow around object is under 110 kpc\"\"\"\n",
    "    desig_mask = alpaka_agn['Desig']== name\n",
    "    ind = alpaka_agn[desig_mask].index.values[0]\n",
    "    # find max angle in deg at obj redshift for projected sep of 110 kpc\n",
    "    thetaMax = ((110*u.kpc/cosmo.angular_diameter_distance(alpaka_agn['Z'][desig_mask].values[0])).to(\"\")*u.rad).to(u.deg).value\n",
    "    # check for angular distance around obj\n",
    "    ocoord = SkyCoord(ra[desig_mask]*u.deg, dec[desig_mask]*u.deg)\n",
    "    neibor_coord = [SkyCoord(ra[i]*u.deg, dec[i]*u.deg) for i in np.arange(ind-nrow,ind+nrow+1)]\n",
    "    angsep = np.array([(ocoord.separation(o)[0]).to(u.deg).value for o in neibor_coord])\n",
    "    dual_mask = [(angsep <= thetaMax) & (angsep != 0)]\n",
    "    return dual_mask\n",
    "\n",
    "# get sample names, alpaka\n",
    "files = os.listdir(\"/home/insepien/research-data/agn-result/fit/fit_correct/masked_image_with_header/\")\n",
    "sizes = [fits.getdata(\"/home/insepien/research-data/agn-result/fit/fit_correct/masked_image_with_header/\"+i).shape[0] for i in files]\n",
    "onames = [f.split(\".\")[0] for f in files]\n",
    "magel = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\")\n",
    "# find the min and max cut out sizes\n",
    "zs = [magel[magel['Desig'] == n]['Z'].values[0] for n in onames]\n",
    "sz = np.array(sizes)\n",
    "szkpc = ((sz*0.16*u.arcsec).to(u.rad).value*cosmo.angular_diameter_distance(np.array(zs))).to(u.kpc)\n",
    "print(f\"Min size: {szkpc.min():.2f}, Max size: {szkpc.max():.2f}\")\n",
    "\n",
    "# load alpaka\n",
    "alpaka = fits.getdata(\"/home/insepien/research-data/alpaka/ALPAKA_v1_withDes.fits\")\n",
    "alpaka = Table(alpaka).to_pandas()\n",
    "# filter for agn only\n",
    "non_agn_mask = alpaka[\"AGN_TYPE\"] == -1\n",
    "alpaka_agn = alpaka[~non_agn_mask]\n",
    "alpaka_agn.sort_values(by=['RA','DEC'],inplace=True)\n",
    "alpaka_agn.reset_index(inplace=True,drop=True)\n",
    "# get ra and dec array\n",
    "ra = alpaka_agn['RA'].values\n",
    "dec = alpaka_agn['DEC'].values\n",
    "# check for pairs under 110 kpc sep\n",
    "sepmask = [find_neibor(name) for name in onames]\n",
    "dualmask = [np.sum(i)==1 for i in sepmask]\n",
    "# objects with neighboring AGN within 110 kpc projected sep\n",
    "print(f\"has neighbor AGN: {np.array(onames)[dualmask]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.sdss import SDSS\n",
    "from astropy.coordinates import SkyCoord\n",
    "magel = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\")\n",
    "magelCoords=[SkyCoord(r*u.deg,d*u.deg) for r,d in zip(magel['RA'],magel['DEC']*u.deg)]\n",
    "magelZ = magel['Z'].values\n",
    "# query sdss specobj in 110 kpc radius\n",
    "sdss_query = []\n",
    "for i in range(len(magel)):\n",
    "    thetaMax = ((110*u.kpc/cosmo.angular_diameter_distance(magelZ[i])).to(\"\")*u.rad).to(u.arcmin).value\n",
    "    sdss_query.append(SDSS.query_region(magelCoords[i], radius=f'{thetaMax:.0f} arcmin',specobj_fields=['class','ra','dec','z'],data_release=18))\n",
    "\n",
    "# check if there is multiple QSO search results \n",
    "multi_qso_mask = [(s['class'] == 'QSO').sum() > 1 for s in sdss_query]\n",
    "multi_qso_magel = magel[multi_qso_mask]\n",
    "multi_qso_ind = np.arange(len(sdss_query))[multi_qso_mask]\n",
    "[sdss_query[m] for m in multi_qso_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "looking at .pkl fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J1215+1344\"\n",
    "magel = pd.read_pickle(\"/home/insepien/research-data/alpaka/magellan/alpaka_39fits.pkl\")\n",
    "pix_to_phys = lambda pixlen: (((pixlen*0.16)*u.arcsec).to(u.rad).value*cosmo.angular_diameter_distance(magel[magel['Desig']==on].Z.values[0])).to(u.kpc)\n",
    "imageFile = glob.glob(os.path.expanduser(\"/home/insepien/research-data/agn-result/box/kpcbox/*\"+on+\"*.fits\"))[0]\n",
    "# imageFile = glob.glob(os.path.expanduser(\"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6(wrongBG)/masked_image_SS/*\"+on+\"*.fits\"))[0]\n",
    "imageAGN = fits.getdata(imageFile)\n",
    "fit_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_fit/\"+on+\".pkl\"\n",
    "# fit_path = \"/home/insepien/research-data/agn-result/fit/fit_masked_n.3to6(wrongBG)/masked_fit/\"+on+\".pkl\"\n",
    "with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "    d_fit = pickle.load(f)\n",
    "\n",
    "getind = lambda name: np.where(np.array(list(d_fit['modelNames'].keys()))==name)[0][0]\n",
    "printparam = lambda name,val: [print(f\"{n}: {v:.2f}\") for n,v in zip(name,val)]\n",
    "\n",
    "modelname = \"psf+sersic\"\n",
    "ind = getind(modelname)\n",
    "printparam(d_fit['paramNames'][ind],d_fit['fitResults'][ind].params)\n",
    "plt.imshow(imageAGN - d_fit['modelImage'][ind], norm='symlog')\n",
    "plt.title(f\"{on}, {modelname}\")\n",
    "\n",
    "def ang_sep(pos1,pos2,on):\n",
    "    \"\"\"calculate angular separation given dictionary of parameter names and values\n",
    "        returns angular sep in arcsec and physical separation in kpc\"\"\"\n",
    "    magel = pd.read_pickle(\"/home/insepien/research-data/alpaka/magellan/alpaka_39fits.pkl\")\n",
    "    z = magel[magel['Desig']==on]['Z'].values\n",
    "    imageFile = glob.glob(os.path.expanduser(\"/home/insepien/research-data/agn-result/box/kpcbox/\"+on+\"*\"))[0]\n",
    "    w = WCS(imageFile)\n",
    "    ra1,dec1 = w.pixel_to_world_values(pos1[0],pos1[1])\n",
    "    ra2,dec2 = w.pixel_to_world_values(pos2[0],pos2[1])\n",
    "    sep_rad = (angular_separation(ra1*u.deg,dec1*u.deg,ra2*u.deg,dec2*u.deg)).to(u.rad)\n",
    "    sep_kpc = (cosmo.angular_diameter_distance(z)*sep_rad.value).to('kpc')\n",
    "    return sep_rad.to(u.arcsec), sep_kpc\n",
    "dparam = dict(zip(d_fit['paramNames'][ind],d_fit['fitResults'][ind].params))\n",
    "# print(\"distance: \", ang_sep([dparam['X0_1'],dparam['Y0_1']], [dparam['X0_2'],dparam['Y0_2']],on))\n",
    "\n",
    "comp_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_comp/\"+on+\"_comp.pkl\"\n",
    "with open(os.path.expanduser(comp_path),\"rb\") as f:\n",
    "    d_comp = pickle.load(f)\n",
    "\n",
    "counts = [np.sum(i) for i in d_comp[modelname].comp_im]\n",
    "fx = np.array([c for c in counts[:-1] if c>0])\n",
    "print(\"flux ratio: \", fx/fx.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = d_fit['configs'][0].getModelAsDict()['options']\n",
    "exptime = 26.199\n",
    "geff = conf['GAIN']*4*exptime\n",
    "sigma2 = (imageAGN + conf['ORIGINAL_SKY'])*exptime/geff + conf['NCOMBINED']*conf['READNOISE']**2/geff**2\n",
    "w = 1/sigma2\n",
    "mychi = np.sum(w*(imageAGN - d_fit['modelImage'][ind])**2)\n",
    "\n",
    "print(f\"my chi2: {mychi:.3f}\")\n",
    "print(f\"imfit chi2: {d_fit['fitResults'][ind].fitStat:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calchi(a,b):\n",
    "    return d_fit['fitResults'][rank_ind[a]].fitStat - d_fit['fitResults'][rank_ind[b]].fitStat\n",
    "\n",
    "on = \"J1140+0918\"\n",
    "print(on)\n",
    "fit_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer/highSky_fit/\"+on+\".pkl\"\n",
    "with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "    d_fit = pickle.load(f)\n",
    "rank_ind = np.argsort([d.fitStat for d in d_fit['fitResults']])\n",
    "modelnames = list (d_fit['modelNames'].keys())\n",
    "for i in range(len(rank_ind)):\n",
    "    print(f\"rank {i} - aic {d_fit['fitResults'][rank_ind[i]].aic:.0f} - del {d_fit['fitResults'][rank_ind[0]].aic-d_fit['fitResults'][rank_ind[i]].aic:.0f} - {modelnames[rank_ind[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "j1215 spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "# load spectra\n",
    "magel = pd.read_pickle(\"/home/insepien/research-data/alpaka/magellan/alpaka_39fits.pkl\")\n",
    "j1215 = magel[magel['Desig']=='J1215+1344']\n",
    "f = fits.open(\"/home/insepien/research-data/pop-result/spec-1613-53115-0408.fits\")\n",
    "d = f[1].data\n",
    "# load cutout fits for fiber plot\n",
    "on = \"J1215+1344\"\n",
    "imageFile = glob.glob(os.path.expanduser(\"/home/insepien/research-data/agn-result/box/kpcbox/*\"+on+\"*.fits\"))[0]\n",
    "imageAGN, header = fits.getdata(imageFile,header=True)\n",
    "wcs = WCS(header)\n",
    "fra_pix, fdec_pix = wcs.world_to_pixel_values(f[0].header['PLUG_RA'], f[0].header['PLUG_DEC'])\n",
    "rad = 1.5/0.16 # sdss fibers are 3'' in diameter, divided by magellan plate scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(9,4),gridspec_kw={'width_ratios': [3,7],'height_ratios':[1]},dpi=300)\n",
    "\n",
    "cmapp = sns.color_palette(\"ch:s=-.3,r=.6\", as_cmap=True).reversed()\n",
    "ax[0].imshow(imageAGN,norm='symlog',cmap=cmapp)\n",
    "circ = Circle((fra_pix,fdec_pix), rad, fill=False,alpha=0.5)\n",
    "ax[0].add_patch(circ)\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[0].invert_yaxis()\n",
    "\n",
    "ax[1].plot(10**d['loglam']/(1+j1215['Z'].values[0]),d['flux'],c=cmapp.colors[70],linewidth=0.5)\n",
    "ax[1].set_xlabel(\"Rest wavelength [$\\AA$]\")\n",
    "ax[1].set_ylabel(\"F$_{\\lambda}$ [$10^{-17}~\\rm{erg~s}^{-1}\\rm{cm}^{-2} \\AA^{-1}$]\")\n",
    "ax[1].text(0.05,0.90,f\"{j1215['NAME'].values[0][7:21]}, $z=${j1215['Z'].values[0]:.3f}\",transform=ax[1].transAxes)\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cosmo.angular_diameter_distance(0.172)*(2.75*u.arcsec).to(u.rad).value).to(u.kpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(12,6))\n",
    "ax[0].plot(10**d['loglam']/1.155,d['flux'],c=cmapp.colors[70],linewidth=1)\n",
    "ax[0].set_xlim(5007-100,5007+100)\n",
    "for wl, text in zip([4959,5007],['[OIII]4959','[OIII]5007']):\n",
    "    ax[0].axvline(wl,alpha=0.2)\n",
    "    ax[0].text(wl,25,text)\n",
    "\n",
    "\n",
    "ax[1].plot(10**d['loglam']/1.155,d['flux'],c=cmapp.colors[70],linewidth=1)\n",
    "ha_wl = 6564\n",
    "ax[1].set_xlim(ha_wl-100,ha_wl+100)\n",
    "ax[1].axvline(ha_wl,alpha=0.2)\n",
    "ax[1].text(ha_wl,25,'HA')\n",
    "\n",
    "[a.set_xlabel(\"Rest-frame wavelength (Angstrom)\") for a in ax]\n",
    "[a.set_ylabel(\"Flux, same unit\") for a in ax]\n",
    "fig.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "fig,ax = plt.subplots(2,2,figsize=(10,6),sharey=True)\n",
    "\n",
    "def gaussian_1d(x, amplitude, mean, std_dev):\n",
    "        return amplitude * np.exp(-(x - mean)**2 / (2 * std_dev**2))\n",
    "\n",
    "for wl,a,mul,lab,aax in zip([5007,6564],ax[1,:],j1215[['OIII_5007_FWHM',\"HA_FWHM\"]].values[0],['[OIII]','HA'],ax[0,:]):\n",
    "    restwl = 10**d['loglam']/1.155\n",
    "    # mask for 40 angstrom around line\n",
    "    aa = 20\n",
    "    mask57 = (restwl > wl-aa) & (restwl < wl+aa)\n",
    "    # crop wl and flux\n",
    "    cropwl = restwl[mask57]\n",
    "    cropvel = (cropwl-wl)/wl*3e5\n",
    "    # subtract continuum. Actually fitting cont with OIII gives 10.55, but 13 with HA, so assume 10 here\n",
    "    cropflx = d['flux'][mask57] - 10\n",
    "    # fit line w gaussian\n",
    "    params, covariance = curve_fit(gaussian_1d, cropvel, cropflx, p0=[30,0,200])\n",
    "    fitted_amplitude, fitted_mean, fitted_std_dev = params\n",
    "    a.plot(cropvel, cropflx);\n",
    "    a.plot(cropvel, gaussian_1d(cropvel, fitted_amplitude, fitted_mean, fitted_std_dev))\n",
    "    a.set_xlabel(\"Velocity [km/s]\")\n",
    "    a.set_ylabel('Continuum subtracted flux')\n",
    "    a.set_title(f\"Fitted FWHM = {fitted_std_dev*2.355:.0f} km/s\\n Mullaney FWHM: {mul:.0f} km/s\")\n",
    "    a.text(-700,25,lab)\n",
    "    \n",
    "    aax.step(cropwl,cropflx+10,where='mid')\n",
    "    aax.set_xlabel(\"Wavelength [$\\AA$]\")\n",
    "    aax.set_ylabel('flux')\n",
    "\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# calculating sky error for uncertainty analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clipped_stats\n",
    "# load sky data\n",
    "skydict = pd.read_pickle(\"/home/insepien/research-data/agn-result/box/skylev/sky_clean.pkl\")\n",
    "# sigma clip diff-boxsize-median at 2-sigma, get 1-sigma sky level\n",
    "sky_std = np.array([sigma_clipped_stats(skydict[k][1][:,2], sigma=2)[-1] for k in skydict.keys()])\n",
    "# save to new df\n",
    "skydf = pd.DataFrame(skydict,index=['sky','data']).T\n",
    "skydf['std'] = sky_std\n",
    "skydf['pdiff'] = np.abs(sky_std/skydf['sky'])\n",
    "fig,ax = plt.subplots(1,2,figsize=(7,3))\n",
    "skydf['pdiff'].hist(grid='',ax=ax[0])\n",
    "skydf[np.isin(skydf.index.values,dualnames)]['pdiff'].hist(grid='',ax=ax[1])\n",
    "[a.set_xlabel(\"$\\sigma$/sky level\") for a in ax]\n",
    "[a.set_title(tit) for a,tit in zip(ax,[\"full sample\",\"dual+candidate\"])]\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# analyze sky uncer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flx_ratio(d_comp_,modelname_,combine=False):\n",
    "    comp_ims = d_comp_[modelname_].comp_im\n",
    "    counts = [np.sum(i) for i in comp_ims]\n",
    "    fx = np.array([c for c in counts[:-1] if c>0])\n",
    "    if combine:\n",
    "        fx = np.array([fx[0]+fx[2],fx[1],fx[3]])\n",
    "    fx_ratio = fx/fx.min()\n",
    "    return fx_ratio\n",
    "\n",
    "def get_flx(d_comp_,modelname_,combine=False):\n",
    "    comp_ims = d_comp_[modelname_].comp_im\n",
    "    counts = [np.sum(i) for i in comp_ims]\n",
    "    fx = np.array([c for c in counts[:-1] if c>0])\n",
    "    if combine:\n",
    "        fx = np.array([fx[0]+fx[2],fx[1],fx[3]])\n",
    "    return fx\n",
    "\n",
    "def load_fid_fit(on):\n",
    "    # load old fit\n",
    "    fit_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_fit/\"+on+\".pkl\"\n",
    "    with open(os.path.expanduser(fit_path),\"rb\") as f:\n",
    "        d_fit = pickle.load(f)\n",
    "    comp_path = \"/home/insepien/research-data/agn-result/fit/fit_kpcbox/kpcbox_comp/\"+on+\"_comp.pkl\"\n",
    "    with open(os.path.expanduser(comp_path),\"rb\") as f:\n",
    "        d_comp = pickle.load(f)\n",
    "    return d_fit, d_comp\n",
    "    \n",
    "\n",
    "def load_uncer_fit(fit_path_uncer,comp_path_uncer):  \n",
    "    # load new fit\n",
    "    with open(os.path.expanduser(fit_path_uncer),\"rb\") as f:\n",
    "        d_fit_uncer = pickle.load(f)\n",
    "    # uncer comp\n",
    "    with open(os.path.expanduser(comp_path_uncer),\"rb\") as f:\n",
    "        d_comp_uncer = pickle.load(f)\n",
    "    return d_fit_uncer, d_comp_uncer\n",
    "\n",
    "def get_model_ind(d_fit_, modelname_):\n",
    "    return np.where(np.array(list(d_fit_['modelNames'].keys()))==modelname_)[0][0]\n",
    "\n",
    "def cal_diff_percentage(old,new):\n",
    "    return np.abs((old-new)/old*100)\n",
    "\n",
    "def get_position_val(param_val, param_name):\n",
    "    position_mask = [p[0] == 'X' or p[0]=='Y' for p in param_name]\n",
    "    positions = param_val[position_mask]\n",
    "    return positions\n",
    "\n",
    "def get_flx_pos(on_, fit_path_uncer_, comp_path_uncer_, modelname_fid_, modelname_uncer_,combine_=False,ratio=False):\n",
    "    d_fit_fid, d_comp_fid = load_fid_fit(on_)\n",
    "    d_fit_uncer, d_comp_uncer = load_uncer_fit(fit_path_uncer_,comp_path_uncer_)\n",
    "    # get model index\n",
    "    ind_fid = get_model_ind(d_fit_fid,modelname_fid_)\n",
    "    ind_uncer = get_model_ind(d_fit_uncer,modelname_uncer_)\n",
    "\n",
    "    if ratio:\n",
    "        #### get flux ratios\n",
    "        fratio_fid = get_flx_ratio(d_comp_fid,modelname_fid_)\n",
    "        fratio_uncer = get_flx_ratio(d_comp_uncer,modelname_uncer_,combine_)\n",
    "    else:\n",
    "        fratio_fid = get_flx(d_comp_fid,modelname_fid_)\n",
    "        fratio_uncer = get_flx(d_comp_uncer,modelname_uncer_,combine_)\n",
    "    #### get positions\n",
    "    positions_fid = get_position_val(d_fit_fid['fitResults'][ind_fid].params,d_fit_fid['paramNames'][ind_fid])\n",
    "    positions_uncer = get_position_val(d_fit_uncer['fitResults'][ind_uncer].params,d_fit_uncer['paramNames'][ind_uncer])\n",
    "    \n",
    "    return fratio_fid, fratio_uncer, positions_fid, positions_uncer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### look at flux to get mag changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J1222-0007\"\n",
    "modelname_fid = \"sersic,sersic\"\n",
    "modelname_uncer = \"sersic,sersic\"\n",
    "flxd = []\n",
    "posd = []\n",
    "for uncertype in ['lowSky_fit','highSky_fit']:\n",
    "    fit_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\", uncertype, on+\".pkl\")\n",
    "    comp_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\",uncertype,on+\"_comp.pkl\")\n",
    "    f_fid, f_uncer, pos_fid, pos_uncer = get_flx_pos(on, fit_path_uncer, comp_path_uncer, modelname_fid, modelname_uncer)\n",
    "    magdif = -2.5*np.log10(f_fid/f_uncer)\n",
    "    print(f\"{uncertype}, diff in mag: {magdif}\")\n",
    "    # print(f_fid, f_uncer, pos_fid, pos_uncer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### look at flux ratios pos changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dualnames = ['J1215+1344','J1222-0007','J0918+1207',\"J0932+1611\",\"J1140+0918\"]\n",
    "modelnames = [\"sersic+psf,psf\",\"sersic,sersic\",\"sersic+sersic,sersic\",\"sersic+sersic,sersic\",\"sersic+psf,sersic\"]\n",
    "\n",
    "\n",
    "on = \"J1215+1344\"\n",
    "modelname_fid = \"sersic+psf,psf\"\n",
    "modelname_uncer = \"sersic+psf,psf\"\n",
    "flxd = []\n",
    "posd = []\n",
    "for uncertype in ['lowSky_fit','highSky_fit']:\n",
    "    fit_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\", uncertype, on+\".pkl\")\n",
    "    comp_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\",uncertype,on+\"_comp.pkl\")\n",
    "    fratio_fid, fratio_uncer, pos_fid, pos_uncer = get_flx_pos(on, fit_path_uncer, comp_path_uncer, modelname_fid, modelname_uncer)#,combine_= True)\n",
    "    fx_diff = cal_diff_percentage(fratio_fid,fratio_uncer)\n",
    "    pos_diff = cal_diff_percentage(pos_fid,pos_uncer)\n",
    "    flxd.extend(fx_diff)\n",
    "    posd.extend(pos_diff)\n",
    "    \n",
    "print(f\"Fid model: {modelname_fid}\")\n",
    "print(f\"Uncer model: {modelname_uncer}\")\n",
    "print(f\"% diff in flux ratio: ({fx_diff[fx_diff!=0].min():.2e} , {fx_diff.max():.2e})\")\n",
    "print(f\"% diff in positions: ({pos_diff.min():.2e} , {pos_diff.max():.2e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### look at R_e and n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J1222-0007\"\n",
    "d_fit, _ = load_fid_fit(on)\n",
    "uncertype='lowSky_fit'\n",
    "fit_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\", uncertype, on+\".pkl\")\n",
    "comp_path_uncer = os.path.join(\"/home/insepien/research-data/agn-result/fit/fit_kpcbox/fitUncer\",uncertype,on+\"_comp.pkl\")\n",
    "dfitu, dcompu = load_uncer_fit(fit_path_uncer, comp_path_uncer)\n",
    "\n",
    "getind = lambda name,d_fit: np.where(np.array(list(d_fit['modelNames'].keys()))==name)[0][0]\n",
    "printparam = lambda name,val: [print(f\"{n}: {v:.4f}\") for n,v in zip(name,val)]\n",
    "\n",
    "modelname = \"sersic,sersic\"\n",
    "ind = getind(modelname,dfitu)\n",
    "print(uncertype)\n",
    "printparam(dfitu['paramNames'][ind],d_fit['fitResults'][ind].params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
