{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee \n",
    "import pyimfit \n",
    "from astropy.io import fits\n",
    "import corner\n",
    "from IPython.display import Latex\n",
    "import sys\n",
    "import warnings\n",
    "from matplotlib.ticker import LogFormatter\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from photutils.detection import find_peaks\n",
    "from photutils.aperture import CircularAperture\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import NDData\n",
    "from photutils.psf import extract_stars\n",
    "from photutils.psf import EPSFBuilder\n",
    "from photutils import profiles\n",
    "from astropy.table import Table\n",
    "\n",
    "medium_font_size = 10\n",
    "plt.rcParams['font.size'] = medium_font_size\n",
    "plt.rcParams['axes.labelsize'] = medium_font_size\n",
    "plt.rcParams['axes.titlesize'] = medium_font_size\n",
    "plt.rcParams['xtick.labelsize'] = medium_font_size\n",
    "plt.rcParams['ytick.labelsize'] = medium_font_size\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks_remove_dups(Imin):\n",
    "    \"\"\"Find peaks with pixel value > Imin\n",
    "       remove duplicate values of x_peak\n",
    "       find indices of detections that are too close/erred\n",
    "       Return peak table with no duplicates and list of indices of close detections\"\"\"\n",
    "    # FIND PEAKS\n",
    "    peaks_tbl = find_peaks(data, threshold=Imin)   \n",
    "    \n",
    "    # Cleaning\n",
    "    # search and remove sources with same x values, keeping only first finds\n",
    "    df = peaks_tbl.to_pandas().sort_values(by='x_peak')\n",
    "    dups = df.duplicated(subset=\"x_peak\",keep=\"first\")\n",
    "    nodups = df[~dups]\n",
    "    # list to remove sources with separation in x and y < 10 pixels \n",
    "    indices_to_drop = []\n",
    "    for i in range(len(nodups)-1):\n",
    "        if abs(nodups.iloc[i+1]['x_peak'] - nodups.iloc[i]['x_peak']) < 10 and abs(nodups.iloc[i+1]['y_peak'] - nodups.iloc[i]['y_peak']) < 10:\n",
    "            indices_to_drop.append(nodups.iloc[i+1].name)\n",
    "            indices_to_drop.append(nodups.iloc[i].name)\n",
    "\n",
    "    indices_to_drop=list((set(indices_to_drop)))\n",
    "    return nodups, indices_to_drop\n",
    "    \n",
    "    \n",
    "def plot_erred_star_peaks(nodups,indices_to_drop,figfile):\n",
    "    \"\"\"plot duplicates detections that turns out to be erred stars\"\"\"\n",
    "    nodups.loc[indices_to_drop].sort_values('x_peak')\n",
    "    ncols = 6\n",
    "    nrows = int(np.ceil(len(indices_to_drop)/ncols))\n",
    "    fig,ax = plt.subplots(nrows,ncols,figsize=(ncols*2,nrows*2))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(len(indices_to_drop)):\n",
    "        y=int(nodups.loc[indices_to_drop[i]]['y_peak'])\n",
    "        x=int(nodups.loc[indices_to_drop[i]]['x_peak'])\n",
    "        px=30\n",
    "        ax[i].imshow(data[y-px:y+px,x-px:x+px], origin='lower', cmap='viridis')\n",
    "        ax[i].set_title(f\"{x},{y}\",fontsize=5)\n",
    "    [ax[-i].axis('off') for i in range(1,len(ax)-len(indices_to_drop)+1)]\n",
    "    fig.suptitle(\"Erred and duplicate detections of peaks\",y=1.0)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(figfile)\n",
    "    \n",
    "    \n",
    "def drop_erred_peaks(nodups, indices_to_drop):\n",
    "    \"\"\"drop erred indices from indice_to_drop from nodups,  returns table of sources position and pixel counts\"\"\"\n",
    "    peaks_tbl = nodups.drop(indices_to_drop)\n",
    "    return peaks_tbl\n",
    "\n",
    "\n",
    "def plot_sources(peaks_tbl):\n",
    "    \"\"\"plot detected sources on the sky exposure\"\"\"\n",
    "    positions = np.transpose((peaks_tbl['x_peak'], peaks_tbl['y_peak']))\n",
    "    apertures = CircularAperture(positions, r=10.0)\n",
    "    norm = simple_norm(data, 'log', percent=99.9)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(data, cmap='Greys_r', origin='lower', norm=norm,\n",
    "               interpolation='nearest')\n",
    "    apertures.plot(color='#0547f9', lw=0.5)\n",
    "    plt.xlim(0, data.shape[1] - 1)\n",
    "    plt.ylim(0, data.shape[0] - 1);\n",
    "    \n",
    "    \n",
    "def plot_stars(stars):\n",
    "    \"\"\"plotting a table of star stamps\"\"\"\n",
    "    nrows = int(np.ceil(len(stars)/4))\n",
    "    ncols = 4\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(int(ncols*2), int(nrows*2)),\n",
    "                           squeeze=True)\n",
    "    ax = ax.ravel()\n",
    "    for i in range(len(stars)):\n",
    "        norm = simple_norm(stars[i], 'log', percent=99.0)\n",
    "        im = ax[i].imshow(stars[i], norm=norm, origin='lower', cmap='viridis')\n",
    "        ax[i].set_title(f\"{i}, ({stars[i].center_flat[0][0]:.0f},{stars[i].center_flat[0][1]:.0f})\")\n",
    "        colorbar = fig.colorbar(im, ax=ax[i], shrink=0.8)\n",
    "        colorbar.ax.yaxis.set_major_locator(plt.MaxNLocator(2))\n",
    "    # turn off empty axes\n",
    "    empty_axes = nrows*ncols-len(stars)\n",
    "    [ax[-i].axis('off') for i in np.arange(1,empty_axes+1)]\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Star ensemble for ePSF construction\")\n",
    "    \n",
    "    \n",
    "def make_star_cutout(peaks_tbl):\n",
    "    \"\"\"make 35x35 pixels star cutouts from peaks_tbl\"\"\"\n",
    "    # size of a star cutout\n",
    "    size = 35\n",
    "    hsize = (size - 1) / 2\n",
    "    x = peaks_tbl['x_peak']  \n",
    "    y = peaks_tbl['y_peak']  \n",
    "    # remove stars that are too close to edges\n",
    "    mask = ((x > hsize) & (x < (data.shape[1] -1 - hsize)) &\n",
    "            (y > hsize) & (y < (data.shape[0] -1 - hsize))) \n",
    "    stars_tbl = Table()\n",
    "    stars_tbl['x'] = x[mask]  \n",
    "    stars_tbl['y'] = y[mask]\n",
    "    # extract stamps\n",
    "    nddata = NDData(data=data)\n",
    "    stars = extract_stars(nddata, stars_tbl, size=35)\n",
    "    return stars_tbl, stars\n",
    "\n",
    "\n",
    "def drop_star_stamps(stars_tbl,drop400,d400=True):\n",
    "    stars_tbl.remove_rows(drop400)\n",
    "    nddata = NDData(data=data)\n",
    "    stars = extract_stars(nddata, stars_tbl, size=35)\n",
    "    return stars\n",
    "\n",
    "\n",
    "def build_psf(stars,osamp,shp,k='quartic',norm_r=20,maxit=30):\n",
    "    \"\"\"build epsf from star ensemble\"\"\"\n",
    "    epsf_builder = EPSFBuilder(oversampling=osamp,shape=shp,smoothing_kernel=k,norm_radius=norm_r,maxiters=maxit) \n",
    "    epsf, fitted_stars = epsf_builder(stars) \n",
    "    return epsf,fitted_stars\n",
    "\n",
    "\n",
    "def plot_psfs(epsf, epsf1, osamp):\n",
    "    \"\"\"plot to compare oversampled and not oversampled psfs\"\"\"\n",
    "    fig,ax = plt.subplots(1,2)\n",
    "    im0 = ax[0].imshow(epsf.data, cmap='viridis')\n",
    "    im1= ax[1].imshow(epsf1.data, cmap='viridis')\n",
    "    [fig.colorbar([im0,im1][i], ax=[ax[0],ax[1]][i],shrink=0.3) for i in range(2)]\n",
    "    [ax[i].set_title([f'Oversampled PSF (x{osamp})', \"PSF\"][i]) for i in range(2)]\n",
    "    fig.tight_layout();\n",
    "    \n",
    "def save_psf(epsf, filename):\n",
    "    \"\"\"save psf to fits file\"\"\"\n",
    "    hdu = fits.PrimaryHDU(epsf.data)\n",
    "    hdulist = fits.HDUList([hdu])\n",
    "    hdulist.writeto(filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = \"J0912+0148\"\n",
    "sourceFile = glob.glob(\"/home/insepien/raw-data-agn/mos-fits-agn/2020_02_20_updated_20260105/*\"+on+\"*\")[0]\n",
    "data = fits.getdata(sourceFile)\n",
    "# find peaks and remove duplicates, erred detections\n",
    "nodups, indices_to_drop = find_peaks_remove_dups(400)\n",
    "#---plot_erred_star_peaks(nodups,indices_to_drop)\n",
    "# drop erred detections \n",
    "peaks_tbl = drop_erred_peaks(nodups, indices_to_drop)\n",
    "# make star stamps\n",
    "stars_tbl, stars = make_star_cutout(peaks_tbl)\n",
    "# drop weird stars and make stamps again\n",
    "d400 = \"0 1 2 3 6 7 8 11 13 15 24 26 27 38 40 44 45 47 51 52 56 59 75 79 80 82 84 86 87 89 90 91 92 96 99 100\".split(\" \")\n",
    "d400 = [int(i) for i in d400]\n",
    "stars_clean = drop_star_stamps(stars_tbl,drop400=d400,d400=True)\n",
    "# plot star stamps\n",
    "#stars = drop_star_stamps(stars_tbl,drop400=[0,2,12,21,22,24],d400=True)\n",
    "plot_stars(stars_clean)\n",
    "# make psfs and plot\n",
    "#epsf,fitted_stars = build_psf(stars,2,shp=None,k='quadratic')\n",
    "# epsf1,fitted_stars1 = build_psf(stars,1,shp=(35,35),k='quartic')\n",
    "# plot_psfs(epsf,epsf1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### try star finders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "hdu = fits.getheader(sourceFile)\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=3.0)\n",
    "### try finding star in only 1 quadrant\n",
    "# find position of source in pix\n",
    "pos = pd.read_csv(\"../cutouts/catalog.txt\", delimiter=' ',header=None, names=['desig','ra','dec'])\n",
    "wcs = WCS(hdu)\n",
    "rapix, decpix = wcs.world_to_pixel(SkyCoord(pos[pos['desig'] == on].ra.values*u.deg, pos[pos['desig'] == on].dec.values*u.deg))\n",
    "# mask everything but source quad\n",
    "mask = np.zeros(data.shape, dtype=bool)\n",
    "mask[:2200,:] = True\n",
    "mask[2200:, 2200:] = True\n",
    "# detect sources\n",
    "daofind = DAOStarFinder(fwhm=hdu['FWHM_AVE'], threshold=5.*std)\n",
    "sources = daofind(data,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot to check source detection\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "apertures = CircularAperture(positions, r=4.0)\n",
    "plt.imshow(data, norm='symlog',vmin=0,vmax=5)\n",
    "plt.plot(rapix, decpix,\"ro\",markersize=50)\n",
    "apertures.plot(color='blue', lw=1.5, alpha=0.5)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract star stamps\n",
    "daopeak = sources.to_pandas()\n",
    "daopeak.rename(columns={'xcentroid':'x_peak','ycentroid':'y_peak'},inplace=True)\n",
    "daostars_tbl, daostars = make_star_cutout(daopeak[daopeak['peak']>400])\n",
    "# clean the star tbl to remove duplicates\n",
    "stars_sorted = daostars_tbl.to_pandas().copy()\n",
    "stars_sorted.sort_values('x',inplace=True)\n",
    "delx = np.diff(stars_sorted['x'])\n",
    "dely = np.diff(stars_sorted['y'])\n",
    "dupmask = (delx<30) & (dely<30)\n",
    "selected_ind = list(stars_sorted.index.values[1:][~dupmask])\n",
    "selected_ind.append(stars_sorted.index.values[0])\n",
    "daostars_nodup = [daostars[i] for i in selected_ind]\n",
    "# plot star no dup\n",
    "plot_stars(daostars_nodup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsf,fitted_stars = build_psf(stars_clean,2,shp=None,k='quadratic')\n",
    "epsf1,fitted_stars1 = build_psf(stars_clean,1,shp=(35,35),k='quartic')\n",
    "plot_psfs(epsf,epsf1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto(\"psf_j0912.fits\", epsf1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nddata = NDData(data=data)\n",
    "stb = Table()\n",
    "stb['x'] =fitted_stars1.center_flat[:,0]\n",
    "stb['y'] =fitted_stars1.center_flat[:,1]\n",
    "recentered_stars = extract_stars(nddata, stb, size=35)\n",
    "i=18\n",
    "# fits.writeto(\"starPSF.fits\", recentered_stars[i]/np.sum(recentered_stars[i]), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### check radial profile consitency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def cal_percent_diff_psf_star_integrated_radial(filename):\n",
    "    \"\"\"find the percent differences of integrated radial profile\"\"\"\n",
    "    d = pd.read_pickle(\"/home/insepien/research-data/psf-results/psf_pkls/\"+filename)\n",
    "    # normalize psf profile\n",
    "    rp_psf1 = profiles.RadialProfile(d['psf'].data,xycen=d['psf'].origin,radii = np.arange(25))\n",
    "    rp_psf1.normalize(\"max\")\n",
    "    # for each star\n",
    "    percent_diff = []\n",
    "    for i in range(len(d['fitted_stars'])):\n",
    "        # normalize profile and integrate\n",
    "        rp_star = profiles.RadialProfile(d['fitted_stars'][i].data,xycen=d['fitted_stars'][i].cutout_center,radii=np.arange(25))\n",
    "        rp_star.normalize(\"max\")\n",
    "        star_sum = np.sum((-np.diff(rp_star.profile))*0.5)\n",
    "        # get residual\n",
    "        rp_resi = rp_star.profile - rp_psf1.profile\n",
    "        # integrate residual\n",
    "        resi_sum = np.sum((np.diff(rp_resi))*0.5)\n",
    "        # find % diff\n",
    "        percent_diff.append(resi_sum/star_sum*100)\n",
    "    return percent_diff # return list, each element = percentage diff of resi/star RP integrated\n",
    "\n",
    "filenames = os.listdir(\"/home/insepien/research-data/psf-results/psf_pkls\")\n",
    "pdiffs = []\n",
    "for f in filenames: # loop for all targets\n",
    "    if f[:3] == 'psf':\n",
    "        pdiffs.append(cal_percent_diff_psf_star_integrated_radial(f))\n",
    "    else: \n",
    "        print(f'err with file {f}')\n",
    "\n",
    "pdiffs = pd.DataFrame(pdiffs)\n",
    "plt.hist(pdiffs.values.flatten())\n",
    "plt.xlabel(\"Int(resi)/Int(Avg star) * 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### RP plot and point source subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_subtraction(epsf1,stars):\n",
    "    \"\"\"plot point source subtraction\"\"\"\n",
    "    ncols = 5\n",
    "    nrows = int(np.ceil(len(stars)/ncols))\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(int(ncols*2), int(nrows*2)),\n",
    "                           squeeze=True)\n",
    "    ax = ax.ravel()\n",
    "    for n in range(len(stars)):\n",
    "        resi = stars[n].compute_residual_image(epsf1)\n",
    "        #err = np.sum(resi)/stars[n].estimate_flux()*100\n",
    "        im = ax[n].imshow(resi)\n",
    "        fig.colorbar(im,ax=ax[n],shrink=0.4)\n",
    "        err = np.sum(resi)/stars[n].estimate_flux()*100\n",
    "        ax[n].set_title(f\"flux overshoot:{err:.2f}%\")\n",
    "    # turn off empty axes\n",
    "    empty_axes = nrows*ncols-len(stars)\n",
    "    [ax[-i].axis('off') for i in np.arange(1,empty_axes+1)]\n",
    "    #err = np.sum(resi)/stars[n].estimate_flux()*100\n",
    "    #fig.suptitle(f\"average total flux overshoot:{err:.2f}%\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "\n",
    "def plot_sum_axis(epsf1, stars, Z, axisname):\n",
    "    \"\"\"plot stars and psf summed along an axis\"\"\"\n",
    "    ncols = int(np.ceil(len(stars)/4))\n",
    "    nrows = 4\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(int(ncols*3), int(nrows*2)),\n",
    "                           squeeze=True)\n",
    "    x,y =np.meshgrid(np.arange(35), np.arange(35))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(len(stars)):\n",
    "        psf = epsf1.evaluate(x=x,y=y,x_0=17,y_0=17,flux = stars[i].estimate_flux())\n",
    "        ax[i].plot(np.sum(stars[i],axis=Z),\"r\")\n",
    "        ax[i].plot(np.sum(psf,axis=Z),\"b\")\n",
    "        ax[i].plot(np.sum(stars[i],axis=Z)-np.sum(psf,axis=Z),\"k\")\n",
    "        ax[i].axvline(x=17,alpha=0.5)    \n",
    "    # turn off empty axes\n",
    "    empty_axes = nrows*ncols-len(stars)\n",
    "    [ax[-i].axis('off') for i in np.arange(1,empty_axes+1)]\n",
    "    fig.suptitle(f\"Summing flux along {axisname}, blue-psf,red-star\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    \n",
    "def plot_psf_rProfile(epsf1,stars):\n",
    "    \"\"\"plot psf and stars radial profiles\"\"\"\n",
    "    fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "    # plot x-sum in first axis\n",
    "    for n in range(len(stars)):\n",
    "        ax[0].plot(np.sum(stars[n].data, axis=0), \"lightblue\", alpha=0.5)\n",
    "    ax[0].plot(np.sum(epsf1.data, axis=0), \"steelblue\")\n",
    "    ax[0].axvline(x=stars[0].cutout_center[0],alpha=0.5)\n",
    "\n",
    "    # plot radial profile in 2nd axis\n",
    "    rp_psf1 = profiles.RadialProfile(epsf1.data,xycen=stars[0].cutout_center,radii = np.arange(25))\n",
    "    rp_psf1.normalize(\"max\")\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(len(stars)):\n",
    "        rp_star = profiles.RadialProfile(stars[i].data,xycen=stars[i].cutout_center,radii=np.arange(25))\n",
    "        rp_star.normalize(\"max\")\n",
    "        m = rp_star.area*rp_star.profile\n",
    "        s+=np.sum(m[~np.isnan(m)])\n",
    "        ax[1].plot(rp_star.radius, rp_star.profile, color=\"lightblue\", alpha=0.5)\n",
    "        ax[1].plot(rp_star.radius, rp_star.profile-rp_psf1.profile, \"g\", alpha=0.1)\n",
    "    ax[1].plot(rp_psf1.radius, rp_psf1.profile,\"steelblue\")\n",
    "\n",
    "    ax[0].set_title(\"x-axis profile\")\n",
    "    ax[0].set_xlabel(\"pixels\")\n",
    "    ax[0].set_ylabel(\"intensity(counts)\")\n",
    "    ax[1].set_title(\"Radial profile of stars and non-oversampled psf\")\n",
    "    ax[1].set_xlabel(\"pixels\")\n",
    "    ax[1].set_ylabel(\"intensity(counts)\")\n",
    "    legend_handles = [plt.Line2D([], [], color='lightblue', label='stars'),\n",
    "                      plt.Line2D([], [], color='steelblue', label='PSF'),\n",
    "                      plt.Line2D([], [], color='green', label='residual')]\n",
    "    ax[1].legend(handles=legend_handles)\n",
    "    psfsum = rp_psf1.area*rp_psf1.profile\n",
    "    psf_integrated = np.sum(psfsum[~np.isnan(psfsum)])\n",
    "    star_integrated = s/len(stars)\n",
    "    ax[1].text(0.4, 0.5, f\"Integrated PSF: {psf_integrated:.2f}\", transform=ax[1].transAxes, fontsize=10, color='k')\n",
    "    ax[1].text(0.4, 0.4, f\"Ave. integrated stars: {star_integrated:.2f}\", transform=ax[1].transAxes, fontsize=10, color='k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psf_rProfile(epsf1,fitted_stars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_point_subtraction(epsf1,fitted_stars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "starnum=0\n",
    "psf1rp = profiles.RadialProfile(epsf1.data,xycen=stars[starnum].cutout_center,radii = np.arange(20))\n",
    "starnrp = profiles.RadialProfile(stars[starnum].data,xycen=stars[starnum].cutout_center,radii = np.arange(20))\n",
    "psf1rp.normalize(\"max\")\n",
    "starnrp.normalize(\"max\")\n",
    "fig,ax = plt.subplots(1,3,figsize=(10,4))\n",
    "ax[0].plot(psf1rp.radius, psf1rp.profile,\"steelblue\")\n",
    "ax[0].plot(starnrp.radius, starnrp.profile,\"lightblue\")\n",
    "ax[0].plot(starnrp.radius, starnrp.profile-psf1rp.profile,\"g\", alpha=0.5)\n",
    "\n",
    "ax[1].plot(np.sum(stars[starnum].data, axis=0), color=\"lightblue\",marker=\"o\")\n",
    "shp = stars[starnum].shape[0]\n",
    "cen = stars[starnum].cutout_center[0]\n",
    "x,y =np.meshgrid(np.arange(shp), np.arange(shp))\n",
    "psf = epsf1.evaluate(x=x,y=y,x_0=cen,y_0=cen,flux = stars[starnum].estimate_flux())\n",
    "ax[1].plot(np.sum(psf, axis=0), \"steelblue\")\n",
    "ax[1].plot(np.sum(psf, axis=0)-np.sum(stars[starnum].data, axis=0), \"green\", alpha=0.5)\n",
    "ax[1].axvline(x=stars[starnum].cutout_center[0],c=\"b\", alpha=0.2)\n",
    "\n",
    "im2 = ax[2].imshow(-stars[starnum].compute_residual_image(epsf1))\n",
    "fig.colorbar(im2, ax=ax[2], shrink=0.5)\n",
    "\n",
    "fig = plt.figure()\n",
    "legend_handles = [plt.Line2D([], [], color='lightblue', label='stars'),\n",
    "                  plt.Line2D([], [], color='steelblue', label='PSF'),\n",
    "                  plt.Line2D([], [], color='green', label='star-psf')]\n",
    "\n",
    "[ax[i].set_title(['Radial profile','x-axis profile','PSF residual'][i]) for i in range(3)]\n",
    "\n",
    "ax[0].legend(handles=legend_handles);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = 2\n",
    "fig,ax = plt.subplots(1,3,figsize=(12,4))\n",
    "norm = simple_norm(stars[i], 'log', percent=99.0)\n",
    "im0 = ax[0].imshow(stars[sn])\n",
    "x,y =np.meshgrid(np.arange(35), np.arange(35))\n",
    "psf = epsf1.evaluate(x=x,y=y,x_0=17,y_0=17,flux = stars[sn].estimate_flux())\n",
    "im1 = ax[1].imshow(psf)\n",
    "im2 = ax[2].imshow(psf-stars[sn].data)\n",
    "[ax[i].plot(17,17,\"ro\", mfc='none') for i in range(2)] \n",
    "[fig.colorbar([im0,im1,im2][i], ax = ax[i],shrink=0.5) for i in range(3)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[stars[i].origin, np.max(stars[i].data), stars[i].flux] for i in range(len(stars))],columns=['pos',\"maxI\",\"flux\"])\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "[ax[i].hist([df.maxI,df.flux][i],histtype=\"step\") for i in range(2)]\n",
    "[ax[i].set_xlabel(['Peak intensity of star(count)','Total star flux'][i]) for i in range(2)]\n",
    "[ax[i].set_ylabel('Number of stars') for i in range(2)]\n",
    "fig.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
