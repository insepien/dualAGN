{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "import astropy.units as u\n",
    "import astropy.constants as const\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.interpolate import CubicSpline\n",
    "from astroquery.sdss import SDSS\n",
    "from astropy.table import vstack\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\",font_scale=1)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{mathptmx}\",  # Times Roman\n",
    "    \"hatch.linewidth\": 3.0,\n",
    "})\n",
    "\n",
    "def make_desig(data, ra_key='ra', dec_key='dec'):\n",
    "    \"\"\"make designation if df has 'ra' and 'dec' columns\"\"\"\n",
    "    desig=[]\n",
    "    for posstring in SkyCoord(data[ra_key].values*u.deg, data[dec_key].values*u.deg,frame='fk5').to_string(\"hmsdms\"):\n",
    "        posstring = posstring.split(' ')\n",
    "        des_ra = posstring[0][0:2]+posstring[0][3:5]\n",
    "        des_dec = posstring[1][0:3]+posstring[1][4:6]\n",
    "        desig.append('J'+des_ra+des_dec)\n",
    "    return desig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at some SNAP targets with neighboring sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = pd.read_csv(\"/home/insepien/research-data/alpaka/snap/snap146.csv\")\n",
    "\n",
    "# manually put in target number and approx angular sep\n",
    "tarnum = np.array([37,42,45,56,58,91,105,112,142])-1\n",
    "zs = np.array([snap.loc[i,\"Z\"] for i in tarnum])\n",
    "sep_arcsec = np.array([15,15,10,15,10,15,15,15,10])\n",
    "sep_kpc = (sep_arcsec*u.arcsec.to(u.rad)*cosmo.angular_diameter_distance(zs)).to(u.kpc)\n",
    "snap.loc[tarnum]\n",
    "\n",
    "## save cutouts from decals\n",
    "# from urllib.request import urlretrieve\n",
    "# for i in range(0, len(final_table)):\n",
    "#urlretrieve('http://legacysurvey.org/viewer/jpeg-cutout?\n",
    "#           ra='+str(snap.loc[tarnum[i],'ra_icrs'])+\n",
    "#           '&dec='+str(snap.loc[tarnum[i],'dec_icrs'])+\n",
    "#           '&layer=decals-dr7&pixscale=0.27&bands=grz',\n",
    "#           'test.jpg'))\n",
    "\n",
    "# decal links given coords, not sure what frame decals is but must not be off by a lot\n",
    "# for i in range(len(tarnum)):\n",
    "#     print(tarnum[i], \"https://www.legacysurvey.org/viewer?ra=\"+str(snap.loc[tarnum[i],'ra_icrs'])+\"&dec=\"+str(snap.loc[tarnum[i],'dec_icrs'])+\"&layer=ls-dr9&zoom=15 \")\n",
    "      \n",
    "sep_kpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get magellan (39objs) & HST (171 from Lbol=OIII*800>1e46) wise lum and r-band mag\n",
    "this was from the old 171 sample. We found later that OIII_DERRED from Mullaney is not reliable, since J1010 is brighter than all 171 objs in r-band and wise, but dimmer in OIII_DERRED. So OIII and IR not matching is probably not a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hst171():\n",
    "    ################# magellan\n",
    "    # this file is from query of sources on WISE, instructions for query in kris candidate selection notebook\n",
    "    # wise search has 39 objects fitted in magellan sample\n",
    "    wise39 = pd.read_pickle(\"/home/insepien/research-data/alpaka/wise-cat/wise_39fits.pkl\")\n",
    "    # read alpaka for optical comparison and redshift\n",
    "    # alpaka has 41 rows, since J0926+0724 (1 is non-agn) and J1222-0007 (dual) are duplicated\n",
    "    alpaka39 = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\")\n",
    "    alpaka39.reset_index(inplace=True)\n",
    "    # get magellan mag and lum\n",
    "    wise_magel_mag, wise_magel_lum, magel_irbol = get_wise_ir_lums(wise39,alpaka39)\n",
    "    #################### OIII\n",
    "    oiii = alpaka39['OIII_5007_LUM_DERRED']\n",
    "\n",
    "    ################# HST\n",
    "    # read wise search\n",
    "    wise171 = pd.read_csv(\"/home/insepien/research-data/alpaka/wise-cat/wise_171.csv\")\n",
    "    desig = [wise171['designation'][i][:5]+wise171['designation'][i][10:15] for i in range(len(wise171))]\n",
    "    wise171['DESIG'] = desig\n",
    "    # find duplicated rows\n",
    "    dupmask = wise171['DESIG'].duplicated(keep=False)\n",
    "    # make separate df\n",
    "    cols = ['DESIG',\"ra\",\"dec\",\"ra_01\",\"dec_01\"]\n",
    "    dups = wise171[dupmask][cols].copy()\n",
    "    # add cols of ra and dec differences \n",
    "    dups['del_ra'] = (dups['ra']-dups['ra_01']).abs()\n",
    "    dups['del_dec'] = (dups['dec']-dups['dec_01']).abs()\n",
    "    # group df by name and find row index with lowest del_ra and del_dec and check\n",
    "    min_dels = dups.groupby(by='DESIG').idxmin()\n",
    "    if np.sum(min_dels['del_ra']==min_dels['del_dec'])==0:\n",
    "        keep_ind = min_dels['del_ra'].values\n",
    "    else:\n",
    "        print(\"min del_ra does not match min del_dec\")\n",
    "    # turns out it is ok to do this\n",
    "    keep_ind = min_dels['del_ra'].values\n",
    "    # drop duplicated rows except for row with lowest ra and dec difference\n",
    "    drop_ind = dups.index[~dups.index.isin(keep_ind)]\n",
    "    wise171.drop(drop_ind,inplace=True)\n",
    "    wise171.reset_index(inplace=True)\n",
    "    #get luminosities\n",
    "    hst_wise_mags, hst_wise_lums, hst_irbol = get_wise_ir_lums(wise171,mul171,wise_key='DESIG',mul_key='DESIG',wl_=22)\n",
    "    # get OIII lum\n",
    "    inf_mask = (mul171['OIII_5007_LUM_DERRED']>-np.inf) & (mul171['OIII_5007_LUM_DERRED']<np.inf)\n",
    "    oiii171 = mul171['OIII_5007_LUM_DERRED'][inf_mask]\n",
    "    # j1010 numbers\n",
    "    j10_ipac['DESIG'] = make_desig(j10_ipac)\n",
    "    j10_w_mag,j10_w_lum,j10_ir_bol = get_wise_ir_lums(j10_ipac,j10_mul,wise_key=\"DESIG\",wl_=22)\n",
    "\n",
    "    ################# r-band\n",
    "    j10_r_magab = 16.83\n",
    "    # read query results and calculate ab mag\n",
    "    sdss = pd.read_pickle(\"~/research-data/alpaka/sdss-cat/sdss_rband_171.pkl\")\n",
    "    hst_magab = 22.5 - 2.5 * np.log10(sdss['spectroFlux_r'])\n",
    "\n",
    "    fig,ax = plt.subplots(2,2,figsize=(13,10))\n",
    "    ax[0,0].hist(wise171['w4mpro']+6.620,label='hst sample IR',color='green')\n",
    "    ax[0,0].hist(pd.DataFrame(wise_magel_mag).loc[3]+6.620, label='magellan sample IR', color='orange') \n",
    "    ax[0,0].axvline(j10_ipac['w4mpro'].values[0]+6.620, label='J1010 IR',c='blue')\n",
    "    ax[0,0].hist(hst_magab,label='hst sample SDSS-R',color='red')\n",
    "    ax[0,0].axvline(j10_r_magab,c='red',label='j1010 SDSS-R')\n",
    "    ax[0,0].set_title(\"Magnitude in WISE IR and SDSS R-band\")\n",
    "    ax[0,0].legend()\n",
    "    ax[0,0].set_xlabel(\"AB Mag\")\n",
    "\n",
    "    # ax[0,1].hist(np.log10(hst_wise_lums),label='hst IR',color='green')\n",
    "    # ax[0,1].hist(np.log10(wise_magel_lum),label='magellan IR',color='orange')\n",
    "    ax[0,1].hist(np.log10(mul171['OIII_5007_LUM']+mul171['OIII_5007B_LUM']),label='narrow+broad [OIII] luminosity')\n",
    "    ax[0,1].axvline(np.log10(j10_mul['OIII_5007_LUM']+j10_mul['OIII_5007B_LUM']).values[0],label='J1010 n+b [OIII] luminosity')\n",
    "    ax[0,1].hist(np.log10(oiii171),label='OIII_DERRED',color='red')\n",
    "    ax[0,1].axvline(np.log10(j10_mul['OIII_5007_LUM_DERRED'].values[0]),color='r',linestyle='--',label='j1010 OIII_DERRED')\n",
    "    ax[0,1].set_xlabel(\"Log(Luminosity) [ergs/s]\")\n",
    "    ax[0,1].set_title(\"Compare [OIII] and [OIII] de-reddened luminosities\")\n",
    "    ax[0,1].legend()\n",
    "    [ax[0,i].set_xlabel(\"Number of AGNs\") for i in range(2)]\n",
    "\n",
    "    ax[1,0].hist(np.log10(hst_wise_lums),label='hst sample',color='green')\n",
    "    ax[1,0].hist(np.log10(wise_magel_lum),label='magellan sample',color='orange')\n",
    "    ax[1,0].axvline(np.log10(j10_w_lum),label='j1010 IR',color='blue')\n",
    "    ax[1,0].set_xlabel(\"Log(IR Luminosity) [ergs/s]\")\n",
    "    ax[1,0].set_title(\"WISE 22-micron Luminosity\")\n",
    "    ax[1,0].legend(loc='upper left')\n",
    "\n",
    "    ax[1,1].hist(np.log10(hst_irbol),label='HST IR', color='green')\n",
    "    ax[1,1].hist(np.log10(magel_irbol),label='Magellan IR', color='orange')\n",
    "    ax[1,1].axvline(np.log10(j10_ir_bol),label='j1010 IR',c=\"blue\")\n",
    "\n",
    "    ax[1,1].set_xlabel(\"Log(L_bol)\")\n",
    "    ax[1,1].set_title(\"Bolometric luminosity (12% correction on IR lum)\")\n",
    "    ax[1,1].legend(loc='upper left')\n",
    "    framenum=np.arange(1,5)\n",
    "    axx = ax.ravel()\n",
    "    [axx[i].text(0.9, 0.9, f\"{framenum[i]}\", transform=axx[i].transAxes, fontsize=30, \n",
    "                fontweight=\"bold\", va=\"top\", ha=\"left\") for i in range(4)]\n",
    "    fig.tight_layout();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new sample\n",
    "after knowing that OIII_DERRED is not reliable, we cut with wise IR lum, correct to bolometric by 12% in log(L_IR). Note that the IR luminosity calculated is a bit higher than the plot in J1010 proposal, but checked so many times with WISE doc (consistent to flux_dens) and chat GPT, and still don't find anything wrong.\n",
    "\n",
    "first look at all type-2 agns in z=0.1-0.5 to see how low we can go in L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_z05_merged_wise.pkl\")\n",
    "j10_ipac = pd.read_csv(\"/home/insepien/research-data/alpaka/wise-cat/j1010_ipac.csv\")\n",
    "j10_mul = mdf[mdf['Desig']==\"J1010+1413\"]\n",
    "\n",
    "wbol = mdf['irbol']\n",
    "wmag = mdf['w4mpro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we cut around 46, we can get an ok sample, J1010 is still the brightest, so it might be unlikely that we find duals in our sample tho...? also 2nd plot is the plot in j1010 proposal, logL seems too be > by 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "ax[0].hist(mdf['w4mpro']+6.620,histtype='step')\n",
    "ax[0].axvline(j10_ipac['w4mpro'].values[0]+6.620,label='j1010')\n",
    "\n",
    "a0= ax[1].hist(np.log10(wbol[(wbol<np.inf)&(wbol>-np.inf)]),histtype='step')\n",
    "#ax[1].axvline(np.log10(j10_ir_bol),label='j1010')\n",
    "\n",
    "ax[0].set_xlabel(\"wise AB mag at $22\\mu m$\")\n",
    "ax[1].set_xlabel(\"Log(Lbol) [erg/s]\")\n",
    "ax[0].set_title(\"WISE magnitude of type-2 AGN in z=0.1-0.5\")\n",
    "ax[1].set_title(\"Bolometric luminosity\\n(12% correction to $Log(L_{22 \\mu m})$) \")\n",
    "\n",
    "[ax[i].legend(loc='upper right') for i in range(2)];\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(8,3))\n",
    "ax[0].scatter(np.log10(mdf['OIII_5007_LUM']),np.log10(mdf['wiseLum']),s=0.5)\n",
    "\n",
    "ax[0].axvline(41,alpha=0.5)\n",
    "ax[0].axhline(44,alpha=0.5)\n",
    "ax[0].set_xlabel(\"Log(L$_{\\\\rm{[OIII]}})$ [erg/s]\")\n",
    "\n",
    "ax[1].scatter(np.log10(mdf['OIII_5007_LUM_DERRED']),np.log10(mdf['wiseLum']),s=0.5)\n",
    "ax[1].set_xlabel(\"Log(L$_{\\\\rm{[OIII, derred]}})$ [erg/s]\")\n",
    "\n",
    "[ax[i].set_ylabel(\"Log(L$_{\\\\rm{IR}})$ [erg/s]\") for i in range(2)]\n",
    "[ax[i].set_xlim(xmin=40) for i in range(2)]\n",
    "[ax[i].set_ylim(ymax=46) for i in range(2)]\n",
    "fig.tight_layout()\n",
    ";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now convert Lbol and Mbh for some eddington rate to choose a good L cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbol_to_m(lbol,edd_rate=0.3):\n",
    "    ledd = lbol/edd_rate\n",
    "    return np.log10(ledd/(1.28e46/1e8))\n",
    "\n",
    "def m_to_lbol(m,edd_rate=0.3):\n",
    "    ledd = 1.28e46*m/1e8\n",
    "    return np.log10(ledd*edd_rate)\n",
    "\n",
    "lbol_to_m(10**45.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at snap sample at some lbol cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lcut = 45.9\n",
    "# check that the log(lbol)>46 subset makes sense in OIII\n",
    "w_Lcut = np.log10(wbol)>log_lcut\n",
    "mul_Lcut = mdf[w_Lcut]\n",
    "def get_lum(cat, key):\n",
    "    return cat[key][(cat[key]>0) & (np.isfinite(cat[key]))]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "ax[0].hist(np.log10(get_lum(mul_Lcut,'HA_LUM')),label='HA',histtype='step')\n",
    "ax[0].hist(np.log10(get_lum(mul_Lcut,'OIII_5007_LUM')),label='OIII',histtype='step')\n",
    "ax[0].axvline(np.log10(j10_mul['HA_LUM'].values[0]),label='j1010 HA')\n",
    "ax[0].axvline(np.log10(j10_mul['OIII_5007_LUM'].values[0]),label='j1010 OIII',c='orange')\n",
    "ax[0].set_xlabel(\"Luminosity [erg/s]\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(mul_Lcut['Z'])\n",
    "ax[1].set_xlabel(\"Z\")\n",
    "ax[1].set_ylabel(\"Number of AGN\")\n",
    "fig.suptitle(f\"log(Lbol)={log_lcut}, log(MBH)={lbol_to_m(10**log_lcut):.2f},sample size: {len(mul_Lcut)}, {len(mul_Lcut)*0.1285/3:.0f} detections\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sdss r-band mag\n",
    "we need to search for r-band mag for exposure time cal and also to put in APT file, but the query is messy, so I had to looked at duplicates and see what to remove/keep. Turns out there are actually 2 kpc scale duals, which messed things up for a while, but fixed everything. final sample after removing 4 observed w hst is 148. While preparing phase 2, I find that the dimmer J1222 is one of the target and it is below the luminosity cut. It was included by mistake because I selected things using designations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sdss(cat,rad=1,query_field=['ra','dec','z','spectroFlux_r','spectroFluxIvar_r']):\n",
    "    \"\"\"query sdss specobj with ra and dec given some catalog\"\"\"\n",
    "    search_results = []\n",
    "    # search some radius in SDSS\n",
    "    for i in cat.index.values:\n",
    "        pos = SkyCoord(cat['RA'][i]*u.deg, cat['DEC'][i]*u.deg, frame='fk5')\n",
    "        xid = SDSS.query_region(pos, radius=str(rad)+' arcsec',specobj_fields=query_field)\n",
    "        search_results.append(xid)\n",
    "    return search_results\n",
    "\n",
    "def add_sdss_data(mul_Lcut):\n",
    "    \"\"\"open sdss query result df, clean that df, merge with alpaka, calculate r-mag AB and error\"\"\"\n",
    "    ########### query around 2 arcsec. if around 1'', miss 1 obj\n",
    "    #search_results = search_sdss(mul_Lcut)\n",
    "    #sdss_matches = pd.concat([Table(search_results[i]).to_pandas() for i in range(len(search_results))])\n",
    "\n",
    "    ########### put search results into df and remove dups\n",
    "    sdss_matches = pd.read_pickle(\"/home/insepien/research-data/alpaka/snap/sdss_query_1arcsec_snap151_original.pkl\")\n",
    "    sdss_matches.reset_index(inplace=True,drop=True)\n",
    "    sdss_matches['Desig'] = make_desig(sdss_matches)\n",
    "    print(f\"sdss query returns {sdss_matches.shape}\")\n",
    "    # match search results with alpaka ra and dec\n",
    "    radec_mask = ((sdss_matches['ra'].isin(mul_Lcut['RA']))& (sdss_matches['dec'].isin(mul_Lcut['DEC'])))\n",
    "    sdss_radec_match = sdss_matches[radec_mask]\n",
    "    sdss_radec_match.reset_index(inplace=True,drop=True)\n",
    "    print(f'matched ra&dec shape: {sdss_radec_match.shape}')\n",
    "    # match ra and dec still return 155 rows. turns out there are duplicated sources (in RA, DEC) but slightly different z, \n",
    "    # since rmag is not too different, just keep the first row\n",
    "    dup_radec_mask = (sdss_radec_match['ra'].duplicated(keep='first')) & (sdss_radec_match['dec'].duplicated(keep='first'))\n",
    "    drop_ind = sdss_radec_match[dup_radec_mask].index.values\n",
    "    sdss_nodups = sdss_radec_match.drop(drop_ind)\n",
    "    sdss_nodups.reset_index(inplace=True,drop=True)\n",
    "    print(f\"removed dups shape: {sdss_nodups.shape}\")\n",
    "\n",
    "    ########### check what rows are missing\n",
    "    missing_rows = mul_Lcut[~(mul_Lcut['Desig'].isin(sdss_nodups['Desig']))].reset_index(drop=True)\n",
    "    print(f\"number of missing rows: {len(missing_rows)}; index = {missing_rows.index.values}; names {missing_rows.Desig.values}\")\n",
    "    # add missing rows. this changes depending on what row is missing and why\n",
    "    # 0th missing row due to no entry in specobj, 1st row missing due to too small search radius\n",
    "    missing_ind = missing_rows.index.values\n",
    "    query_specphot = lambda coord: SDSS.query_region(coord,radius='0.5 arcsec',fields=['ra','dec','z','modelMag_r','modelMagErr_r'])\n",
    "    query_specobj = lambda coord: SDSS.query_region(coord,radius='2 arcsec',specobj_fields=['ra','dec','z','spectroFlux_r','spectroFluxIvar_r'])\n",
    "    pos = lambda row: SkyCoord(row.RA*u.deg,row.DEC*u.deg,frame='fk5')\n",
    "    search0 = query_specphot(pos(missing_rows.loc[0]))\n",
    "    search1 = query_specobj(pos(missing_rows.loc[1]))\n",
    "    # add rows to sdss df\n",
    "    makerow = lambda row: list(row[['OBJID',\"RA\",\"DEC\",\"Z\"]].values)+[np.nan,np.nan,row['Desig']]\n",
    "    sdss_nodups.loc[len(sdss_nodups)] = makerow(missing_rows.loc[0])\n",
    "    sdss_nodups.loc[len(sdss_nodups)] = makerow(missing_rows.loc[1])\n",
    "    # add 1st missing row fluxes\n",
    "    closer_z_ind = np.argmin(search1['z']-missing_rows.loc[1,\"Z\"])\n",
    "    ind0 = sdss_nodups[sdss_nodups['Desig'] == \"J1203+2006\"].index\n",
    "    sdss_nodups.loc[ind0,'spectroFlux_r'] = search1['spectroFlux_r'].value[closer_z_ind]\n",
    "    sdss_nodups.loc[ind0,'spectroFluxIvar_r'] = search1['spectroFluxIvar_r'].value[closer_z_ind]\n",
    "    print(f\"shape after adding missing rows: {sdss_nodups.shape}\")\n",
    "    # renaming colume to merge with alpaka\n",
    "    sdss_nodups.rename(columns={'ra':\"RA\"},inplace=True)\n",
    "    hst_sdss152 = mul_Lcut.merge(sdss_nodups[['RA', 'z', 'spectroFlux_r','spectroFluxIvar_r']],on='RA')\n",
    "    # cal mag and mag err\n",
    "    from uncertainties import ufloat\n",
    "    import uncertainties.umath as um \n",
    "    magWErr = [22.5 - 2.5 * um.log10(ufloat(flx,err)) for flx,err in zip(hst_sdss152['spectroFlux_r'].values,1/np.sqrt(hst_sdss152['spectroFluxIvar_r'].values))]\n",
    "    mag = [m.n for m in magWErr]\n",
    "    magErr = [m.s for m in magWErr]\n",
    "    hst_sdss152['rmag'] = mag\n",
    "    hst_sdss152['rmagErr'] = magErr\n",
    "    # add 0th missing row values which only has mag, not flux\n",
    "    asinh_to_flx = lambda magr_asinh: um.sinh(magr_asinh/-2.5*um.log(10)-um.log(1.2e-10))*2.4e-10\n",
    "    flx_to_ab = lambda flxd: -2.5*um.log10(flxd) \n",
    "    mag0933 = flx_to_ab(asinh_to_flx(ufloat(search0['modelMag_r'].value[0],search0['modelMagErr_r'].value[0])))\n",
    "    ind1 = hst_sdss152[hst_sdss152['Desig'] == \"J0933+2253\"].index\n",
    "    hst_sdss152.loc[ind1,'rmag'] = mag0933.n\n",
    "    hst_sdss152.loc[ind1,'rmagErr'] = mag0933.s\n",
    "    return hst_sdss152\n",
    "\n",
    "#hst_sdss152 = add_sdss_data(mul_Lcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exposure time stuffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have a sampe of 147 (148 in phase 1), I will just read in the pickled sample and I'll format stuffs here to help submit phase 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_sdss152 = pd.read_pickle(\"/home/insepien/research-data/alpaka/snap/hstP2_snap151_alpakaWithSDSS.pkl\")\n",
    "\n",
    "hst_sdss152['10kpc_to_arcsec'] = ((10*u.kpc/cosmo.angular_diameter_distance(hst_sdss152['Z'].values)).to(\"\")*u.rad).to(u.arcsec).value\n",
    "hst_sdss152['oiii_flx_10'] = hst_sdss152['OIII_5007_FLUX']*1e-17 / np.pi/ hst_sdss152['10kpc_to_arcsec']**2  #erg/s/cm2/arcsec2\n",
    "hst_sdss152['magEXT_10'] = hst_sdss152['rmag']+2.5*np.log10(np.pi*hst_sdss152['10kpc_to_arcsec'].values**2) #mag/arcsec2\n",
    "hst_sdss152['rflx_Jy_10'] = hst_sdss152['spectroFlux_r']*3.631*u.Jy / np.pi/ hst_sdss152['10kpc_to_arcsec']**2 #Jy/arcsec2\n",
    "hst_sdss152['OIII_wl'] = (hst_sdss152['Z']+1)*5007\n",
    "hst_sdss152['HA_wl'] = (hst_sdss152['Z']+1)*6562\n",
    "hst_sdss152['ha_flx_10'] = hst_sdss152['HA_FLUX']*1e-17 / np.pi/ hst_sdss152['10kpc_to_arcsec']**2  #erg/s/cm2/arcsec2\n",
    "\n",
    "j1000mask = hst_sdss152['Desig']=='J1000+1242'\n",
    "j1010mask = hst_sdss152['Desig']=='J1010+1413'\n",
    "\n",
    "# remove 4 observed targets\n",
    "observed_mask = hst_sdss152['Desig'].isin(['J1000+1242', 'J1010+1413','J1352+6541', 'J1356+1026','J1222-0007'])\n",
    "hst_sdss148 = hst_sdss152[~observed_mask]\n",
    "hst_sdss148.reset_index(inplace=True,drop=True)\n",
    "print(f\"final sample shape: {hst_sdss148.shape}\")\n",
    "\n",
    "hst_sdss152[j1000mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zranges = [0.1,0.15,0.2,0.3,0.4]\n",
    "zcuts=[(hst_sdss148['Z']< zranges[i+1]) & (hst_sdss148['Z'] > zranges[i]) for i in range(len(zranges)-1)]\n",
    "max_cflx = []\n",
    "colnames = ['Desig','Z','rmag','10kpc_to_arcsec','oiii_flx_10','magEXT_10','OIII_wl',\"HA_wl\",'ha_flx_10']\n",
    "for cutind in range(4):\n",
    "    maxpos = np.argmax(hst_sdss148['magEXT_10'][zcuts[cutind]])\n",
    "    maxind = hst_sdss148[zcuts[cutind]].index.values[maxpos]\n",
    "    max_cflx.append(hst_sdss148.loc[maxind:maxind][colnames].values[0])\n",
    "max_cflx.append(hst_sdss152[j1000mask][colnames].values[0])\n",
    "pd.DataFrame(max_cflx,columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the .csv for target import in APT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get relevant columns and \n",
    "snap148 = hst_sdss148#[['Desig','RA','DEC',\"Z\",'wise4_mag','wise_Lbol','spectroFlux_r',\n",
    "                      # 'rmag','rmagErr','OIII_5007_FLUX','10kpc_to_arcsec','oiii_flx_extended']]\n",
    "snap148.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# convert coords to ICRS frame\n",
    "coord_icrs = SkyCoord(snap148[\"RA\"].values*u.deg, snap148[\"DEC\"].values*u.deg,frame='fk5').transform_to(\"icrs\")\n",
    "snap148['ra_icrs'] = coord_icrs.ra.value\n",
    "snap148['dec_icrs'] = coord_icrs.dec.value\n",
    "\n",
    "#add unique name for APT entry. formatted as SDSSJ... with 2 decimals\n",
    "dess = []\n",
    "for i in range(len(snap148)):\n",
    "    posstring = SkyCoord(snap148.loc[i,\"ra_icrs\"]*u.deg, snap148.loc[i,\"dec_icrs\"]*u.deg).to_string('hmsdms').split(\" \")\n",
    "    des_ra = posstring[0][0:2]+posstring[0][3:5]+posstring[0][6:11]\n",
    "    des_dec = posstring[1][0:3]+posstring[1][4:6]+posstring[1][7:12]\n",
    "    dess.append('SDSSJ'+des_ra+des_dec)\n",
    "snap148['Name'] = dess\n",
    "#add 'other flux' values\n",
    "snap148['otherflux'] = [f\"SDSS r-band AB mag = {snap148.loc[i,'rmag']:.3f}+/-{snap148.loc[i,'rmagErr']:.3f}\" for i in range(len(snap148))]\n",
    "#format csv file to import target\n",
    "snap = snap148[[\"Name\",\"ra_icrs\",\"dec_icrs\",\"Z\",\"otherflux\"]]\n",
    "snap['category'] = [\"GALAXY\"]*len(snap)\n",
    "snap['description'] = [\"[NUCLEUS, QUASAR]\"]*len(snap)\n",
    "snap.shape\n",
    "# # #snap.to_csv(\"snap_phase2.csv\")\n",
    "\n",
    "# fig,ax = plt.subplots(1,4,figsize=(10,3),dpi=200)\n",
    "# ax[0].scatter(snap148['ra_icrs'],snap148['dec_icrs'],s=1)\n",
    "# ax[0].set_xlim(0,360)\n",
    "# ax[0].set_ylim(-90,90)\n",
    "# ax[0].set_xlabel(\"RA[deg]\")\n",
    "# ax[0].set_ylabel(\"DEC[deg]\")\n",
    "\n",
    "# ax[1].hist(snap148['Z'])\n",
    "# ax[1].set_xlabel(\"Redshift\")\n",
    "\n",
    "# ax[2].hist(snap148['rmag'])\n",
    "# ax[2].axvline(hst_sdss152[j1010mask]['rmag'].values[0],c='g')\n",
    "# ax[2].set_xlabel(\"R-mag AB [mag]\")\n",
    "\n",
    "# ax[3].hist(snap148['magEXT_10'])\n",
    "# ax[3].axvline(hst_sdss152[j1010mask]['magEXT_10'].values[0],c='g',label='J1000')\n",
    "# ax[3].set_xlabel(\"R-band surface brightness\\n[mag/arcsec$^2$]\")\n",
    "# ax[3].legend(fontsize=6)\n",
    "\n",
    "# fig.suptitle(f\"Final SNAP sample, {len(snap148)} targets\")\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing sample to J1000, alpaka oiii flux seems to be an underestimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(ax,quant,lab):\n",
    "    ax.hist(quant,alpha=0.5)\n",
    "    ax.axvline(quant[j1000mask].values[0],c='steelblue',label='j1000 sdss/alpaka')\n",
    "    ax.set_xlabel(lab)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(10,3))\n",
    "p(ax[0],hst_sdss152['10kpc_to_arcsec'], \"Extended source radius[arcsec]\\n(assume phys. rad. of 10 kpc)\")\n",
    "\n",
    "p(ax[1],np.log10(hst_sdss152['oiii_flx_extended']), \"Log(OIII_flux)\\n[erg/s/cm2/arcsec2]\")\n",
    "ax[1].axvline(np.log10(1.7e-15),label='j1000 Magel',c='r')\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing filter\n",
    "here i plot the shifted OIII5007 and HA lines for the sample and the response function to choose filter for each observation. the idea is we want to observe NLR, i.e where there is OIII or HA emission. Then we want to observe just the continuum, i.e where there is no emission lines. So you need to choose on-band filter with the shifted emission line, and off-band filter without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info of WFC3 medium filters: central wl, width, max throughput\n",
    "flt = {'547M':[5447.5,\t650\t,0.27],\n",
    "        '621M':[6218.9,609.5,0.29],\n",
    "       '689M':[6876.8,684.2,0.25],\n",
    "       '763M':[7614.4,708.6,0.21],\n",
    "       '845M':[8439.1,794.3,0.14]}\n",
    "\n",
    "def plt_filter(fname,ax):\n",
    "    \"\"\"plot filter bandpasses\"\"\"\n",
    "    tb = Table(fits.getdata(\"/home/insepien/research-data/alpaka/snap/uvis/wfc3_uvis2_f\"+fname.lower()+\".fits\"))\n",
    "    ax.plot(tb['WAVELENGTH'],tb['THROUGHPUT']*50,label='F'+fname,alpha=0.5)\n",
    "\n",
    "def plt_subsample(cat,ax,zmin, zmax,color_,fillo3):\n",
    "    \"\"\"plot histogram of a subsample in some z-range\n",
    "        option to fill oiii or ha just to emphasize which line to observe in that z-range subsample\"\"\"\n",
    "    # cut by z range and redshift factor\n",
    "    zmask = (cat['Z']< zmax) & (cat['Z'] > zmin)\n",
    "    shift = 1+cat['Z'][zmask]\n",
    "    # option to fill hist or not\n",
    "    if fillo3:\n",
    "        o3style='stepfilled'\n",
    "        hastyle='step'\n",
    "    else:\n",
    "        o3style='step'\n",
    "        hastyle='stepfilled'\n",
    "    # plot shifted lines\n",
    "    ax.hist(shift*5007,histtype=o3style,alpha=0.5,color=color_,label=f\"z={zmin}-{zmax}\")\n",
    "    ax.hist(shift*6562,histtype=hastyle,alpha=0.5,color=color_,linestyle=\"--\")\n",
    "\n",
    "\n",
    "def onBand_mask(wl_line,flt_name,cat):\n",
    "    \"\"\"mask for on band for some filter with some central wl and width\"\"\"\n",
    "    wl_eff,width,_ = flt[flt_name]\n",
    "    wl_min = wl_eff - width/2\n",
    "    wl_max = wl_eff + width/2\n",
    "    return ((1+cat['Z'])*wl_line>wl_min) & ((1+cat['Z'])*wl_line < wl_max)\n",
    "\n",
    "def offBand_mask(wl_line,flt_name,cat):\n",
    "    \"\"\"mask for on band for some filter with some central wl and width\"\"\"\n",
    "    wl_eff,width,_ = flt[flt_name]\n",
    "    wl_min = wl_eff - width/2\n",
    "    wl_max = wl_eff + width/2\n",
    "    return ((1+cat['Z'])*wl_line<wl_min) | ((1+cat['Z'])*wl_line > wl_max)\n",
    "\n",
    "def test_filter_set(fname_on,fname_off,onbandline,cat):\n",
    "    \"\"\"test if some line onbandline is off filter fname_off and on fname_on\"\"\"\n",
    "    d = {'OIII':5007, 'HA': 6562}\n",
    "    mask_on_band = onBand_mask(d[onbandline],fname_on,cat) \n",
    "    mask_off_band = offBand_mask(d[onbandline],fname_off,cat)\n",
    "    print(f\"Number of galaxies with {onbandline} on F{fname_on} and off F{fname_off}: {np.sum(mask_on_band&mask_off_band)} vs input size of {len(cat)}\")\n",
    "    return mask_on_band&mask_off_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we divide sample into 4 z ranges. We can choose fitting filters to keep all targets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_Lcut = hst_sdss148\n",
    "zranges = [0.1,0.14,0.2,0.3,0.4]\n",
    "zcuts=[(mul_Lcut['Z']< zranges[i+1]) & (mul_Lcut['Z'] > zranges[i]) for i in range(len(zranges)-1)]\n",
    "\n",
    "oiii_f547_621 = test_filter_set('547M','621M','OIII',mul_Lcut[zcuts[0]])\n",
    "ha_f763_689 = test_filter_set('763M','689M','HA',mul_Lcut[zcuts[1]])\n",
    "oiii_f621_689 = test_filter_set('621M','689M','OIII',mul_Lcut[zcuts[2]])\n",
    "oiii_f689_763 = test_filter_set('689M','763M','OIII',mul_Lcut[zcuts[3]])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "# plot subsample by z-ranges\n",
    "sample_colors = ['k','orangered','dodgerblue','darkorange', 'plum']\n",
    "# choice for filling in OIII or HA hist\n",
    "fills = [True, False, True, True]\n",
    "[plt_subsample(mul_Lcut,ax,zranges[i],zranges[i+1], sample_colors[i],fills[i]) for i in range(len(zranges)-1)]\n",
    "# plot filters\n",
    "colors = ['g','orange','r','darkred','purple']\n",
    "[plt_filter(list(flt.keys())[n],ax) for n in range(5)]\n",
    "\n",
    "\n",
    "# kind of sanity checking that the filters work for each subsample\n",
    "for m,zcut,wl in zip([oiii_f547_621,ha_f763_689,oiii_f621_689,oiii_f689_763],zcuts,[5007,6562,5007,5007]):\n",
    "    # plot subsample by z-cut and on/off band filter mask\n",
    "    plt.hist((1+mul_Lcut['Z'][m&zcut])*wl,histtype='step',color='k')\n",
    "\n",
    "[ax.axvline(6548*i,c='k',alpha=0.5,label=l) for i,l in zip([1.13,1.26],['','NII'])]\n",
    "ax.axvline(5007*1.25,c='b',alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"wavelength (angstroms)\")\n",
    "ax.set_ylabel(\"number of sources\")\n",
    "ax.set_title(\"shifted [OIII] and HA emission lines of 152 sample\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.text(5400,10,\"OIII5007\")\n",
    "ax.text(7300,10, \"HA\")\n",
    "ax.set_xlim((4700,9500))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search target and filter in HST\n",
    "we need to see if hst has observed a target in the filter we want already. we found 4 objects observed and entries with 'target_name' \"DARK' or 'DARK_NM'. Search the proposal id for the weird names, and those were probably calibration/maintainance stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.esa.hubble import ESAHubble\n",
    "def pos(row):\n",
    "    \"\"\"make skyCoord object for HST coord cone search\"\"\"\n",
    "    return SkyCoord(ra=row['RA']*u.deg, dec=row['DEC']*u.deg)\n",
    "\n",
    "def search_hst(mul171_,filters_=[\"F547M\",\"F621M\",\"F689M\",\"F763M\"]):\n",
    "    \"\"\"search if sample has been observed with HST in one of the filters in input list\n",
    "        returns the search results, indices with search errors, and indices of objects that have been observed before\"\"\"\n",
    "    res = []\n",
    "    erred_ind = []\n",
    "    esahubble = ESAHubble()\n",
    "    for i in list(mul171_.index):\n",
    "        try:# try to search in hubble given a mullaney df\n",
    "            res.append(esahubble.cone_search_criteria(coordinates=pos(mul171_.loc[i]),\n",
    "                                                radius=7*u.arcmin,\n",
    "                                                instrument_name = ['WFC3'],\n",
    "                                                filters = filters_))\n",
    "        except: # if there is an error, save index so can find out why\n",
    "            erred_ind.append(i)\n",
    "    # index where there is a search match in HST\n",
    "    observed_ind = [i for i in range(len(res)) if len(res[i])!=0]\n",
    "    return res, erred_ind, observed_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, erred_ind, observed_ind = search_hst(hst_sdss148)\n",
    "hstsearch = pd.concat([Table(r).to_pandas() for r in res])\n",
    "hstsearch['DESIG'] = make_desig(hstsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary calculation\n",
    "\n",
    "we want to know how many binaries we expect to find from our SNAP given the GWB. From GWB, Kris gave a number density of binaries. We use GSMF and MBHMF from Liepold+2024 to calculate the number density of massive galaxies and massive BHs. The fraction is then the ratio of the 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def f(x,alpha,beta,phi):\n",
    "    \"\"\"integrand of SChecter function\"\"\"\n",
    "    return phi*x**alpha*np.exp(-x**beta)  \n",
    "\n",
    "def n_massive_dens(logMcut_,logMbhcut_):\n",
    "    \"\"\"calculate the number density of binary given mass cuts\"\"\"\n",
    "    # GSMF constants\n",
    "    phi1 = 10**-4.85\n",
    "    phi2 = 10**-2.85\n",
    "    Ms = 10**11.33\n",
    "    alpha1 = 0.92\n",
    "    alpha2 = -1.38\n",
    "    # BHMF constants\n",
    "    alpha_bh = -1.27\n",
    "    beta_bh = 0.45\n",
    "    phi_bh = 10**-2\n",
    "    Msbh = 10**8.09\n",
    "    # numerically integrate the number density of massive galaxies (note the GSMF is a sum of 2 PS functions)\n",
    "    result1, _ = quad(f, 10**logMcut_/Ms, np.inf, args=(alpha1,1,phi1))\n",
    "    result2, _ = quad(f, 10**logMcut_/Ms, np.inf, args=(alpha2,1,phi2)) \n",
    "    n_massive_gal = result1+result2\n",
    "    # number density of massive BHs\n",
    "    n_massive_bh, _ = quad(f, 10**logMbhcut_/Msbh, np.inf, args=(alpha_bh,beta_bh,phi_bh)) \n",
    "    return n_massive_gal, n_massive_bh\n",
    "\n",
    "def n_bi(n_massive_,n_binary_):\n",
    "    \"\"\"calculate number of binary and galaxies given their number densities\n",
    "        find dual fraction and expected observations\"\"\"\n",
    "    # get binary number \n",
    "    # SDSS covers only part of sky\n",
    "    f_sky = 9380/41253\n",
    "    # comoving volume in z-range\n",
    "    volume = (cosmo.comoving_volume(0.4)-cosmo.comoving_volume(0.1)).value\n",
    "    # Number of binary\n",
    "    N_c22 = n_binary_*volume*f_sky\n",
    "    # get massive gal number\n",
    "    N_massive_gal = n_massive_*volume*f_sky\n",
    "    # dual fraction\n",
    "    f_dual = N_c22/N_massive_gal\n",
    "    # results\n",
    "    print(f\"{N_c22:.0f} binaries in SDSS in z=0.14-0.22\")\n",
    "    print(f\"{N_massive_gal:.2e} massive galaxies\")\n",
    "    print(f\"dual fraction:{f_dual*100:.2f}%\")\n",
    "    print(f\"We can observe {f_dual*50:.0f}/50 binaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cuts and binary density\n",
    "logMcut = 11\n",
    "logMbhcut = 8.32\n",
    "n_bin = 2.3e-4\n",
    "# calculate number of massive things\n",
    "n_massive_gal, n_massive_bh = n_massive_dens(logMcut_=logMcut, logMbhcut_=logMbhcut)\n",
    "\n",
    "# print results\n",
    "print(\"GSMF\")\n",
    "n_bi(n_massive_gal,n_bin)\n",
    "print(\"\\nBHMF\")\n",
    "n_bi(n_massive_bh,n_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
