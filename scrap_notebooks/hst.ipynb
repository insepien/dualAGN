{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "import astropy.units as u\n",
    "import astropy.constants as const\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.interpolate import CubicSpline\n",
    "from astroquery.sdss import SDSS\n",
    "from astropy.table import vstack\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def j1010_checks(j1010_mul, j1010_ipac):\n",
    "    \"\"\"Checks for J1010 OIII bolo, F160 lum, and IR bolo\"\"\"\n",
    "    # OIII luminosity and bolo from OIII\n",
    "    ja_oiii = 1.2e44 # different from alpaka value??\n",
    "    i1 = ja_oiii*800/(1+1.3)\n",
    "    i2 = i1*1.3\n",
    "    print(f\"alpaka OIII_LUM_DERRED: {j1010_mul['OIII_5007_LUM_DERRED'].values[0]:.1e}\")\n",
    "    print(f\"paper OIII_LUM_DERRED {ja_oiii:.1e}\")\n",
    "    print(f\"by paper OIII, my core 1 bolometric: {i1:.1e}, my core 2 bolometric: {i2:.1e}\")\n",
    "\n",
    "    # F160 luminosity \n",
    "    f160 = 3.23e-12*u.erg/u.s/(u.cm)**2 # from paper\n",
    "    ja_ir = 1.1e11\n",
    "    da = cosmo.luminosity_distance(j1010_mul['Z'].values[0])\n",
    "    print(f\"paper F160 IR lum: {ja_ir:.1e}\")\n",
    "    print(f\"my F160 IR Lum: {(f160*4*np.pi*da**2).to(u.L_sun):.1e}\")\n",
    "\n",
    "    # IR bolo from WISE\n",
    "    paper_ir_bol = 6e46\n",
    "    print(f\"paper bolometric luminosity from WISE IR: {paper_ir_bol:.2e}\")\n",
    "    \n",
    "    wmag10, wmagerr10  = get_wise_mags(j1010_ipac)\n",
    "    j10_w_lum = wise_lum_from_mag(wmag10[:,0], wmagerr10[:,0], 22, 0.198).value\n",
    "    j10_ir_bol = j10_w_lum*10**1.12#10**(spl(np.log10(j10_w_lum)))\n",
    "    print(f\"J1010 AGN lum from WISE IR at 22 microns: {j10_ir_bol:.2e}\")\n",
    "\n",
    "\n",
    "def get_wise_mags(wise_):\n",
    "    \"\"\"get wise mags and mag errors from data frame of ipac search results\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    w1mag = wise_['w1mpro']\n",
    "    w2mag = wise_['w2mpro']\n",
    "    w3mag = wise_['w3mpro']\n",
    "    w4mag = wise_['w4mpro']\n",
    "    wmags_ = np.array([w1mag, w2mag, w3mag, w4mag])\n",
    "    wmags_err_ = np.array([wise_['w1sigmpro'], wise_['w2sigmpro'], wise_['w3sigmpro'], wise_['w4sigmpro']])\n",
    "    return wmags_, wmags_err_\n",
    "\n",
    "\n",
    "def wise_lum_from_mag(wmags_, wmags_err_, obs_wavelength_, redshift_):\n",
    "    \"\"\"calculate wise luminosity from magnitude at some observed wavelength\"\"\"\n",
    "    ## change mags to fluxes -- http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html#example\n",
    "    zeromagflux = np.array([309.540, 171.787, 31.674, 8.363])*u.Jy\n",
    "    fluxdens = zeromagflux*10**(-wmags_/2.5) # in Jy\n",
    "    # now either interpolate flux dens to some wavelength or use a band from wise\n",
    "    wise_wavelengths = np.array([3.4, 4.6, 12., 22.]) # 1e-6 m\n",
    "    if np.isin(obs_wavelength_, wise_wavelengths): # check if need to interpolate to non-wise wl\n",
    "        obs_flux = fluxdens[wise_wavelengths==obs_wavelength_][0]\n",
    "    else: # interpolate\n",
    "        fluxdens_err = zeromagflux*10**(-wmags_err_/2.5)\n",
    "        ## interpolate - use straight line\n",
    "        wiseflux = np.polyfit(wise_wavelengths, fluxdens.value,1, w=1./fluxdens_err)\n",
    "        ## get flux at obs wavelength, i.e. just a straight line here\n",
    "        obs_flux = (wiseflux[0]*obs_wavelength_+wiseflux[1])*u.Jy      \n",
    "    ## change to luminosity\n",
    "    obs_hz = (const.c/(obs_wavelength_*u.micron)).to(u.Hz)\n",
    "    lum = (obs_flux*obs_hz*4*np.pi*\n",
    "           cosmo.luminosity_distance(redshift_)**2).to(u.erg/u.s)\n",
    "    return lum\n",
    "\n",
    "\n",
    "def correct_ir():\n",
    "    \"\"\"correct IR luminosity at 15 microns rest frame based on Hopkins+20\"\"\"\n",
    "    # load hopkins bolometric correction\n",
    "    with open(\"/home/insepien/research-data/pop-result/bc.txt\",\"r\") as f:\n",
    "        d = f.read().splitlines()\n",
    "    hopkins = pd.DataFrame([d[1:][i].split(' ') for i in range(len(d[1:]))],columns=d[0].split(' '))\n",
    "    Lbol = np.array(list(hopkins['Lbols'].values), dtype=float)\n",
    "    LIR = np.array(list(hopkins['LIRs'].values), dtype=float)\n",
    "    spl = CubicSpline(LIR, Lbol)\n",
    "    return spl\n",
    "\n",
    "def get_wise_ir_lums(wise_, alpaka_,wise_key = 'designation', mul_key='Desig',wl_=22):\n",
    "    \"\"\"calculate wise IR luminosity and bolometric lum, \n",
    "        default keys (variants of 'desig') are for magellan sample\"\"\"\n",
    "    ## get wise mags and errors\n",
    "    wmags, wmags_err_nan = get_wise_mags(wise_)\n",
    "    # replace nan values in mag error with median\n",
    "    wmags_err = np.nan_to_num(wmags_err_nan,np.median(wmags_err_nan))\n",
    "    # calculate luminosity\n",
    "    wise_lums = np.zeros((len(wise_)))\n",
    "    for i in range(0, len(wise_)):\n",
    "        z = alpaka_.loc[i,'Z']\n",
    "        wise_lums[i] = wise_lum_from_mag(wmags[:,i], wmags_err[:,i], wl_, z).value\n",
    "    # check wavelength to see how to do bolo correction\n",
    "    if wl_==15: # use Hopkins+2020 if at 15 microns\n",
    "        spl = correct_ir()\n",
    "        irbol = 10**(spl(np.log10(wise_lums)))\n",
    "    else: # else correct by 12%\n",
    "        irbol = wise_lums*10**1.12\n",
    "    return wmags, wise_lums,irbol\n",
    "\n",
    "def make_desig(data, ra_key='ra', dec_key='dec'):\n",
    "    \"\"\"make designation if df has 'ra' and 'dec' columns\"\"\"\n",
    "    desig=[]\n",
    "    for posstring in SkyCoord(data[ra_key].values*u.deg, data[dec_key].values*u.deg,frame='fk5').to_string(\"hmsdms\"):\n",
    "        posstring = posstring.split(' ')\n",
    "        des_ra = posstring[0][0:2]+posstring[0][3:5]\n",
    "        des_dec = posstring[1][0:3]+posstring[1][4:6]\n",
    "        desig.append('J'+des_ra+des_dec)\n",
    "    return desig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load alpaka\n",
    "alpaka = Table(fits.getdata('/home/insepien/research-data/alpaka/ALPAKA_v1_withDes.fits')).to_pandas()\n",
    "# read 171 sample\n",
    "mul171 = pd.read_pickle(\"/home/insepien/research-data/alpaka/mull171.pkl\")\n",
    "mul171['DESIG'] = make_desig(mul171, ra_key='RA', dec_key='DEC')\n",
    "# get j1010 row\n",
    "j10_mul = alpaka[alpaka['Desig']==\"J1010+1413\"]\n",
    "# j1010 WISE search\n",
    "j10_ipac = pd.read_csv(\"/home/insepien/research-data/alpaka/wise-cat/j1010_ipac.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get magellan (39objs) & HST (171 from Lbol=OIII*800>1e46) wise lum and r-band mag\n",
    "this was from the old 171 sample. We found later that OIII_DERRED from Mullaney is not reliable, since J1010 is brighter than all 171 objs in r-band and wise, but dimmer in OIII_DERRED. So OIII and IR not matching is probably not a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hst171():\n",
    "    ################# magellan\n",
    "    # this file is from query of sources on WISE, instructions for query in kris candidate selection notebook\n",
    "    # wise search has 39 objects fitted in magellan sample\n",
    "    wise39 = pd.read_pickle(\"/home/insepien/research-data/alpaka/wise-cat/wise_39fits.pkl\")\n",
    "    # read alpaka for optical comparison and redshift\n",
    "    # alpaka has 41 rows, since J0926+0724 (1 is non-agn) and J1222-0007 (dual) are duplicated\n",
    "    alpaka39 = pd.read_pickle(\"/home/insepien/research-data/alpaka/alpaka_39fits.pkl\")\n",
    "    alpaka39.reset_index(inplace=True)\n",
    "    # get magellan mag and lum\n",
    "    wise_magel_mag, wise_magel_lum, magel_irbol = get_wise_ir_lums(wise39,alpaka39)\n",
    "    #################### OIII\n",
    "    oiii = alpaka39['OIII_5007_LUM_DERRED']\n",
    "\n",
    "    ################# HST\n",
    "    # read wise search\n",
    "    wise171 = pd.read_csv(\"/home/insepien/research-data/alpaka/wise-cat/wise_171.csv\")\n",
    "    desig = [wise171['designation'][i][:5]+wise171['designation'][i][10:15] for i in range(len(wise171))]\n",
    "    wise171['DESIG'] = desig\n",
    "    # find duplicated rows\n",
    "    dupmask = wise171['DESIG'].duplicated(keep=False)\n",
    "    # make separate df\n",
    "    cols = ['DESIG',\"ra\",\"dec\",\"ra_01\",\"dec_01\"]\n",
    "    dups = wise171[dupmask][cols].copy()\n",
    "    # add cols of ra and dec differences \n",
    "    dups['del_ra'] = (dups['ra']-dups['ra_01']).abs()\n",
    "    dups['del_dec'] = (dups['dec']-dups['dec_01']).abs()\n",
    "    # group df by name and find row index with lowest del_ra and del_dec and check\n",
    "    min_dels = dups.groupby(by='DESIG').idxmin()\n",
    "    if np.sum(min_dels['del_ra']==min_dels['del_dec'])==0:\n",
    "        keep_ind = min_dels['del_ra'].values\n",
    "    else:\n",
    "        print(\"min del_ra does not match min del_dec\")\n",
    "    # turns out it is ok to do this\n",
    "    keep_ind = min_dels['del_ra'].values\n",
    "    # drop duplicated rows except for row with lowest ra and dec difference\n",
    "    drop_ind = dups.index[~dups.index.isin(keep_ind)]\n",
    "    wise171.drop(drop_ind,inplace=True)\n",
    "    wise171.reset_index(inplace=True)\n",
    "    #get luminosities\n",
    "    hst_wise_mags, hst_wise_lums, hst_irbol = get_wise_ir_lums(wise171,mul171,wise_key='DESIG',mul_key='DESIG',wl_=22)\n",
    "    # get OIII lum\n",
    "    inf_mask = (mul171['OIII_5007_LUM_DERRED']>-np.inf) & (mul171['OIII_5007_LUM_DERRED']<np.inf)\n",
    "    oiii171 = mul171['OIII_5007_LUM_DERRED'][inf_mask]\n",
    "    # j1010 numbers\n",
    "    j10_ipac['DESIG'] = make_desig(j10_ipac)\n",
    "    j10_w_mag,j10_w_lum,j10_ir_bol = get_wise_ir_lums(j10_ipac,j10_mul,wise_key=\"DESIG\",wl_=22)\n",
    "\n",
    "    ################# r-band\n",
    "    j10_r_magab = 16.83\n",
    "    # read query results and calculate ab mag\n",
    "    sdss = pd.read_pickle(\"~/research-data/alpaka/sdss-cat/sdss_rband_171.pkl\")\n",
    "    hst_magab = 22.5 - 2.5 * np.log10(sdss['spectroFlux_r'])\n",
    "\n",
    "    fig,ax = plt.subplots(2,2,figsize=(13,10))\n",
    "    ax[0,0].hist(wise171['w4mpro']+6.620,label='hst sample IR',color='green')\n",
    "    ax[0,0].hist(pd.DataFrame(wise_magel_mag).loc[3]+6.620, label='magellan sample IR', color='orange') \n",
    "    ax[0,0].axvline(j10_ipac['w4mpro'].values[0]+6.620, label='J1010 IR',c='blue')\n",
    "    ax[0,0].hist(hst_magab,label='hst sample SDSS-R',color='red')\n",
    "    ax[0,0].axvline(j10_r_magab,c='red',label='j1010 SDSS-R')\n",
    "    ax[0,0].set_title(\"Magnitude in WISE IR and SDSS R-band\")\n",
    "    ax[0,0].legend()\n",
    "    ax[0,0].set_xlabel(\"AB Mag\")\n",
    "\n",
    "    # ax[0,1].hist(np.log10(hst_wise_lums),label='hst IR',color='green')\n",
    "    # ax[0,1].hist(np.log10(wise_magel_lum),label='magellan IR',color='orange')\n",
    "    ax[0,1].hist(np.log10(mul171['OIII_5007_LUM']+mul171['OIII_5007B_LUM']),label='narrow+broad [OIII] luminosity')\n",
    "    ax[0,1].axvline(np.log10(j10_mul['OIII_5007_LUM']+j10_mul['OIII_5007B_LUM']).values[0],label='J1010 n+b [OIII] luminosity')\n",
    "    ax[0,1].hist(np.log10(oiii171),label='OIII_DERRED',color='red')\n",
    "    ax[0,1].axvline(np.log10(j10_mul['OIII_5007_LUM_DERRED'].values[0]),color='r',linestyle='--',label='j1010 OIII_DERRED')\n",
    "    ax[0,1].set_xlabel(\"Log(Luminosity) [ergs/s]\")\n",
    "    ax[0,1].set_title(\"Compare [OIII] and [OIII] de-reddened luminosities\")\n",
    "    ax[0,1].legend()\n",
    "    [ax[0,i].set_xlabel(\"Number of AGNs\") for i in range(2)]\n",
    "\n",
    "    ax[1,0].hist(np.log10(hst_wise_lums),label='hst sample',color='green')\n",
    "    ax[1,0].hist(np.log10(wise_magel_lum),label='magellan sample',color='orange')\n",
    "    ax[1,0].axvline(np.log10(j10_w_lum),label='j1010 IR',color='blue')\n",
    "    ax[1,0].set_xlabel(\"Log(IR Luminosity) [ergs/s]\")\n",
    "    ax[1,0].set_title(\"WISE 22-micron Luminosity\")\n",
    "    ax[1,0].legend(loc='upper left')\n",
    "\n",
    "    ax[1,1].hist(np.log10(hst_irbol),label='HST IR', color='green')\n",
    "    ax[1,1].hist(np.log10(magel_irbol),label='Magellan IR', color='orange')\n",
    "    ax[1,1].axvline(np.log10(j10_ir_bol),label='j1010 IR',c=\"blue\")\n",
    "\n",
    "    ax[1,1].set_xlabel(\"Log(L_bol)\")\n",
    "    ax[1,1].set_title(\"Bolometric luminosity (12% correction on IR lum)\")\n",
    "    ax[1,1].legend(loc='upper left')\n",
    "    framenum=np.arange(1,5)\n",
    "    axx = ax.ravel()\n",
    "    [axx[i].text(0.9, 0.9, f\"{framenum[i]}\", transform=axx[i].transAxes, fontsize=30, \n",
    "                fontweight=\"bold\", va=\"top\", ha=\"left\") for i in range(4)]\n",
    "    fig.tight_layout();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new sample\n",
    "after knowing that OIII_DERRED is not reliable, we cut with wise IR lum, correct to bolometric by 12% in log(L_IR). Note that the IR luminosity calculated is a bit higher than the plot in J1010 proposal, but checked so many times with WISE doc (consistent to flux_dens) and chat GPT, and still don't find anything wrong.\n",
    "\n",
    "first look at all type-2 agns in z=0.1-0.5 to see how low we can go in L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut only in z and type from alpaka and do wise search\n",
    "mask = (alpaka['Z']>0.1) & (alpaka['Z']<0.5) & (alpaka['AGN_TYPE']==2)\n",
    "alpaka_z05 = alpaka[mask]\n",
    "# to make ipac .dat query file\n",
    "# ipac_cat = Table([alpaka[mask]['RA'], alpaka[mask]['DEC']], names=['ra','dec'])\n",
    "# for_wise_search = ascii.write(ipac_cat, 'wise_search_z05.dat', format='ipac', overwrite=True);\n",
    "# read wise search results for all type 2 under z=0.5\n",
    "wsearch = pd.read_csv('/home/insepien/research-data/alpaka/wise-cat/wise_z05_result.csv')\n",
    "wsearch['DESIG'] = make_desig(wsearch,ra_key='ra_01',dec_key='dec_01')\n",
    "wsearch.sort_values(by='ra_01')\n",
    "wsearch_ord = wsearch.reset_index(drop=True)\n",
    "alpaka_z05_ord = alpaka_z05.sort_values(by='RA').reset_index(drop=True)\n",
    "# calculate mag and lum\n",
    "wmag,wlum,wbol = get_wise_ir_lums(wsearch_ord, alpaka_z05_ord,wise_key='DESIG',mul_key='Desig',wl_=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we cut around 46, we can get an ok sample, J1010 is still the brightest, so it might be unlikely that we find duals in our sample tho...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "\n",
    "ax[0].hist(wmag[3,:]+6.620,histtype='step')\n",
    "ax[0].axvline(j10_ipac['w4mpro'].values[0]+6.620,label='j1010')\n",
    "\n",
    "a0= ax[1].hist(np.log10(wbol[(wbol<np.inf)&(wbol>-np.inf)]),histtype='step')\n",
    "#ax[1].axvline(np.log10(j10_ir_bol),label='j1010')\n",
    "\n",
    "ax[0].set_xlabel(\"wise AB mag at $22\\mu m$\")\n",
    "ax[1].set_xlabel(\"Log(Lbol) [erg/s]\")\n",
    "ax[0].set_title(\"WISE magnitude of type-2 AGN in z=0.1-0.5\")\n",
    "ax[1].set_title(\"Bolometric luminosity\\n(12% correction to $Log(L_{22 \\mu m})$) \")\n",
    "\n",
    "[ax[i].legend(loc='upper right') for i in range(2)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now convert Lbol and Mbh for some eddington rate to choose a good L cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbol_to_m(lbol,edd_rate=0.3):\n",
    "    ledd = lbol/edd_rate\n",
    "    return np.log10(ledd/(1.28e46/1e8))\n",
    "\n",
    "def m_to_lbol(m,edd_rate=0.3):\n",
    "    ledd = 1.28e46*m/1e8\n",
    "    return np.log10(ledd*edd_rate)\n",
    "\n",
    "lbol_to_m(10**45.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the plot in j1010 proposal, logL seems too be > by 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log10(alpaka_z05['OIII_5007_LUM']),np.log10(wlum),s=0.5)\n",
    "\n",
    "plt.xlim(xmin=40)\n",
    "plt.ylim(ymax=46)\n",
    "\n",
    "#plt.scatter(np.log10(alpaka_z05['OIII_5007_LUM']),np.log10(wlum),s=0.5)\n",
    "#plt.plot(np.log10(j10_mul['OIII_5007_LUM']), np.log10(j10_w_lum), c='r',marker='x')\n",
    "plt.axvline(41)\n",
    "plt.axhline(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at snap sample at some lbol cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lcut = 45.9\n",
    "# check that the log(lbol)>46 subset makes sense in OIII\n",
    "w_Lcut = np.log10(wbol)>log_lcut\n",
    "#mask_Lcut = alpaka_z05['Desig'].isin()\n",
    "mul_Lcut = alpaka_z05_ord[w_Lcut]\n",
    "mul_Lcut['wise4_mag'] = wmag[3,:][w_Lcut]\n",
    "mul_Lcut['wise_lum'] = wlum[w_Lcut]\n",
    "mul_Lcut['wise_Lbol'] = wbol[w_Lcut]\n",
    "def get_lum(cat, key):\n",
    "    return cat[key][(cat[key]>0) & (np.isfinite(cat[key]))]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "ax[0].hist(np.log10(get_lum(mul_Lcut,'HA_LUM')),label='HA',histtype='step')\n",
    "ax[0].hist(np.log10(get_lum(mul_Lcut,'OIII_5007_LUM')),label='OIII',histtype='step')\n",
    "ax[0].axvline(np.log10(j10_mul['HA_LUM'].values[0]),label='j10 HA')\n",
    "ax[0].axvline(np.log10(j10_mul['OIII_5007_LUM'].values[0]),label='j10 OIII',c='orange')\n",
    "ax[0].set_xlabel(\"Luminosity [erg/s]\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(mul_Lcut['Z'])\n",
    "ax[1].set_xlabel(\"Z\")\n",
    "ax[1].set_ylabel(\"# AGN\")\n",
    "fig.suptitle(f\"log(Lbol)={log_lcut}, log(MBH)={lbol_to_m(10**log_lcut):.2f},sample size: {len(mul_Lcut)}, {len(mul_Lcut)*0.1285/3:.0f} detections\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for exposure time cal\n",
    "we need to search for r-band mag for exposure time cal and also to put in APT file, but the query is messy, so I had to looked at duplicates and see what to remove/keep. Turns out there are actually 2 kpc scale duals, which messed things up for a while, but fixed everything. final sample after removing 4 observed w hst is 148. While preparing phase 2, I find that the dimmer J1222 is one of the target and it is below the luminosity cut. It was included by mistake because I selected things using designations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sdss(cat,rad=1,query_field=['ra','dec','z','spectroFlux_r','spectroFluxIvar_r']):\n",
    "    \"\"\"query sdss specobj with ra and dec given some catalog\"\"\"\n",
    "    search_results = []\n",
    "    # search some radius in SDSS\n",
    "    for i in cat.index.values:\n",
    "        pos = SkyCoord(cat['RA'][i]*u.deg, cat['DEC'][i]*u.deg, frame='fk5')\n",
    "        xid = SDSS.query_region(pos, radius=str(rad)+' arcsec',specobj_fields=query_field)\n",
    "        search_results.append(xid)\n",
    "    # put rows into table\n",
    "    #sdss_matches = vstack(search_results).to_pandas()\n",
    "    # make designations\n",
    "    #sdss_matches['DESIG'] = make_desig(sdss_matches)\n",
    "    # examined dups and can take first values, so drop other dup rows\n",
    "    #nodup_mask = sdss_matches['DESIG'].drop_duplicates(keep='first').index.values\n",
    "    #sdss_nodups = sdss_matches.loc[nodup_mask]\n",
    "    return search_results\n",
    "########### query around 2 arcsec. if around 1'', miss 1 obj\n",
    "# search_results = search_sdss(mul_Lcut)\n",
    "\n",
    "########### put search results into df and remove dups\n",
    "sdss_matches = pd.concat([Table(search_results[i]).to_pandas() for i in range(len(search_results))])\n",
    "sdss_matches.reset_index(inplace=True,drop=True)\n",
    "sdss_matches['Desig'] = make_desig(sdss_matches)\n",
    "print(f\"sdss query returns {sdss_matches.shape}\")\n",
    "# match search results with alpaka ra and dec\n",
    "radec_mask = ((sdss_matches['ra'].isin(mul_Lcut['RA']))& (sdss_matches['dec'].isin(mul_Lcut['DEC'])))\n",
    "sdss_radec_match = sdss_matches[radec_mask]\n",
    "sdss_radec_match.reset_index(inplace=True,drop=True)\n",
    "print(f'matched ra&dec shape: {sdss_radec_match.shape}')\n",
    "# match ra and dec still return 155 rows. turns out there are duplicated sources (in RA, DEC) but slightly different z, \n",
    "# since rmag is not too different, just keep the first row\n",
    "dup_radec_mask = (sdss_radec_match['ra'].duplicated(keep='first')) & (sdss_radec_match['dec'].duplicated(keep='first'))\n",
    "drop_ind = sdss_radec_match[dup_radec_mask].index.values\n",
    "sdss_nodups = sdss_radec_match.drop(drop_ind)\n",
    "sdss_nodups.reset_index(inplace=True,drop=True)\n",
    "print(f\"removed dups shape: {sdss_nodups.shape}\")\n",
    "\n",
    "########### check what rows are missing\n",
    "missing_rows = mul_Lcut[~(mul_Lcut['Desig'].isin(sdss_nodups['Desig']))].reset_index(drop=True)\n",
    "print(f\"number of missing rows: {len(missing_rows)}; index = {missing_rows.index.values}; names {missing_rows.Desig.values}\")\n",
    "# add missing rows. this changes depending on what row is missing and why\n",
    "# 0th missing row due to no entry in specobj, 1st row missing due to too small search radius\n",
    "missing_ind = missing_rows.index.values\n",
    "query_specphot = lambda coord: SDSS.query_region(coord,radius='0.5 arcsec',fields=['ra','dec','z','modelMag_r','modelMagErr_r'])\n",
    "query_specobj = lambda coord: SDSS.query_region(coord,radius='2 arcsec',specobj_fields=['ra','dec','z','spectroFlux_r','spectroFluxIvar_r'])\n",
    "pos = lambda row: SkyCoord(row.RA*u.deg,row.DEC*u.deg,frame='fk5')\n",
    "search0 = query_specphot(pos(missing_rows.loc[0]))\n",
    "search1 = query_specobj(pos(missing_rows.loc[1]))\n",
    "# add rows to sdss df\n",
    "makerow = lambda row: list(row[['OBJID',\"RA\",\"DEC\",\"Z\"]].values)+[np.nan,np.nan,row['Desig']]\n",
    "sdss_nodups.loc[len(sdss_nodups)] = makerow(missing_rows.loc[0])\n",
    "sdss_nodups.loc[len(sdss_nodups)] = makerow(missing_rows.loc[1])\n",
    "# add 1st missing row fluxes\n",
    "closer_z_ind = np.argmin(search1['z']-missing_rows.loc[1,\"Z\"])\n",
    "ind0 = sdss_nodups[sdss_nodups['Desig'] == \"J1203+2006\"].index\n",
    "sdss_nodups.loc[ind0,'spectroFlux_r'] = search1['spectroFlux_r'].value[closer_z_ind]\n",
    "sdss_nodups.loc[ind0,'spectroFluxIvar_r'] = search1['spectroFluxIvar_r'].value[closer_z_ind]\n",
    "print(f\"shape after adding missing rows: {sdss_nodups.shape}\")\n",
    "# renaming colume to merge with alpaka\n",
    "sdss_nodups.rename(columns={'ra':\"RA\"},inplace=True)\n",
    "hst_sdss152 = mul_Lcut.merge(sdss_nodups[['RA', 'z', 'spectroFlux_r','spectroFluxIvar_r']],on='RA')\n",
    "# cal mag and mag err\n",
    "from uncertainties import ufloat\n",
    "import uncertainties.umath as um \n",
    "magWErr = [22.5 - 2.5 * um.log10(ufloat(flx,err)) for flx,err in zip(hst_sdss152['spectroFlux_r'].values,1/np.sqrt(hst_sdss152['spectroFluxIvar_r'].values))]\n",
    "mag = [m.n for m in magWErr]\n",
    "magErr = [m.s for m in magWErr]\n",
    "hst_sdss152['rmag'] = mag\n",
    "hst_sdss152['rmagErr'] = magErr\n",
    "# add 0th missing row values which only has mag, not flux\n",
    "asinh_to_flx = lambda magr_asinh: um.sinh(magr_asinh/-2.5*um.log(10)-um.log(1.2e-10))*2.4e-10\n",
    "flx_to_ab = lambda flxd: -2.5*um.log10(flxd) \n",
    "mag0933 = flx_to_ab(asinh_to_flx(ufloat(search0['modelMag_r'].value[0],search0['modelMagErr_r'].value[0])))\n",
    "ind1 = hst_sdss152[hst_sdss152['Desig'] == \"J0933+2253\"].index\n",
    "hst_sdss152.loc[ind1,'rmag'] = mag0933.n\n",
    "hst_sdss152.loc[ind1,'rmagErr'] = mag0933.s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have a sampe of 147 (148 in phase 1), I will just read in the pickled sample and I'll format stuffs here to help submit phase 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_sdss152 = pd.read_pickle(\"/home/insepien/research-data/alpaka/sdss-cat/hstP2_snap151_withSDSS.pkl\")\n",
    "\n",
    "hst_sdss152['10kpc_to_arcsec'] = ((10*u.kpc/cosmo.angular_diameter_distance(hst_sdss152['Z'].values)).to(\"\")*u.rad).to(u.arcsec).value\n",
    "hst_sdss152['oiii_flx_10'] = hst_sdss152['OIII_5007_FLUX']*1e-17 / np.pi/ hst_sdss152['10kpc_to_arcsec']**2  #erg/s/cm2/arcsec2\n",
    "hst_sdss152['magEXT_10'] = hst_sdss152['rmag']+2.5*np.log10(np.pi*hst_sdss152['10kpc_to_arcsec'].values**2) #mag/arcsec2\n",
    "hst_sdss152['rflx_Jy_10'] = hst_sdss152['spectroFlux_r']*3.631*u.Jy / np.pi/ hst_sdss152['10kpc_to_arcsec']**2 #Jy/arcsec2\n",
    "hst_sdss152['OIII_wl'] = (hst_sdss152['Z']+1)*5007\n",
    "hst_sdss152['HA_wl'] = (hst_sdss152['Z']+1)*6562\n",
    "hst_sdss152['ha_flx_10'] = hst_sdss152['HA_FLUX']*1e-17 / np.pi/ hst_sdss152['10kpc_to_arcsec']**2  #erg/s/cm2/arcsec2\n",
    "\n",
    "j1000mask = hst_sdss152['Desig']=='J1000+1242'\n",
    "\n",
    "# remove 4 observed targets\n",
    "observed_mask = hst_sdss152['Desig'].isin(['J1000+1242', 'J1010+1413','J1352+6541', 'J1356+1026'])\n",
    "hst_sdss148 = hst_sdss152[~observed_mask]\n",
    "hst_sdss148.reset_index(inplace=True,drop=True)\n",
    "print(f\"final sample shape: {hst_sdss148.shape}\")\n",
    "\n",
    "hst_sdss152[j1000mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get relevant columns and \n",
    "# snap148 = hst_sdss148[['Desig','RA','DEC',\"Z\",'wise4_mag','wise_Lbol','spectroFlux_r',\n",
    "#                        'rmag','rmagErr','OIII_5007_FLUX','10kpc_to_arcsec','oiii_flx_extended']]\n",
    "# snap148.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# # convert coords to ICRS frame\n",
    "# coord_icrs = SkyCoord(snap148[\"RA\"].values*u.deg, snap148[\"DEC\"].values*u.deg,frame='fk5').transform_to(\"icrs\")\n",
    "# snap148['ra_icrs'] = coord_icrs.ra.value\n",
    "# snap148['dec_icrs'] = coord_icrs.dec.value\n",
    "\n",
    "# # add unique name for APT entry. formatted as SDSSJ... with 2 decimals\n",
    "# dess = []\n",
    "# for i in range(len(snap148)):\n",
    "#     posstring = SkyCoord(snap148.loc[i,\"ra_icrs\"]*u.deg, snap148.loc[i,\"dec_icrs\"]*u.deg).to_string('hmsdms').split(\" \")\n",
    "#     des_ra = posstring[0][0:2]+posstring[0][3:5]+posstring[0][6:11]\n",
    "#     des_dec = posstring[1][0:3]+posstring[1][4:6]+posstring[1][7:12]\n",
    "#     dess.append('SDSSJ'+des_ra+des_dec)\n",
    "# snap148['Name'] = dess\n",
    "# #add 'other flux' values\n",
    "# snap148['otherflux'] = [f\"SDSS r-band AB mag = {snap148.loc[i,'rmag']:.3f}+/-{snap148.loc[i,'rmagErr']:.3f}\" for i in range(len(snap148))]\n",
    "# format csv file to import target\n",
    "# snap = snap148[[\"Name\",\"ra_icrs\",\"dec_icrs\",\"Z\",\"otherflux\"]]\n",
    "# snap['category'] = [\"GALAXY\"]*len(snap)\n",
    "# snap['description'] = [\"[NUCLEUS, QUASAR]\"]*len(snap)\n",
    "# snap\n",
    "# #snap.to_csv(\"snap_phase2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zranges = [0.1,0.13,0.19,0.3,0.4]\n",
    "zcuts=[(hst_sdss148['Z']< zranges[i+1]) & (hst_sdss148['Z'] > zranges[i]) for i in range(len(zranges)-1)]\n",
    "max_cflx = []\n",
    "colnames = ['Desig','Z','rmag','10kpc_to_arcsec','oiii_flx_10','magEXT_10','OIII_wl',\"HA_wl\",'ha_flx_10']\n",
    "for cutind in range(4):\n",
    "    maxpos = np.argmax(hst_sdss148['magEXT_10'][zcuts[cutind]])\n",
    "    maxind = hst_sdss148[zcuts[cutind]].index.values[maxpos]\n",
    "    max_cflx.append(hst_sdss148.loc[maxind:maxind][colnames].values[0])\n",
    "max_cflx.append(hst_sdss152[j1000mask][colnames].values[0])\n",
    "pd.DataFrame(max_cflx,columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,4,figsize=(10,3))\n",
    "ax[0].scatter(snap148['RA'],snap148['DEC'],s=1)\n",
    "ax[0].set_xlim(0,360)\n",
    "ax[0].set_ylim(-90,90)\n",
    "ax[0].set_xlabel(\"RA[deg]\")\n",
    "ax[0].set_ylabel(\"DEC[deg]\")\n",
    "\n",
    "ax[1].hist(snap148['Z'])\n",
    "ax[1].set_xlabel(\"Redshift\")\n",
    "\n",
    "ax[2].hist(snap148['rmag'])\n",
    "ax[2].set_xlabel(\"R-mag AB [mag]\")\n",
    "\n",
    "ax[2].axvline(hst_sdss152[j1000mask]['rmag'].values[0],c='g')\n",
    "\n",
    "\n",
    "nu = const.c/6231/u.angstrom\n",
    "maggie_flux_to_lum = lambda flx_maggie, z: (4*np.pi*(flx_maggie*3.631e-6*u.Jy*nu)*cosmo.angular_diameter_distance(z)**2).to(u.erg/u.s)\n",
    "# ax[3].hist(np.log10(maggie_flux_to_lum(snap148['spectroFlux_r'].values,snap148['Z'].values).value))\n",
    "# ax[3].axvline(np.log10(maggie_flux_to_lum(hst_sdss152[j1000mask]['spectroFlux_r'].values,hst_sdss152[j1000mask]['Z'].values).value),c='g',label='J1000+1242')\n",
    "ax[3].hist(snap148['wise4_mag'])\n",
    "ax[3].axvline(hst_sdss152[j1000mask]['wise4_mag'].values[0],c='g',label='J1000')\n",
    "ax[3].set_xlabel(\"Wise AB mag [mag]\")\n",
    "ax[3].legend(fontsize=6)\n",
    "\n",
    "fig.suptitle(f\"Final SNAP sample, {len(snap148)} targets\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(ax,quant,lab):\n",
    "    ax.hist(quant,alpha=0.5)\n",
    "    ax.axvline(quant[j1000mask].values[0],c='steelblue',label='j1000 sdss/alpaka')\n",
    "    ax.set_xlabel(lab)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(10,3))\n",
    "p(ax[0],hst_sdss152['10kpc_to_arcsec'], \"Extended source radius[arcsec]\\n(assume phys. rad. of 10 kpc)\")\n",
    "\n",
    "p(ax[1],np.log10(hst_sdss152['oiii_flx_extended']), \"Log(OIII_flux)\\n[erg/s/cm2/arcsec2]\")\n",
    "ax[1].axvline(np.log10(1.7e-15),label='j1000 Magel',c='r')\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing filter\n",
    "here i plot the shifted OIII5007 and HA lines for the sample and the response function to choose filter for each observation. the idea is we want to observe NLR, i.e where there is OIII or HA emission. Then we want to observe just the continuum, i.e where there is no emission lines. So you need to choose on-band filter with the shifted emission line, and off-band filter without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info of WFC3 medium filters: central wl, width, max throughput\n",
    "flt = {'547M':[5447.5,\t650\t,0.27],\n",
    "        '621M':[6218.9,609.5,0.29],\n",
    "       '689M':[6876.8,684.2,0.25],\n",
    "       '763M':[7614.4,708.6,0.21],\n",
    "       '845M':[8439.1,794.3,0.14]}\n",
    "\n",
    "def plt_filter(fname,flt_,color,ax):\n",
    "    \"\"\"plot filter bandpasses\"\"\"\n",
    "    # read dict to get central wl, filter width, and peak throughput\n",
    "    # wl0 = flt_[fname][0]\n",
    "    # width = flt_[fname][1]\n",
    "    # throughput = flt_[fname][2]\n",
    "    # # plot as a scaled rectangle ^^\n",
    "    # rect = patches.Rectangle((wl0-width/2, 0), width, throughput*10 , label='F'+fname,\n",
    "    #                          linewidth=2, facecolor=color, alpha=0.3)\n",
    "    # ax.add_patch(rect)\n",
    "    tb = Table(fits.getdata(\"/home/insepien/research-data/alpaka/uvis/wfc3_uvis2_f\"+fname.lower()+\".fits\"))\n",
    "    ax.plot(tb['WAVELENGTH'],tb['THROUGHPUT']*50,label='F'+fname,alpha=0.5)\n",
    "\n",
    "def plt_subsample(cat,ax,zmin, zmax,color_,fillo3):\n",
    "    \"\"\"plot histogram of a subsample in some z-range\n",
    "        option to fill oiii or ha just to emphasize which line to observe in that z-range subsample\"\"\"\n",
    "    # cut by z range and redshift factor\n",
    "    zmask = (cat['Z']< zmax) & (cat['Z'] > zmin)\n",
    "    shift = 1+cat['Z'][zmask]\n",
    "    # option to fill hist or not\n",
    "    if fillo3:\n",
    "        o3style='stepfilled'\n",
    "        hastyle='step'\n",
    "    else:\n",
    "        o3style='step'\n",
    "        hastyle='stepfilled'\n",
    "    # plot shifted lines\n",
    "    ax.hist(shift*5007,histtype=o3style,alpha=0.5,color=color_,label=f\"z={zmin}-{zmax}\")\n",
    "    ax.hist(shift*6562,histtype=hastyle,alpha=0.5,color=color_,linestyle=\"--\")\n",
    "\n",
    "\n",
    "def onBand_mask(wl_line,flt_name,cat):\n",
    "    \"\"\"mask for on band for some filter with some central wl and width\"\"\"\n",
    "    wl_eff,width,_ = flt[flt_name]\n",
    "    wl_min = wl_eff - width/2\n",
    "    wl_max = wl_eff + width/2\n",
    "    return ((1+cat['Z'])*wl_line>wl_min) & ((1+cat['Z'])*wl_line < wl_max)\n",
    "\n",
    "def offBand_mask(wl_line,flt_name,cat):\n",
    "    \"\"\"mask for on band for some filter with some central wl and width\"\"\"\n",
    "    wl_eff,width,_ = flt[flt_name]\n",
    "    wl_min = wl_eff - width/2\n",
    "    wl_max = wl_eff + width/2\n",
    "    return ((1+cat['Z'])*wl_line<wl_min) | ((1+cat['Z'])*wl_line > wl_max)\n",
    "\n",
    "def test_filter_set(fname_on,fname_off,onbandline,cat):\n",
    "    \"\"\"test if some line onbandline is off filter fname_off and on fname_on\"\"\"\n",
    "    d = {'OIII':5007, 'HA': 6562}\n",
    "    mask_on_band = onBand_mask(d[onbandline],fname_on,cat) \n",
    "    mask_off_band = offBand_mask(d[onbandline],fname_off,cat)\n",
    "    print(f\"Number of galaxies with {onbandline} on F{fname_on} and off F{fname_off}: {np.sum(mask_on_band&mask_off_band)} vs input size of {len(cat)}\")\n",
    "    return mask_on_band&mask_off_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can observe only HA, but we lose some targets that are not on any filter. this plot below shows this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe only HA, use 2 filter sets\n",
    "ha_f763_689 = test_filter_set('763M','689M','HA',alpaka_z05[mask_Lcut])\n",
    "ha_f645_763 = test_filter_set('845M','763M','HA',alpaka_z05[mask_Lcut])\n",
    "# plot\n",
    "fig,ax = plt.subplots()\n",
    "# plot whole sample\n",
    "plt_subsample(ax,0.1,0.4, 'steelblue',True) \n",
    "# plot filters\n",
    "colors = ['g','orange','r','purple',\"k\"]\n",
    "[plt_filter(list(flt.keys())[n],flt,colors[n],ax) for n in range(5)]\n",
    "#ax.hist(shift*4959,histtype='step',label=\"shifted [OIII]4959\",alpha=0.5)\n",
    "# ax.hist(shift*6548,histtype='step',label=\"shifted NII 6548\",alpha=0.5)\n",
    "# ax.hist(shift*6584,histtype='step',label=\"shifted NII 6584\",alpha=0.5)\n",
    "# plot only points observable in filter sets\n",
    "plt.hist((1+alpaka_z05[mask_Lcut]['Z'][ha_f763_689])*6562,histtype='step',color='k',\n",
    "         label=f'can observe {np.sum(ha_f763_689)+np.sum(ha_f645_763)} AGNs,\\n{(np.sum(ha_f763_689)+np.sum(ha_f645_763))/3*0.1285:.0f} binaries')\n",
    "plt.hist((1+alpaka_z05[mask_Lcut]['Z'][ha_f645_763])*6562,histtype='step',color='k')\n",
    "ax.set_xlabel(\"wavelength (angstroms)\")\n",
    "ax.set_ylabel(\"# of sources\")\n",
    "ax.set_title(\"shifted [OIII] and HA emission lines of 152 sample\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.text(5400,25,\"OIII5007\")\n",
    "ax.text(7300,25, \"HA\")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we divide sample into 4 z ranges. We can choose fitting filters to keep all targets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_Lcut = hst_sdss148\n",
    "zranges = [0.1,0.13,0.19,0.26,0.33,0.4]\n",
    "#zranges = [0.1,0.15,0.2,0.3,0.4]\n",
    "zcuts=[(mul_Lcut['Z']< zranges[i+1]) & (mul_Lcut['Z'] > zranges[i]) for i in range(len(zranges)-1)]\n",
    "\n",
    "oiii_f547_621 = test_filter_set('547M','621M','OIII',mul_Lcut[zcuts[0]])\n",
    "ha_f763_689 = test_filter_set('763M','689M','HA',mul_Lcut[zcuts[1]])\n",
    "oiii_f621_689 = test_filter_set('621M','689M','OIII',mul_Lcut[zcuts[2]])\n",
    "ha_f845_763 = test_filter_set('845M','763M','HA',mul_Lcut[zcuts[3]])\n",
    "oiii_f689_763 = test_filter_set('689M','763M','OIII',mul_Lcut[zcuts[4]])\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "# plot subsample by z-ranges\n",
    "sample_colors = ['k','orangered','dodgerblue','darkorange', 'plum']\n",
    "# choice for filling in OIII or HA hist\n",
    "fills = [True, False, True, False, True]\n",
    "[plt_subsample(mul_Lcut,ax,zranges[i],zranges[i+1], sample_colors[i],fills[i]) for i in range(len(zranges)-1)]\n",
    "# plot filters\n",
    "colors = ['g','orange','r','darkred','purple']\n",
    "[plt_filter(list(flt.keys())[n],flt,colors[n],ax) for n in range(5)]\n",
    "#ax.hist(shift*4959,histtype='step',label=\"shifted [OIII]4959\",alpha=0.5)\n",
    "# ax.hist(shift*6548,histtype='step',label=\"shifted NII 6548\",alpha=0.5)\n",
    "# ax.hist(shift*6584,histtype='step',label=\"shifted NII 6584\",alpha=0.5)\n",
    "\n",
    "# kind of sanity checking that the filters work for each subsample\n",
    "for m,zcut,wl in zip([oiii_f547_621,ha_f763_689,oiii_f621_689, ha_f845_763, oiii_f689_763],zcuts,[5007,6562,5007,6562,5007]):\n",
    "    # plot subsample by z-cut and on/off band filter mask\n",
    "    plt.hist((1+mul_Lcut['Z'][m&zcut])*wl,histtype='step',color='k')\n",
    "\n",
    "[ax.axvline(6548*i,c='k',alpha=0.5,label=l) for i,l in zip([1.13,1.26],['','NII'])]\n",
    "\n",
    "ax.set_xlabel(\"wavelength (angstroms)\")\n",
    "ax.set_ylabel(\"# of sources\")\n",
    "ax.set_title(\"shifted [OIII] and HA emission lines of 152 sample\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.text(5400,10,\"OIII5007\")\n",
    "ax.text(7300,10, \"HA\")\n",
    "ax.set_xlim((4000,10000))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search target and filter in HST\n",
    "we need to see if hst has observed a target in the filter we want already. we found 4 objects observed and entries with 'target_name' \"DARK' or 'DARK_NM'. Search the proposal id for the weird names, and those were probably calibration/maintainance stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.esa.hubble import ESAHubble\n",
    "def pos(row):\n",
    "    \"\"\"make skyCoord object for HST coord cone search\"\"\"\n",
    "    return SkyCoord(ra=row['RA']*u.deg, dec=row['DEC']*u.deg)\n",
    "\n",
    "def search_hst(mul171_,filters_=[\"F547M\",\"F621M\",\"F689M\",\"F763M\"]):\n",
    "    \"\"\"search if sample has been observed with HST in one of the filters in input list\n",
    "        returns the search results, indices with search errors, and indices of objects that have been observed before\"\"\"\n",
    "    res = []\n",
    "    erred_ind = []\n",
    "    esahubble = ESAHubble()\n",
    "    for i in list(mul171_.index):\n",
    "        try:# try to search in hubble given a mullaney df\n",
    "            res.append(esahubble.cone_search_criteria(coordinates=pos(mul171_.loc[i]),\n",
    "                                                radius=7*u.arcmin,\n",
    "                                                instrument_name = ['WFC3'],\n",
    "                                                filters = filters_))\n",
    "        except: # if there is an error, save index so can find out why\n",
    "            erred_ind.append(i)\n",
    "    # index where there is a search match in HST\n",
    "    observed_ind = [i for i in range(len(res)) if len(res[i])!=0]\n",
    "    return res, erred_ind, observed_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, erred_ind, observed_ind = search_hst(hst_sdss148)\n",
    "hstsearch = pd.concat([Table(r).to_pandas() for r in res])\n",
    "hstsearch['DESIG'] = make_desig(hstsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary calculation\n",
    "\n",
    "we want to know how many binaries we expect to find from our SNAP given the GWB. From GWB, Kris gave a number density of binaries. We use GSMF and MBHMF from Liepold+2024 to calculate the number density of massive galaxies and massive BHs. The fraction is then the ratio of the 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def f(x,alpha,beta,phi):\n",
    "    \"\"\"integrand of SChecter function\"\"\"\n",
    "    return phi*x**alpha*np.exp(-x**beta)  \n",
    "\n",
    "def n_massive_dens(logMcut_,logMbhcut_):\n",
    "    \"\"\"calculate the number density of binary given mass cuts\"\"\"\n",
    "    # GSMF constants\n",
    "    phi1 = 10**-4.85\n",
    "    phi2 = 10**-2.85\n",
    "    Ms = 10**11.33\n",
    "    alpha1 = 0.92\n",
    "    alpha2 = -1.38\n",
    "    # BHMF constants\n",
    "    alpha_bh = -1.27\n",
    "    beta_bh = 0.45\n",
    "    phi_bh = 10**-2\n",
    "    Msbh = 10**8.09\n",
    "    # numerically integrate the number density of massive galaxies (note the GSMF is a sum of 2 PS functions)\n",
    "    result1, _ = quad(f, 10**logMcut_/Ms, np.inf, args=(alpha1,1,phi1))\n",
    "    result2, _ = quad(f, 10**logMcut_/Ms, np.inf, args=(alpha2,1,phi2)) \n",
    "    n_massive_gal = result1+result2\n",
    "    # number density of massive BHs\n",
    "    n_massive_bh, _ = quad(f, 10**logMbhcut_/Msbh, np.inf, args=(alpha_bh,beta_bh,phi_bh)) \n",
    "    return n_massive_gal, n_massive_bh\n",
    "\n",
    "def n_bi(n_massive_,n_binary_):\n",
    "    \"\"\"calculate number of binary and galaxies given their number densities\n",
    "        find dual fraction and expected observations\"\"\"\n",
    "    # get binary number \n",
    "    # SDSS covers only part of sky\n",
    "    f_sky = 9380/41253\n",
    "    # comoving volume in z-range\n",
    "    volume = (cosmo.comoving_volume(0.4)-cosmo.comoving_volume(0.1)).value\n",
    "    # Number of binary\n",
    "    N_c22 = n_binary_*volume*f_sky\n",
    "    # get massive gal number\n",
    "    N_massive_gal = n_massive_*volume*f_sky\n",
    "    # dual fraction\n",
    "    f_dual = N_c22/N_massive_gal\n",
    "    # results\n",
    "    print(f\"{N_c22:.0f} binaries in SDSS in z=0.14-0.22\")\n",
    "    print(f\"{N_massive_gal:.2e} massive galaxies\")\n",
    "    print(f\"dual fraction:{f_dual*100:.2f}%\")\n",
    "    print(f\"We can observe {f_dual*50:.0f}/50 binaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cuts and binary density\n",
    "logMcut = 11\n",
    "logMbhcut = 8.32\n",
    "n_bin = 2.3e-4\n",
    "# calculate number of massive things\n",
    "n_massive_gal, n_massive_bh = n_massive_dens(logMcut_=logMcut, logMbhcut_=logMbhcut)\n",
    "\n",
    "# print results\n",
    "print(\"GSMF\")\n",
    "n_bi(n_massive_gal,n_bin)\n",
    "print(\"\\nBHMF\")\n",
    "n_bi(n_massive_bh,n_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
